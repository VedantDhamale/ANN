{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a770264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57818013",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y=np.array([[0],[1],[1],[0]])\n",
    "\n",
    "#input layer neuron\n",
    "IL=2\n",
    "\n",
    "#hidden layer neuron\n",
    "HL=2\n",
    "\n",
    "#output layer neuron\n",
    "OL=1\n",
    "\n",
    "epochs = 1000\n",
    "lr = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e578d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_fun(x):\n",
    "    sigmoid_val=1/(1+np.exp(-x))\n",
    "    return sigmoid_val\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2c7f9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer Weights\n",
      "[[0.73401097 0.17805132]\n",
      " [0.57308471 0.42868602]]\n",
      " \n",
      "Hidden layer bias\n",
      "[[0.22993907 0.91484037]]\n",
      " \n",
      "Output layer Weights\n",
      "[[0.10559708]\n",
      " [0.13493054]]\n",
      " \n",
      "Output layer bias\n",
      "[[0.243671]]\n"
     ]
    }
   ],
   "source": [
    "HW = np.random.uniform(size=(IL,HL))\n",
    "hidden_bias =np.random.uniform(size=(1,HL))\n",
    "\n",
    "print(\"Hidden layer Weights\")\n",
    "print(HW)\n",
    "print(\" \")\n",
    "\n",
    "print(\"Hidden layer bias\")\n",
    "print(hidden_bias)\n",
    "print(\" \")\n",
    "\n",
    "OW = np.random.uniform(size=(HL,OL))\n",
    "output_bias = np.random.uniform(size=(1,OL))\n",
    "\n",
    "print(\"Output layer Weights\")\n",
    "print(OW)\n",
    "print(\" \")\n",
    "\n",
    "print(\"Output layer bias\")\n",
    "print(output_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8cf1d6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggrigation in hidden layer\n",
      "[[0.22993907 0.91484037]\n",
      " [0.80302378 1.34352639]\n",
      " [0.96395004 1.09289169]\n",
      " [1.53703475 1.5215777 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55723282 0.71398963]\n",
      " [0.69062092 0.79306926]\n",
      " [0.72391197 0.74892585]\n",
      " [0.82303325 0.82077069]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.39885217]\n",
      " [0.42360782]\n",
      " [0.42116696]\n",
      " [0.44132794]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.59841185]\n",
      " [0.60434625]\n",
      " [0.60376246]\n",
      " [0.60857541]]\n"
     ]
    }
   ],
   "source": [
    "#for hidden layer\n",
    "\n",
    "print(\"Aggrigation in hidden layer\")\n",
    "#doing aggrigation\n",
    "HL_activation = np.dot(x,HW)\n",
    "HL_activation += hidden_bias\n",
    "print(HL_activation)\n",
    "print(\" \")\n",
    "\n",
    "print(\"Applying Activation in Hidden layer\")\n",
    "#applying activation function\n",
    "hidden_layer_output = sigmoid_fun(HL_activation)\n",
    "print(hidden_layer_output)\n",
    "\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "\n",
    "#for output layer\n",
    "#doing aggrigation\n",
    "print(\"Aggrigation in Output Layer\")\n",
    "OL_activation=np.dot(hidden_layer_output,OW)\n",
    "OL_activation += output_bias\n",
    "print(OL_activation)\n",
    "\n",
    "\n",
    "print(\" \")\n",
    "#applying activation \n",
    "print(\"Applying Activation Function in Output layer\")\n",
    "print(\"Predicated Output\")\n",
    "Predicted_Output = sigmoid_fun(OL_activation)\n",
    "print(Predicted_Output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a37ee3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error [[-0.59841185]\n",
      " [ 0.39565375]\n",
      " [ 0.39623754]\n",
      " [-0.60857541]]\n"
     ]
    }
   ],
   "source": [
    "error = y - Predicted_Output\n",
    "print(\"Error\",error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "acaaf797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggrigation in hidden layer\n",
      "[[0.22993907 0.91484037]\n",
      " [0.80302378 1.34352639]\n",
      " [0.96395004 1.09289169]\n",
      " [1.53703475 1.5215777 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55723282 0.71398963]\n",
      " [0.69062092 0.79306926]\n",
      " [0.72391197 0.74892585]\n",
      " [0.82303325 0.82077069]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.39885217]\n",
      " [0.42360782]\n",
      " [0.42116696]\n",
      " [0.44132794]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.59841185]\n",
      " [0.60434625]\n",
      " [0.60376246]\n",
      " [0.60857541]]\n",
      "Error [[-0.59841185]\n",
      " [ 0.39565375]\n",
      " [ 0.39623754]\n",
      " [-0.60857541]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22975495 0.91460637]\n",
      " [0.80283014 1.34321412]\n",
      " [0.96374301 1.09261044]\n",
      " [1.53681821 1.5212182 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55718739 0.71394184]\n",
      " [0.69057955 0.79301801]\n",
      " [0.72387059 0.74887297]\n",
      " [0.82300171 0.8207178 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.37985365]\n",
      " [0.40313752]\n",
      " [0.40081234]\n",
      " [0.4197817 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.59383781]\n",
      " [0.59944125]\n",
      " [0.59888282]\n",
      " [0.60343101]]\n",
      "Error [[-0.59383781]\n",
      " [ 0.40055875]\n",
      " [ 0.40111718]\n",
      " [-0.60343101]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2295909  0.91439505]\n",
      " [0.8026613  1.34293326]\n",
      " [0.96356138 1.09235931]\n",
      " [1.53663179 1.52089752]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55714692 0.71389868]\n",
      " [0.69054347 0.7929719 ]\n",
      " [0.72383429 0.74882573]\n",
      " [0.82297455 0.82067061]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.36168901]\n",
      " [0.38356745]\n",
      " [0.38135346]\n",
      " [0.39918457]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.58944923]\n",
      " [0.59473324]\n",
      " [0.5941995 ]\n",
      " [0.59849173]]\n",
      "Error [[-0.58944923]\n",
      " [ 0.40526676]\n",
      " [ 0.4058005 ]\n",
      " [-0.59849173]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22944506 0.91420451]\n",
      " [0.80251474 1.34268109]\n",
      " [0.96340263 1.09213559]\n",
      " [1.5364723  1.52061217]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55711093 0.71385976]\n",
      " [0.69051215 0.7929305 ]\n",
      " [0.72380255 0.74878365]\n",
      " [0.82295132 0.82062861]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.34433468]\n",
      " [0.36487217]\n",
      " [0.362765  ]\n",
      " [0.37950975]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.58524308]\n",
      " [0.59021934]\n",
      " [0.5897096 ]\n",
      " [0.59375486]]\n",
      "Error [[-0.58524308]\n",
      " [ 0.40978066]\n",
      " [ 0.4102904 ]\n",
      " [-0.59375486]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22931573 0.91403296]\n",
      " [0.80238812 1.3424551 ]\n",
      " [0.96326441 1.09193678]\n",
      " [1.53633681 1.52035891]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55707902 0.71382472]\n",
      " [0.69048509 0.79289339]\n",
      " [0.72377492 0.74874625]\n",
      " [0.82293157 0.82059133]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.32776597]\n",
      " [0.34702501]\n",
      " [0.34502041]\n",
      " [0.36072916]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5812157 ]\n",
      " [0.58589597]\n",
      " [0.58540952]\n",
      " [0.58921693]]\n",
      "Error [[-0.5812157 ]\n",
      " [ 0.41410403]\n",
      " [ 0.41459048]\n",
      " [-0.58921693]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22920128 0.91387872]\n",
      " [0.80227929 1.34225291]\n",
      " [0.96314458 1.09176051]\n",
      " [1.53622258 1.5201347 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55705078 0.71379321]\n",
      " [0.69046183 0.79286019]\n",
      " [0.72375096 0.74871309]\n",
      " [0.82291493 0.82055831]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.31195733]\n",
      " [0.32999838]\n",
      " [0.32809223]\n",
      " [0.34281372]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.57736295]\n",
      " [0.58175898]\n",
      " [0.58129512]\n",
      " [0.58487385]]\n",
      "Error [[-0.57736295]\n",
      " [ 0.41824102]\n",
      " [ 0.41870488]\n",
      " [-0.58487385]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22910026 0.91374023]\n",
      " [0.80218626 1.34207233]\n",
      " [0.96304114 1.09160461]\n",
      " [1.53612715 1.51993671]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55702586 0.71376492]\n",
      " [0.69044195 0.79283053]\n",
      " [0.72373028 0.74868376]\n",
      " [0.82290102 0.82052916]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.29688262]\n",
      " [0.31376407]\n",
      " [0.31195239]\n",
      " [0.3257337 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.57368027]\n",
      " [0.57780376]\n",
      " [0.57736175]\n",
      " [0.58072096]]\n",
      "Error [[-0.57368027]\n",
      " [ 0.42219624]\n",
      " [ 0.42263825]\n",
      " [-0.58072096]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2290113  0.91361607]\n",
      " [0.80210723 1.34191134]\n",
      " [0.96295228 1.09146708]\n",
      " [1.53604822 1.51976235]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55700391 0.71373955]\n",
      " [0.69042506 0.79280408]\n",
      " [0.72371251 0.74865788]\n",
      " [0.82288952 0.82050348]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.28251537]\n",
      " [0.2982935 ]\n",
      " [0.29657246]\n",
      " [0.30945898]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.57016279]\n",
      " [0.5740253 ]\n",
      " [0.57360441]\n",
      " [0.5767532 ]]\n",
      "Error [[-0.57016279]\n",
      " [ 0.4259747 ]\n",
      " [ 0.42639559]\n",
      " [-0.5767532 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22893315 0.9135049 ]\n",
      " [0.80204055 1.34176805]\n",
      " [0.96287632 1.09134606]\n",
      " [1.53598373 1.51960922]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55698462 0.71371684]\n",
      " [0.69041081 0.79278055]\n",
      " [0.72369732 0.74863511]\n",
      " [0.82288012 0.82048093]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.26882899]\n",
      " [0.28355796]\n",
      " [0.28192384]\n",
      " [0.2939593 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5668054 ]\n",
      " [0.57041829]\n",
      " [0.57001782]\n",
      " [0.57296516]]\n",
      "Error [[-0.5668054 ]\n",
      " [ 0.42958171]\n",
      " [ 0.42998218]\n",
      " [-0.57296516]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22886467 0.91340549]\n",
      " [0.80198471 1.34164074]\n",
      " [0.96281176 1.09123986]\n",
      " [1.5359318  1.51947512]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55696772 0.71369652]\n",
      " [0.69039887 0.79275963]\n",
      " [0.72368441 0.74861512]\n",
      " [0.82287255 0.82046118]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.25579691]\n",
      " [0.2695288 ]\n",
      " [0.26797803]\n",
      " [0.27920446]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5636028 ]\n",
      " [0.56697722]\n",
      " [0.56659645]\n",
      " [0.56935118]]\n",
      "Error [[-0.5636028 ]\n",
      " [ 0.43302278]\n",
      " [ 0.43340355]\n",
      " [-0.56935118]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22880482 0.91331671]\n",
      " [0.80193836 1.34152784]\n",
      " [0.96275722 1.09114692]\n",
      " [1.53589075 1.51935805]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55695296 0.71367839]\n",
      " [0.69038896 0.79274108]\n",
      " [0.72367351 0.74859763]\n",
      " [0.82286657 0.82044393]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.24339282]\n",
      " [0.25617757]\n",
      " [0.25470673]\n",
      " [0.26516448]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.56054959]\n",
      " [0.56369642]\n",
      " [0.56333465]\n",
      " [0.56590541]]\n",
      "Error [[-0.56054959]\n",
      " [ 0.43630358]\n",
      " [ 0.43666535]\n",
      " [-0.56590541]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22875267 0.91323755]\n",
      " [0.80190026 1.34142789]\n",
      " [0.96271147 1.09106583]\n",
      " [1.53585906 1.51925617]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55694009 0.71366221]\n",
      " [0.69038082 0.79272466]\n",
      " [0.72366436 0.74858237]\n",
      " [0.82286195 0.82042892]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.2315907 ]\n",
      " [0.24347623]\n",
      " [0.24208204]\n",
      " [0.25180978]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.55764028]\n",
      " [0.56057013]\n",
      " [0.56022667]\n",
      " [0.5626219 ]]\n",
      "Error [[-0.55764028]\n",
      " [ 0.43942987]\n",
      " [ 0.43977333]\n",
      " [-0.5626219 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22870735 0.91316705]\n",
      " [0.80186933 1.34133957]\n",
      " [0.96267338 1.0909953 ]\n",
      " [1.53583535 1.51916782]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55692891 0.7136478 ]\n",
      " [0.69037421 0.79271015]\n",
      " [0.72365674 0.7485691 ]\n",
      " [0.82285849 0.8204159 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.22036503]\n",
      " [0.23139719]\n",
      " [0.2300765 ]\n",
      " [0.23911131]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5548694 ]\n",
      " [0.55759255]\n",
      " [0.55726673]\n",
      " [0.55949463]]\n",
      "Error [[-0.5548694 ]\n",
      " [ 0.44240745]\n",
      " [ 0.44273327]\n",
      " [-0.55949463]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22866809 0.91310437]\n",
      " [0.80184456 1.34126169]\n",
      " [0.96264195 1.09093416]\n",
      " [1.53581842 1.51909148]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55691922 0.71363499]\n",
      " [0.69036891 0.79269735]\n",
      " [0.72365046 0.74855759]\n",
      " [0.82285602 0.82040466]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.2096908 ]\n",
      " [0.21991349]\n",
      " [0.21866329]\n",
      " [0.22704062]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.55223145]\n",
      " [0.55475787]\n",
      " [0.55444904]\n",
      " [0.55651758]]\n",
      "Error [[-0.55223145]\n",
      " [ 0.44524213]\n",
      " [ 0.44555096]\n",
      " [-0.55651758]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2286342  0.91304871]\n",
      " [0.80182509 1.34119314]\n",
      " [0.96261628 1.09088135]\n",
      " [1.53580717 1.51902578]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55691085 0.71362362]\n",
      " [0.69036475 0.79268608]\n",
      " [0.72364532 0.74854765]\n",
      " [0.82285438 0.82039498]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.19954364]\n",
      " [0.2089988 ]\n",
      " [0.2078162 ]\n",
      " [0.21556995]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.54972104]\n",
      " [0.55206034]\n",
      " [0.55176787]\n",
      " [0.55368475]]\n",
      "Error [[-0.54972104]\n",
      " [ 0.44793966]\n",
      " [ 0.44823213]\n",
      " [-0.55368475]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22860504 0.91299936]\n",
      " [0.80181012 1.34113294]\n",
      " [0.96259558 1.09083591]\n",
      " [1.53580066 1.51896949]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55690366 0.71361353]\n",
      " [0.69036155 0.79267619]\n",
      " [0.72364118 0.7485391 ]\n",
      " [0.82285344 0.82038668]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.18989984]\n",
      " [0.19862753]\n",
      " [0.19750979]\n",
      " [0.20467234]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5473328 ]\n",
      " [0.54949427]\n",
      " [0.54921755]\n",
      " [0.55099021]]\n",
      "Error [[-0.5473328 ]\n",
      " [ 0.45050573]\n",
      " [ 0.45078245]\n",
      " [-0.55099021]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22858005 0.91295569]\n",
      " [0.80179895 1.3410802 ]\n",
      " [0.96257912 1.09079699]\n",
      " [1.53579803 1.5189215 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55689749 0.71360461]\n",
      " [0.69035916 0.79266752]\n",
      " [0.72363789 0.74853177]\n",
      " [0.82285305 0.82037961]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.18073641]\n",
      " [0.18877488]\n",
      " [0.18771935]\n",
      " [0.19432162]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5450615 ]\n",
      " [0.54705407]\n",
      " [0.54679251]\n",
      " [0.54842811]]\n",
      "Error [[-0.5450615 ]\n",
      " [ 0.45294593]\n",
      " [ 0.45320749]\n",
      " [-0.54842811]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22855872 0.9129171 ]\n",
      " [0.80179098 1.34103409]\n",
      " [0.96256627 1.0907638 ]\n",
      " [1.53579853 1.51888079]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55689223 0.71359672]\n",
      " [0.69035746 0.79265995]\n",
      " [0.72363532 0.74852552]\n",
      " [0.82285312 0.82037361]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.17203111]\n",
      " [0.17941682]\n",
      " [0.17842101]\n",
      " [0.18449248]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.54290202]\n",
      " [0.54473427]\n",
      " [0.5444873 ]\n",
      " [0.54599274]]\n",
      "Error [[-0.54290202]\n",
      " [ 0.45526573]\n",
      " [ 0.4555127 ]\n",
      " [-0.54599274]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2285406  0.91288307]\n",
      " [0.80178565 1.3409939 ]\n",
      " [0.96255646 1.09073565]\n",
      " [1.53580151 1.51884647]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55688776 0.71358977]\n",
      " [0.69035632 0.79265334]\n",
      " [0.72363336 0.74852022]\n",
      " [0.82285356 0.82036855]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.16376247]\n",
      " [0.1705302 ]\n",
      " [0.16959171]\n",
      " [0.17516048]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.54084937]\n",
      " [0.54252953]\n",
      " [0.5422966 ]\n",
      " [0.5436785 ]]\n",
      "Error [[-0.54084937]\n",
      " [ 0.45747047]\n",
      " [ 0.4577034 ]\n",
      " [-0.5436785 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22852529 0.91285313]\n",
      " [0.80178248 1.34095895]\n",
      " [0.96254921 1.0907119 ]\n",
      " [1.5358064  1.51881772]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55688398 0.71358365]\n",
      " [0.69035564 0.7926476 ]\n",
      " [0.72363191 0.74851575]\n",
      " [0.82285427 0.82036432]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.15590982]\n",
      " [0.16209268]\n",
      " [0.16120924]\n",
      " [0.16630208]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.53889869]\n",
      " [0.54043468]\n",
      " [0.54021525]\n",
      " [0.54147997]]\n",
      "Error [[-0.53889869]\n",
      " [ 0.45956532]\n",
      " [ 0.45978475]\n",
      " [-0.54147997]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22851242 0.91282683]\n",
      " [0.80178105 1.34092866]\n",
      " [0.96254406 1.09069201]\n",
      " [1.53581269 1.51879384]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5568808  0.71357827]\n",
      " [0.69035534 0.79264262]\n",
      " [0.72363088 0.74851201]\n",
      " [0.82285519 0.8203608 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.14845325]\n",
      " [0.15408278]\n",
      " [0.15325221]\n",
      " [0.15789464]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5370453 ]\n",
      " [0.53844466]\n",
      " [0.53823824]\n",
      " [0.53939185]]\n",
      "Error [[-0.5370453 ]\n",
      " [ 0.46155534]\n",
      " [ 0.46176176]\n",
      " [-0.53939185]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22850167 0.9128038 ]\n",
      " [0.80178099 1.34090249]\n",
      " [0.96254065 1.09067547]\n",
      " [1.53581997 1.51877416]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55687815 0.71357356]\n",
      " [0.69035532 0.79263832]\n",
      " [0.7236302  0.74850889]\n",
      " [0.82285625 0.8203579 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.14137365]\n",
      " [0.14647987]\n",
      " [0.14570012]\n",
      " [0.14991639]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.53528466]\n",
      " [0.53655463]\n",
      " [0.53636073]\n",
      " [0.53740906]]\n",
      "Error [[-0.53528466]\n",
      " [ 0.46344537]\n",
      " [ 0.46363927]\n",
      " [-0.53740906]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22849276 0.91278368]\n",
      " [0.801782   1.34087996]\n",
      " [0.96253862 1.09066182]\n",
      " [1.53582786 1.51875811]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55687595 0.71356945]\n",
      " [0.69035554 0.79263461]\n",
      " [0.72362979 0.74850633]\n",
      " [0.8228574  0.82035553]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.1346527 ]\n",
      " [0.13926418]\n",
      " [0.13853327]\n",
      " [0.14234649]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5336124 ]\n",
      " [0.53475988]\n",
      " [0.53457804]\n",
      " [0.53552665]]\n",
      "Error [[-0.5336124 ]\n",
      " [ 0.46524012]\n",
      " [ 0.46542196]\n",
      " [-0.53552665]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22848543 0.91276615]\n",
      " [0.80178378 1.34086065]\n",
      " [0.96253769 1.09065068]\n",
      " [1.53583604 1.51874518]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55687414 0.71356587]\n",
      " [0.69035592 0.79263144]\n",
      " [0.72362961 0.74850423]\n",
      " [0.82285859 0.82035363]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.12827284]\n",
      " [0.13241674]\n",
      " [0.13173281]\n",
      " [0.13516494]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.53202431]\n",
      " [0.5330559 ]\n",
      " [0.53288566]\n",
      " [0.53373988]]\n",
      "Error [[-0.53202431]\n",
      " [ 0.4669441 ]\n",
      " [ 0.46711434]\n",
      " [-0.53373988]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22847946 0.91275093]\n",
      " [0.80178609 1.34084417]\n",
      " [0.9625376  1.09064168]\n",
      " [1.53584424 1.51873492]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55687267 0.71356276]\n",
      " [0.69035641 0.79262873]\n",
      " [0.72362959 0.74850254]\n",
      " [0.82285979 0.82035212]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.12221725]\n",
      " [0.12591941]\n",
      " [0.12528068]\n",
      " [0.12835261]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.53051634]\n",
      " [0.53143832]\n",
      " [0.53127927]\n",
      " [0.53204417]]\n",
      "Error [[-0.53051634]\n",
      " [ 0.46856168]\n",
      " [ 0.46872073]\n",
      " [-0.53204417]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22847465 0.91273778]\n",
      " [0.80178875 1.34083017]\n",
      " [0.96253814 1.09063452]\n",
      " [1.53585223 1.51872692]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55687148 0.71356007]\n",
      " [0.69035698 0.79262643]\n",
      " [0.7236297  0.74850119]\n",
      " [0.82286095 0.82035094]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.11646989]\n",
      " [0.11975484]\n",
      " [0.11915963]\n",
      " [0.12189121]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5290846 ]\n",
      " [0.52990298]\n",
      " [0.52975471]\n",
      " [0.53043513]]\n",
      "Error [[-0.5290846 ]\n",
      " [ 0.47009702]\n",
      " [ 0.47024529]\n",
      " [-0.53043513]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22847083 0.91272645]\n",
      " [0.80179156 1.34081835]\n",
      " [0.96253911 1.09062891]\n",
      " [1.53585984 1.51872081]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55687054 0.71355775]\n",
      " [0.69035758 0.79262449]\n",
      " [0.72362989 0.74850013]\n",
      " [0.82286206 0.82035004]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.1110154 ]\n",
      " [0.11390649]\n",
      " [0.11335318]\n",
      " [0.11576328]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.52772538]\n",
      " [0.52844587]\n",
      " [0.52830799]\n",
      " [0.52890854]]\n",
      "Error [[-0.52772538]\n",
      " [ 0.47155413]\n",
      " [ 0.47169201]\n",
      " [-0.52890854]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846784 0.91271674]\n",
      " [0.80179438 1.34080843]\n",
      " [0.96254035 1.09062461]\n",
      " [1.53586689 1.51871629]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5568698  0.71355577]\n",
      " [0.69035819 0.79262286]\n",
      " [0.72363014 0.74849932]\n",
      " [0.82286309 0.82034937]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.10583913]\n",
      " [0.10835852]\n",
      " [0.1078456 ]\n",
      " [0.10995213]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.52643511]\n",
      " [0.52706315]\n",
      " [0.5269353 ]\n",
      " [0.52746037]]\n",
      "Error [[-0.52643511]\n",
      " [ 0.47293685]\n",
      " [ 0.4730647 ]\n",
      " [-0.52746037]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846555 0.91270848]\n",
      " [0.8017971  1.34080017]\n",
      " [0.96254172 1.09062139]\n",
      " [1.53587327 1.51871308]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686924 0.71355408]\n",
      " [0.69035877 0.7926215 ]\n",
      " [0.72363041 0.74849872]\n",
      " [0.82286402 0.8203489 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.10092711]\n",
      " [0.10309586]\n",
      " [0.10262188]\n",
      " [0.10444187]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.52521038]\n",
      " [0.52575116]\n",
      " [0.52563298]\n",
      " [0.52608676]]\n",
      "Error [[-0.52521038]\n",
      " [ 0.47424884]\n",
      " [ 0.47436702]\n",
      " [-0.52608676]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846384 0.91270149]\n",
      " [0.80179959 1.34079335]\n",
      " [0.96254311 1.09061907]\n",
      " [1.53587886 1.51871093]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686882 0.71355265]\n",
      " [0.6903593  0.79262038]\n",
      " [0.72363069 0.74849828]\n",
      " [0.82286483 0.82034858]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.09626604]\n",
      " [0.09810413]\n",
      " [0.09766771]\n",
      " [0.09921733]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.52404794]\n",
      " [0.52450638]\n",
      " [0.52439754]\n",
      " [0.524784  ]]\n",
      "Error [[-0.52404794]\n",
      " [ 0.47549362]\n",
      " [ 0.47560246]\n",
      " [-0.524784  ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2284626  0.91269563]\n",
      " [0.80180179 1.34078778]\n",
      " [0.96254441 1.09061747]\n",
      " [1.5358836  1.51870962]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686851 0.71355146]\n",
      " [0.69035977 0.79261946]\n",
      " [0.72363095 0.74849798]\n",
      " [0.82286552 0.82034839]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.09184321]\n",
      " [0.09336963]\n",
      " [0.09296947]\n",
      " [0.09426406]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.52294468]\n",
      " [0.52332547]\n",
      " [0.52322564]\n",
      " [0.52354858]]\n",
      "Error [[-0.52294468]\n",
      " [ 0.47667453]\n",
      " [ 0.47677436]\n",
      " [-0.52354858]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846176 0.91269077]\n",
      " [0.80180362 1.34078328]\n",
      " [0.96254556 1.09061645]\n",
      " [1.53588742 1.51870896]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5568683  0.71355046]\n",
      " [0.69036016 0.79261872]\n",
      " [0.72363118 0.74849779]\n",
      " [0.82286608 0.82034829]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.08764654]\n",
      " [0.08887933]\n",
      " [0.08851418]\n",
      " [0.08956832]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.52189762]\n",
      " [0.52220522]\n",
      " [0.52211411]\n",
      " [0.52237712]]\n",
      "Error [[-0.52189762]\n",
      " [ 0.47779478]\n",
      " [ 0.47788589]\n",
      " [-0.52237712]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846122 0.91268678]\n",
      " [0.80180502 1.3407797 ]\n",
      " [0.96254647 1.09061587]\n",
      " [1.53589027 1.51870879]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686817 0.71354965]\n",
      " [0.69036046 0.79261813]\n",
      " [0.72363136 0.74849768]\n",
      " [0.8228665  0.82034827]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.08366455]\n",
      " [0.08462079]\n",
      " [0.08428949]\n",
      " [0.08511701]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.52090395]\n",
      " [0.52114258]\n",
      " [0.5210599 ]\n",
      " [0.52126641]]\n",
      "Error [[-0.52090395]\n",
      " [ 0.47885742]\n",
      " [ 0.4789401 ]\n",
      " [-0.52126641]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846092 0.91268357]\n",
      " [0.80180596 1.34077691]\n",
      " [0.9625471  1.09061563]\n",
      " [1.53589214 1.51870897]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686809 0.71354899]\n",
      " [0.69036066 0.79261767]\n",
      " [0.72363149 0.74849763]\n",
      " [0.82286677 0.82034829]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.07988628]\n",
      " [0.08058222]\n",
      " [0.08028364]\n",
      " [0.08089767]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.51996096]\n",
      " [0.52013466]\n",
      " [0.52006014]\n",
      " [0.52021339]]\n",
      "Error [[-0.51996096]\n",
      " [ 0.47986534]\n",
      " [ 0.47993986]\n",
      " [-0.52021339]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2284608  0.91268103]\n",
      " [0.8018064  1.34077478]\n",
      " [0.9625474  1.09061563]\n",
      " [1.535893   1.51870938]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686807 0.71354847]\n",
      " [0.69036075 0.79261733]\n",
      " [0.72363155 0.74849763]\n",
      " [0.82286689 0.82034835]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.07630134]\n",
      " [0.07675238]\n",
      " [0.07648547]\n",
      " [0.07689846]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.51906609]\n",
      " [0.51917868]\n",
      " [0.51911205]\n",
      " [0.51921515]]\n",
      "Error [[-0.51906609]\n",
      " [ 0.48082132]\n",
      " [ 0.48088795]\n",
      " [-0.51921515]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846082 0.9126791 ]\n",
      " [0.80180632 1.34077322]\n",
      " [0.96254735 1.09061577]\n",
      " [1.53589285 1.51870989]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686807 0.71354808]\n",
      " [0.69036074 0.79261707]\n",
      " [0.72363154 0.74849766]\n",
      " [0.82286687 0.82034843]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.07289983]\n",
      " [0.07312059]\n",
      " [0.07288434]\n",
      " [0.07310811]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.51821689]\n",
      " [0.51827201]\n",
      " [0.51821302]\n",
      " [0.51826889]]\n",
      "Error [[-0.51821689]\n",
      " [ 0.48172799]\n",
      " [ 0.48178698]\n",
      " [-0.51826889]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846093 0.91267768]\n",
      " [0.80180571 1.34077212]\n",
      " [0.96254691 1.09061598]\n",
      " [1.53589169 1.51871042]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5568681  0.71354779]\n",
      " [0.69036061 0.79261689]\n",
      " [0.72363145 0.7484977 ]\n",
      " [0.8228667  0.82034851]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.06967235]\n",
      " [0.0696767 ]\n",
      " [0.06947016]\n",
      " [0.06951592]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.51741105]\n",
      " [0.51741213]\n",
      " [0.51736056]\n",
      " [0.51737198]]\n",
      "Error [[-0.51741105]\n",
      " [ 0.48258787]\n",
      " [ 0.48263944]\n",
      " [-0.51737198]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846109 0.91267672]\n",
      " [0.80180455 1.34077141]\n",
      " [0.96254607 1.09061621]\n",
      " [1.53588954 1.5187109 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686814 0.71354759]\n",
      " [0.69036036 0.79261677]\n",
      " [0.72363128 0.74849774]\n",
      " [0.82286639 0.82034858]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.06660997]\n",
      " [0.06641106]\n",
      " [0.06623333]\n",
      " [0.06611171]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.51664634]\n",
      " [0.51659667]\n",
      " [0.51655228]\n",
      " [0.51652191]]\n",
      "Error [[-0.51664634]\n",
      " [ 0.48340333]\n",
      " [ 0.48344772]\n",
      " [-0.51652191]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846127 0.91267616]\n",
      " [0.80180286 1.34077102]\n",
      " [0.96254482 1.09061639]\n",
      " [1.53588641 1.51871125]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686818 0.71354748]\n",
      " [0.69036    0.79261671]\n",
      " [0.72363103 0.74849777]\n",
      " [0.82286594 0.82034863]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.06370419]\n",
      " [0.06331451]\n",
      " [0.06316472]\n",
      " [0.06288582]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.51592066]\n",
      " [0.51582334]\n",
      " [0.51578593]\n",
      " [0.51571628]]\n",
      "Error [[-0.51592066]\n",
      " [ 0.48417666]\n",
      " [ 0.48421407]\n",
      " [-0.51571628]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846145 0.91267594]\n",
      " [0.80180063 1.34077087]\n",
      " [0.96254316 1.09061648]\n",
      " [1.53588234 1.51871141]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686823 0.71354743]\n",
      " [0.69035952 0.79261668]\n",
      " [0.7236307  0.74849779]\n",
      " [0.82286534 0.82034865]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.06094696]\n",
      " [0.06037834]\n",
      " [0.06025569]\n",
      " [0.05982908]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.51523203]\n",
      " [0.51509   ]\n",
      " [0.51505937]\n",
      " [0.51495281]]\n",
      "Error [[-0.51523203]\n",
      " [ 0.48491   ]\n",
      " [ 0.48494063]\n",
      " [-0.51495281]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846161 0.91267601]\n",
      " [0.80179788 1.34077092]\n",
      " [0.96254109 1.09061644]\n",
      " [1.53587735 1.51871135]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686827 0.71354745]\n",
      " [0.69035893 0.79261669]\n",
      " [0.72363028 0.74849778]\n",
      " [0.82286461 0.82034864]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.05833063]\n",
      " [0.05759429]\n",
      " [0.05749801]\n",
      " [0.05693277]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.51457852]\n",
      " [0.51439459]\n",
      " [0.51437054]\n",
      " [0.51422935]]\n",
      "Error [[-0.51457852]\n",
      " [ 0.48560541]\n",
      " [ 0.48562946]\n",
      " [-0.51422935]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846173 0.91267634]\n",
      " [0.8017946  1.34077111]\n",
      " [0.9625386  1.09061624]\n",
      " [1.53587147 1.51871101]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5568683  0.71354751]\n",
      " [0.69035823 0.79261672]\n",
      " [0.72362979 0.74849775]\n",
      " [0.82286376 0.82034859]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.05584791]\n",
      " [0.05495452]\n",
      " [0.05488387]\n",
      " [0.0541886 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.51395835]\n",
      " [0.51373517]\n",
      " [0.51371752]\n",
      " [0.51354384]]\n",
      "Error [[-0.51395835]\n",
      " [ 0.48626483]\n",
      " [ 0.48628248]\n",
      " [-0.51354384]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846179 0.9126769 ]\n",
      " [0.80179083 1.34077141]\n",
      " [0.96253571 1.09061585]\n",
      " [1.53586474 1.51871036]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686831 0.71354763]\n",
      " [0.69035743 0.79261677]\n",
      " [0.72362921 0.74849767]\n",
      " [0.82286278 0.8203485 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.05349193]\n",
      " [0.05245157]\n",
      " [0.05240585]\n",
      " [0.05158873]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.51336979]\n",
      " [0.51310989]\n",
      " [0.51309847]\n",
      " [0.51289432]]\n",
      "Error [[-0.51336979]\n",
      " [ 0.48689011]\n",
      " [ 0.48690153]\n",
      " [-0.51289432]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846179 0.91267763]\n",
      " [0.80178657 1.34077178]\n",
      " [0.96253242 1.09061524]\n",
      " [1.5358572  1.51870939]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686831 0.71354778]\n",
      " [0.69035652 0.79261683]\n",
      " [0.72362855 0.74849756]\n",
      " [0.82286168 0.82034835]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.05125612]\n",
      " [0.05007837]\n",
      " [0.05005694]\n",
      " [0.04912569]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.51281122]\n",
      " [0.51251698]\n",
      " [0.51251162]\n",
      " [0.51227895]]\n",
      "Error [[-0.51281122]\n",
      " [ 0.48748302]\n",
      " [ 0.48748838]\n",
      " [-0.51227895]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846172 0.91267853]\n",
      " [0.80178185 1.34077218]\n",
      " [0.96252875 1.09061441]\n",
      " [1.53584888 1.51870806]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686829 0.71354796]\n",
      " [0.69035551 0.7926169 ]\n",
      " [0.72362782 0.7484974 ]\n",
      " [0.82286046 0.82034816]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.04913427]\n",
      " [0.04782822]\n",
      " [0.04783044]\n",
      " [0.04679242]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5122811 ]\n",
      " [0.51195478]\n",
      " [0.51195533]\n",
      " [0.51169597]]\n",
      "Error [[-0.5122811 ]\n",
      " [ 0.48804522]\n",
      " [ 0.48804467]\n",
      " [-0.51169597]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846156 0.91267956]\n",
      " [0.80177668 1.34077259]\n",
      " [0.96252472 1.09061332]\n",
      " [1.53583984 1.51870636]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686825 0.71354817]\n",
      " [0.6903544  0.79261697]\n",
      " [0.72362701 0.7484972 ]\n",
      " [0.82285915 0.82034791]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.04712048]\n",
      " [0.04569474]\n",
      " [0.04572002]\n",
      " [0.04458219]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.51177794]\n",
      " [0.5114217 ]\n",
      " [0.51142802]\n",
      " [0.5111437 ]]\n",
      "Error [[-0.51177794]\n",
      " [ 0.4885783 ]\n",
      " [ 0.48857198]\n",
      " [-0.5111437 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846132 0.9126807 ]\n",
      " [0.80177109 1.34077299]\n",
      " [0.96252033 1.09061199]\n",
      " [1.53583011 1.51870428]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686819 0.7135484 ]\n",
      " [0.69035321 0.79261703]\n",
      " [0.72362613 0.74849694]\n",
      " [0.82285773 0.8203476 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.04520917]\n",
      " [0.0436719 ]\n",
      " [0.04371968]\n",
      " [0.04248863]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.51130037]\n",
      " [0.51091624]\n",
      " [0.51092818]\n",
      " [0.51062056]]\n",
      "Error [[-0.51130037]\n",
      " [ 0.48908376]\n",
      " [ 0.48907182]\n",
      " [-0.51062056]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846099 0.91268193]\n",
      " [0.8017651  1.34077336]\n",
      " [0.96251561 1.09061038]\n",
      " [1.53581973 1.5187018 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686811 0.71354866]\n",
      " [0.69035193 0.79261709]\n",
      " [0.72362519 0.74849664]\n",
      " [0.82285621 0.82034724]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.04339501]\n",
      " [0.04175395]\n",
      " [0.04182371]\n",
      " [0.0405057 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.51084705]\n",
      " [0.51043697]\n",
      " [0.5104544 ]\n",
      " [0.51012504]]\n",
      "Error [[-0.51084705]\n",
      " [ 0.48956303]\n",
      " [ 0.4895456 ]\n",
      " [-0.51012504]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846056 0.91268324]\n",
      " [0.80175874 1.34077367]\n",
      " [0.96251057 1.0906085 ]\n",
      " [1.53580874 1.51869894]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686801 0.71354892]\n",
      " [0.69035057 0.79261714]\n",
      " [0.72362418 0.74849629]\n",
      " [0.82285461 0.82034681]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.04167298]\n",
      " [0.03993547]\n",
      " [0.0400267 ]\n",
      " [0.03862766]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.51041674]\n",
      " [0.50998254]\n",
      " [0.51000534]\n",
      " [0.50965572]]\n",
      "Error [[-0.51041674]\n",
      " [ 0.49001746]\n",
      " [ 0.48999466]\n",
      " [-0.50965572]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846005 0.9126846 ]\n",
      " [0.80175202 1.34077392]\n",
      " [0.96250523 1.09060635]\n",
      " [1.5357972  1.51869567]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686788 0.7135492 ]\n",
      " [0.69034913 0.79261718]\n",
      " [0.72362311 0.74849588]\n",
      " [0.82285293 0.82034633]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0400383 ]\n",
      " [0.0382113 ]\n",
      " [0.03832351]\n",
      " [0.03684908]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.51000824]\n",
      " [0.50955166]\n",
      " [0.50957971]\n",
      " [0.50921123]]\n",
      "Error [[-0.51000824]\n",
      " [ 0.49044834]\n",
      " [ 0.49042029]\n",
      " [-0.50921123]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22845946 0.91268601]\n",
      " [0.80174498 1.34077409]\n",
      " [0.96249961 1.09060393]\n",
      " [1.53578514 1.51869201]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686773 0.71354949]\n",
      " [0.69034763 0.79261721]\n",
      " [0.72362199 0.74849543]\n",
      " [0.82285117 0.82034579]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.03848644]\n",
      " [0.03657654]\n",
      " [0.03670929]\n",
      " [0.03516479]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50962042]\n",
      " [0.50914312]\n",
      " [0.50917629]\n",
      " [0.50879029]]\n",
      "Error [[-0.50962042]\n",
      " [ 0.49085688]\n",
      " [ 0.49082371]\n",
      " [-0.50879029]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22845877 0.91268746]\n",
      " [0.80173764 1.34077418]\n",
      " [0.96249374 1.09060122]\n",
      " [1.53577261 1.51868794]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686756 0.71354979]\n",
      " [0.69034606 0.79261723]\n",
      " [0.72362081 0.74849492]\n",
      " [0.82284935 0.82034519]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.03701309]\n",
      " [0.03502655]\n",
      " [0.03517941]\n",
      " [0.0335699 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50925222]\n",
      " [0.50875574]\n",
      " [0.50879395]\n",
      " [0.50839169]]\n",
      "Error [[-0.50925222]\n",
      " [ 0.49124426]\n",
      " [ 0.49120605]\n",
      " [-0.50839169]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.228458   0.91268893]\n",
      " [0.80173002 1.34077417]\n",
      " [0.96248762 1.09059824]\n",
      " [1.53575964 1.51868349]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686737 0.71355009]\n",
      " [0.69034443 0.79261723]\n",
      " [0.72361959 0.74849436]\n",
      " [0.82284746 0.82034454]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.03561418]\n",
      " [0.03355694]\n",
      " [0.03372949]\n",
      " [0.03205977]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5089026 ]\n",
      " [0.50838845]\n",
      " [0.50843157]\n",
      " [0.50801426]]\n",
      "Error [[-0.5089026 ]\n",
      " [ 0.49161155]\n",
      " [ 0.49156843]\n",
      " [-0.50801426]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22845715 0.91269042]\n",
      " [0.80172215 1.34077407]\n",
      " [0.96248128 1.09059499]\n",
      " [1.53574628 1.51867864]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686716 0.71355039]\n",
      " [0.69034274 0.79261721]\n",
      " [0.72361832 0.74849375]\n",
      " [0.82284551 0.82034382]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.03428585]\n",
      " [0.03216352]\n",
      " [0.03235538]\n",
      " [0.03062999]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50857062]\n",
      " [0.50804019]\n",
      " [0.50808814]\n",
      " [0.5076569 ]]\n",
      "Error [[-0.50857062]\n",
      " [ 0.49195981]\n",
      " [ 0.49191186]\n",
      " [-0.5076569 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22845621 0.91269191]\n",
      " [0.80171404 1.34077386]\n",
      " [0.96247473 1.09059146]\n",
      " [1.53573256 1.51867341]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686693 0.7135507 ]\n",
      " [0.69034101 0.79261717]\n",
      " [0.72361701 0.74849308]\n",
      " [0.82284351 0.82034305]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.03302444]\n",
      " [0.03084234]\n",
      " [0.03105315]\n",
      " [0.02927639]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50825536]\n",
      " [0.50770997]\n",
      " [0.50776266]\n",
      " [0.50731857]]\n",
      "Error [[-0.50825536]\n",
      " [ 0.49229003]\n",
      " [ 0.49223734]\n",
      " [-0.50731857]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22845521 0.91269341]\n",
      " [0.80170573 1.34077354]\n",
      " [0.96246801 1.09058767]\n",
      " [1.53571853 1.5186678 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686669 0.713551  ]\n",
      " [0.69033923 0.79261712]\n",
      " [0.72361567 0.74849237]\n",
      " [0.82284146 0.82034222]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.03182645]\n",
      " [0.02958964]\n",
      " [0.02981905]\n",
      " [0.02799501]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50795594]\n",
      " [0.50739687]\n",
      " [0.50745421]\n",
      " [0.5069983 ]]\n",
      "Error [[-0.50795594]\n",
      " [ 0.49260313]\n",
      " [ 0.49254579]\n",
      " [-0.5069983 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22845413 0.9126949 ]\n",
      " [0.80169723 1.34077311]\n",
      " [0.96246112 1.09058362]\n",
      " [1.53570422 1.51866182]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686642 0.71355131]\n",
      " [0.69033742 0.79261705]\n",
      " [0.72361429 0.74849161]\n",
      " [0.82283938 0.82034134]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.03068861]\n",
      " [0.02840187]\n",
      " [0.02864955]\n",
      " [0.0267821 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50767155]\n",
      " [0.50709999]\n",
      " [0.5071619 ]\n",
      " [0.50669513]]\n",
      "Error [[-0.50767155]\n",
      " [ 0.49290001]\n",
      " [ 0.4928381 ]\n",
      " [-0.50669513]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22845298 0.91269639]\n",
      " [0.80168857 1.34077256]\n",
      " [0.96245408 1.09057931]\n",
      " [1.53568966 1.51865548]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686614 0.71355161]\n",
      " [0.69033557 0.79261696]\n",
      " [0.72361288 0.74849079]\n",
      " [0.82283726 0.82034041]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.02960778]\n",
      " [0.02727566]\n",
      " [0.02754129]\n",
      " [0.0256341 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5074014 ]\n",
      " [0.50681849]\n",
      " [0.50688489]\n",
      " [0.50640818]]\n",
      "Error [[-0.5074014 ]\n",
      " [ 0.49318151]\n",
      " [ 0.49311511]\n",
      " [-0.50640818]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22845178 0.91269787]\n",
      " [0.80167977 1.34077191]\n",
      " [0.96244691 1.09057475]\n",
      " [1.53567491 1.51864879]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686584 0.71355191]\n",
      " [0.69033369 0.79261685]\n",
      " [0.72361145 0.74848994]\n",
      " [0.8228351  0.82033942]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.02858099]\n",
      " [0.02620779]\n",
      " [0.02649109]\n",
      " [0.02454764]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50714476]\n",
      " [0.50655157]\n",
      " [0.50662238]\n",
      " [0.5061366 ]]\n",
      "Error [[-0.50714476]\n",
      " [ 0.49344843]\n",
      " [ 0.49337762]\n",
      " [-0.5061366 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22845051 0.91269933]\n",
      " [0.80167085 1.34077113]\n",
      " [0.96243964 1.09056995]\n",
      " [1.53565998 1.51864176]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686553 0.71355221]\n",
      " [0.69033178 0.79261673]\n",
      " [0.72361    0.74848903]\n",
      " [0.82283293 0.82033839]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.02760545]\n",
      " [0.02519524]\n",
      " [0.02549592]\n",
      " [0.02351951]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50690092]\n",
      " [0.50629848]\n",
      " [0.50637363]\n",
      " [0.50587961]]\n",
      "Error [[-0.50690092]\n",
      " [ 0.49370152]\n",
      " [ 0.49362637]\n",
      " [-0.50587961]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2284492  0.91270077]\n",
      " [0.80166183 1.34077025]\n",
      " [0.96243227 1.09056491]\n",
      " [1.53564491 1.51863439]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5568652  0.71355251]\n",
      " [0.69032985 0.79261658]\n",
      " [0.72360852 0.74848808]\n",
      " [0.82283073 0.8203373 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.02667848]\n",
      " [0.02423514]\n",
      " [0.02455293]\n",
      " [0.02254667]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50666922]\n",
      " [0.50605849]\n",
      " [0.50613792]\n",
      " [0.50563643]]\n",
      "Error [[-0.50666922]\n",
      " [ 0.49394151]\n",
      " [ 0.49386208]\n",
      " [-0.50563643]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22844783 0.91270219]\n",
      " [0.80165273 1.34076925]\n",
      " [0.96242483 1.09055964]\n",
      " [1.53562973 1.5186267 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686487 0.7135528 ]\n",
      " [0.69032791 0.79261642]\n",
      " [0.72360703 0.74848709]\n",
      " [0.82282852 0.82033617]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.02579756]\n",
      " [0.02332474]\n",
      " [0.02365939]\n",
      " [0.02162626]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50644903]\n",
      " [0.50583092]\n",
      " [0.50591457]\n",
      " [0.50540636]]\n",
      "Error [[-0.50644903]\n",
      " [ 0.49416908]\n",
      " [ 0.49408543]\n",
      " [-0.50540636]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22844642 0.91270359]\n",
      " [0.80164357 1.34076814]\n",
      " [0.96241732 1.09055414]\n",
      " [1.53561447 1.51861869]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686452 0.71355308]\n",
      " [0.69032595 0.79261623]\n",
      " [0.72360553 0.74848606]\n",
      " [0.82282629 0.82033499]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.02496029]\n",
      " [0.02246147]\n",
      " [0.02281275]\n",
      " [0.02075555]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50623975]\n",
      " [0.50561513]\n",
      " [0.50570294]\n",
      " [0.5051887 ]]\n",
      "Error [[-0.50623975]\n",
      " [ 0.49438487]\n",
      " [ 0.49429706]\n",
      " [-0.5051887 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22844498 0.91270497]\n",
      " [0.80163437 1.34076692]\n",
      " [0.96240978 1.09054842]\n",
      " [1.53559917 1.51861038]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686416 0.71355336]\n",
      " [0.69032398 0.79261603]\n",
      " [0.72360402 0.74848498]\n",
      " [0.82282406 0.82033376]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.02416441]\n",
      " [0.02164288]\n",
      " [0.02201055]\n",
      " [0.01993195]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50604081]\n",
      " [0.50541051]\n",
      " [0.50550241]\n",
      " [0.50498282]]\n",
      "Error [[-0.50604081]\n",
      " [ 0.49458949]\n",
      " [ 0.49449759]\n",
      " [-0.50498282]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2284435  0.91270632]\n",
      " [0.80162515 1.3407656 ]\n",
      " [0.9624022  1.09054249]\n",
      " [1.53558385 1.51860177]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5568638  0.71355364]\n",
      " [0.69032201 0.79261582]\n",
      " [0.72360251 0.74848386]\n",
      " [0.82282183 0.82033249]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.02340775]\n",
      " [0.02086664]\n",
      " [0.02125049]\n",
      " [0.019153  ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50585167]\n",
      " [0.50521647]\n",
      " [0.50531242]\n",
      " [0.5047881 ]]\n",
      "Error [[-0.50585167]\n",
      " [ 0.49478353]\n",
      " [ 0.49468758]\n",
      " [-0.5047881 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22844199 0.91270765]\n",
      " [0.80161592 1.34076416]\n",
      " [0.96239461 1.09053636]\n",
      " [1.53556854 1.51859288]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686342 0.71355391]\n",
      " [0.69032004 0.79261558]\n",
      " [0.72360099 0.74848271]\n",
      " [0.8228196  0.82033118]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.02268829]\n",
      " [0.02013054]\n",
      " [0.02053037]\n",
      " [0.01841639]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50567183]\n",
      " [0.50503247]\n",
      " [0.50513241]\n",
      " [0.50460397]]\n",
      "Error [[-0.50567183]\n",
      " [ 0.49496753]\n",
      " [ 0.49486759]\n",
      " [-0.50460397]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22844045 0.91270895]\n",
      " [0.80160669 1.34076263]\n",
      " [0.96238701 1.09053003]\n",
      " [1.53555325 1.51858371]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686304 0.71355418]\n",
      " [0.69031806 0.79261533]\n",
      " [0.72359947 0.74848152]\n",
      " [0.82281737 0.82032983]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.02200408]\n",
      " [0.0194325 ]\n",
      " [0.01984811]\n",
      " [0.01771991]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5055008 ]\n",
      " [0.50485797]\n",
      " [0.50496186]\n",
      " [0.50442986]]\n",
      "Error [[-0.5055008 ]\n",
      " [ 0.49514203]\n",
      " [ 0.49503814]\n",
      " [-0.50442986]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22843889 0.91271023]\n",
      " [0.80159749 1.34076099]\n",
      " [0.96237943 1.09052351]\n",
      " [1.53553803 1.51857427]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686266 0.71355444]\n",
      " [0.6903161  0.79261506]\n",
      " [0.72359795 0.74848029]\n",
      " [0.82281515 0.82032844]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.02135329]\n",
      " [0.01877054]\n",
      " [0.01920175]\n",
      " [0.01706147]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50533812]\n",
      " [0.5046925 ]\n",
      " [0.50480029]\n",
      " [0.50426526]]\n",
      "Error [[-0.50533812]\n",
      " [ 0.4953075 ]\n",
      " [ 0.49519971]\n",
      " [-0.50426526]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22843732 0.91271148]\n",
      " [0.80158833 1.34075925]\n",
      " [0.96237188 1.0905168 ]\n",
      " [1.53552289 1.51856458]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686227 0.71355469]\n",
      " [0.69031414 0.79261477]\n",
      " [0.72359644 0.74847903]\n",
      " [0.82281294 0.82032701]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.02073418]\n",
      " [0.01814278]\n",
      " [0.01858941]\n",
      " [0.01643909]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50518336]\n",
      " [0.50453557]\n",
      " [0.50464722]\n",
      " [0.50410968]]\n",
      "Error [[-0.50518336]\n",
      " [ 0.49546443]\n",
      " [ 0.49535278]\n",
      " [-0.50410968]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22843573 0.9127127 ]\n",
      " [0.80157923 1.34075742]\n",
      " [0.96236436 1.09050992]\n",
      " [1.53550785 1.51855464]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686188 0.71355494]\n",
      " [0.69031219 0.79261447]\n",
      " [0.72359494 0.74847773]\n",
      " [0.82281075 0.82032554]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.02014511]\n",
      " [0.01754744]\n",
      " [0.01800933]\n",
      " [0.0158509 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50503611]\n",
      " [0.50438675]\n",
      " [0.50450221]\n",
      " [0.50396264]]\n",
      "Error [[-0.50503611]\n",
      " [ 0.49561325]\n",
      " [ 0.49549779]\n",
      " [-0.50396264]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22843414 0.9127139 ]\n",
      " [0.80157019 1.3407555 ]\n",
      " [0.96235689 1.09050286]\n",
      " [1.53549294 1.51854446]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686149 0.71355519]\n",
      " [0.69031026 0.79261416]\n",
      " [0.72359345 0.7484764 ]\n",
      " [0.82280858 0.82032404]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01958451]\n",
      " [0.01698283]\n",
      " [0.01745983]\n",
      " [0.01529512]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50489597]\n",
      " [0.5042456 ]\n",
      " [0.50436485]\n",
      " [0.5038237 ]]\n",
      "Error [[-0.50489597]\n",
      " [ 0.4957544 ]\n",
      " [ 0.49563515]\n",
      " [-0.5038237 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22843254 0.91271507]\n",
      " [0.80156123 1.34075348]\n",
      " [0.96234948 1.09049564]\n",
      " [1.53547817 1.51853405]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686109 0.71355543]\n",
      " [0.69030834 0.79261382]\n",
      " [0.72359196 0.74847504]\n",
      " [0.82280642 0.82032251]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01905089]\n",
      " [0.01644735]\n",
      " [0.0169393 ]\n",
      " [0.01477005]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50476258]\n",
      " [0.50411174]\n",
      " [0.50423472]\n",
      " [0.50369244]]\n",
      "Error [[-0.50476258]\n",
      " [ 0.49588826]\n",
      " [ 0.49576528]\n",
      " [-0.50369244]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22843094 0.91271622]\n",
      " [0.80155236 1.34075138]\n",
      " [0.96234215 1.09048825]\n",
      " [1.53546357 1.51852342]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5568607  0.71355566]\n",
      " [0.69030645 0.79261348]\n",
      " [0.7235905  0.74847365]\n",
      " [0.82280429 0.82032094]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01854286]\n",
      " [0.01593949]\n",
      " [0.01644626]\n",
      " [0.0142741 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50463558]\n",
      " [0.50398479]\n",
      " [0.50411147]\n",
      " [0.50356846]]\n",
      "Error [[-0.50463558]\n",
      " [ 0.49601521]\n",
      " [ 0.49588853]\n",
      " [-0.50356846]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22842934 0.91271734]\n",
      " [0.8015436  1.34074919]\n",
      " [0.96233489 1.09048072]\n",
      " [1.53544915 1.51851257]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5568603  0.71355589]\n",
      " [0.69030458 0.79261312]\n",
      " [0.72358905 0.74847223]\n",
      " [0.82280219 0.82031934]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01805908]\n",
      " [0.0154578 ]\n",
      " [0.01597926]\n",
      " [0.01380575]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50451465]\n",
      " [0.50386437]\n",
      " [0.50399473]\n",
      " [0.50345138]]\n",
      "Error [[-0.50451465]\n",
      " [ 0.49613563]\n",
      " [ 0.49600527]\n",
      " [-0.50345138]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22842775 0.91271843]\n",
      " [0.80153496 1.34074692]\n",
      " [0.96232773 1.09047303]\n",
      " [1.53543494 1.51850152]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685991 0.71355612]\n",
      " [0.69030273 0.79261275]\n",
      " [0.72358761 0.74847079]\n",
      " [0.82280012 0.82031772]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01759829]\n",
      " [0.01500093]\n",
      " [0.01553695]\n",
      " [0.01336357]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50439946]\n",
      " [0.50375016]\n",
      " [0.50388416]\n",
      " [0.50334084]]\n",
      "Error [[-0.50439946]\n",
      " [ 0.49624984]\n",
      " [ 0.49611584]\n",
      " [-0.50334084]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22842617 0.91271951]\n",
      " [0.80152644 1.34074457]\n",
      " [0.96232067 1.0904652 ]\n",
      " [1.53542094 1.51849027]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685952 0.71355634]\n",
      " [0.69030091 0.79261236]\n",
      " [0.7235862  0.74846931]\n",
      " [0.82279808 0.82031606]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0171593 ]\n",
      " [0.01456759]\n",
      " [0.01511804]\n",
      " [0.01294619]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50428972]\n",
      " [0.50364183]\n",
      " [0.50377944]\n",
      " [0.5032365 ]]\n",
      "Error [[-0.50428972]\n",
      " [ 0.49635817]\n",
      " [ 0.49622056]\n",
      " [-0.5032365 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2284246  0.91272056]\n",
      " [0.80151807 1.34074215]\n",
      " [0.96231372 1.09045723]\n",
      " [1.53540718 1.51847883]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685913 0.71355655]\n",
      " [0.69029912 0.79261196]\n",
      " [0.72358481 0.74846781]\n",
      " [0.82279607 0.82031437]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01674097]\n",
      " [0.01415655]\n",
      " [0.01472132]\n",
      " [0.01255232]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50418514]\n",
      " [0.50353908]\n",
      " [0.50368026]\n",
      " [0.50313804]]\n",
      "Error [[-0.50418514]\n",
      " [ 0.49646092]\n",
      " [ 0.49631974]\n",
      " [-0.50313804]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22842304 0.91272158]\n",
      " [0.80150983 1.34073965]\n",
      " [0.96230689 1.09044913]\n",
      " [1.53539368 1.5184672 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685875 0.71355676]\n",
      " [0.69029736 0.79261155]\n",
      " [0.72358344 0.74846629]\n",
      " [0.8227941  0.82031266]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01634222]\n",
      " [0.01376664]\n",
      " [0.01434563]\n",
      " [0.01218074]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50408546]\n",
      " [0.50344161]\n",
      " [0.50358635]\n",
      " [0.50304515]]\n",
      "Error [[-0.50408546]\n",
      " [ 0.49655839]\n",
      " [ 0.49641365]\n",
      " [-0.50304515]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22842151 0.91272258]\n",
      " [0.80150176 1.34073708]\n",
      " [0.96230018 1.09044091]\n",
      " [1.53538043 1.5184554 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685837 0.71355696]\n",
      " [0.69029563 0.79261113]\n",
      " [0.7235821  0.74846474]\n",
      " [0.82279217 0.82031092]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01596204]\n",
      " [0.01339677]\n",
      " [0.01398987]\n",
      " [0.01183028]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50399042]\n",
      " [0.50334914]\n",
      " [0.50349741]\n",
      " [0.50295754]]\n",
      "Error [[-0.50399042]\n",
      " [ 0.49665086]\n",
      " [ 0.49650259]\n",
      " [-0.50295754]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22841999 0.91272357]\n",
      " [0.80149385 1.34073444]\n",
      " [0.96229361 1.09043255]\n",
      " [1.53536747 1.51844343]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.556858   0.71355717]\n",
      " [0.69029394 0.79261069]\n",
      " [0.72358079 0.74846317]\n",
      " [0.82279028 0.82030915]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01559946]\n",
      " [0.0130459 ]\n",
      " [0.01365301]\n",
      " [0.01149985]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50389978]\n",
      " [0.50326143]\n",
      " [0.5034132 ]\n",
      " [0.50287493]]\n",
      "Error [[-0.50389978]\n",
      " [ 0.49673857]\n",
      " [ 0.4965868 ]\n",
      " [-0.50287493]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2284185  0.91272453]\n",
      " [0.80148612 1.34073174]\n",
      " [0.96228718 1.09042409]\n",
      " [1.5353548  1.5184313 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685763 0.71355736]\n",
      " [0.69029229 0.79261025]\n",
      " [0.7235795  0.74846157]\n",
      " [0.82278843 0.82030736]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01525356]\n",
      " [0.01271303]\n",
      " [0.01333407]\n",
      " [0.01118841]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50381332]\n",
      " [0.50317821]\n",
      " [0.50333347]\n",
      " [0.50279707]]\n",
      "Error [[-0.50381332]\n",
      " [ 0.49682179]\n",
      " [ 0.49666653]\n",
      " [-0.50279707]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22841704 0.91272547]\n",
      " [0.80147857 1.34072897]\n",
      " [0.9622809  1.0904155 ]\n",
      " [1.53534243 1.518419  ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685727 0.71355755]\n",
      " [0.69029067 0.79260979]\n",
      " [0.72357825 0.74845996]\n",
      " [0.82278663 0.82030555]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01492347]\n",
      " [0.01239723]\n",
      " [0.01303211]\n",
      " [0.01089496]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5037308 ]\n",
      " [0.50309927]\n",
      " [0.50325798]\n",
      " [0.50272371]]\n",
      "Error [[-0.5037308 ]\n",
      " [ 0.49690073]\n",
      " [ 0.49674202]\n",
      " [-0.50272371]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2284156  0.91272639]\n",
      " [0.8014712  1.34072614]\n",
      " [0.96227478 1.09040681]\n",
      " [1.53533038 1.51840656]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685691 0.71355774]\n",
      " [0.6902891  0.79260933]\n",
      " [0.72357702 0.74845832]\n",
      " [0.82278487 0.82030372]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01460838]\n",
      " [0.01209761]\n",
      " [0.01274624]\n",
      " [0.01061856]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50365203]\n",
      " [0.50302437]\n",
      " [0.50318652]\n",
      " [0.50265462]]\n",
      "Error [[-0.50365203]\n",
      " [ 0.49697563]\n",
      " [ 0.49681348]\n",
      " [-0.50265462]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2284142  0.91272729]\n",
      " [0.80146404 1.34072325]\n",
      " [0.96226882 1.09039801]\n",
      " [1.53531866 1.51839397]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685657 0.71355793]\n",
      " [0.69028757 0.79260885]\n",
      " [0.72357583 0.74845666]\n",
      " [0.82278317 0.82030186]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01430751]\n",
      " [0.01181333]\n",
      " [0.01247564]\n",
      " [0.01035834]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50357682]\n",
      " [0.5029533 ]\n",
      " [0.50311887]\n",
      " [0.50258956]]\n",
      "Error [[-0.50357682]\n",
      " [ 0.4970467 ]\n",
      " [ 0.49688113]\n",
      " [-0.50258956]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22841282 0.91272818]\n",
      " [0.80145708 1.34072031]\n",
      " [0.96226302 1.09038911]\n",
      " [1.53530728 1.51838124]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685623 0.71355811]\n",
      " [0.69028608 0.79260837]\n",
      " [0.72357467 0.74845499]\n",
      " [0.82278151 0.82029999]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0140201 ]\n",
      " [0.01154359]\n",
      " [0.01221949]\n",
      " [0.01011345]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50350497]\n",
      " [0.50288586]\n",
      " [0.50305484]\n",
      " [0.50252834]]\n",
      "Error [[-0.50350497]\n",
      " [ 0.49711414]\n",
      " [ 0.49694516]\n",
      " [-0.50252834]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22841149 0.91272905]\n",
      " [0.80145033 1.34071731]\n",
      " [0.9622574  1.09038012]\n",
      " [1.53529624 1.51836838]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5568559  0.71355829]\n",
      " [0.69028464 0.79260788]\n",
      " [0.72357355 0.74845329]\n",
      " [0.8227799  0.82029809]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01374547]\n",
      " [0.01128763]\n",
      " [0.01197706]\n",
      " [0.00988308]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50343631]\n",
      " [0.50282188]\n",
      " [0.50299423]\n",
      " [0.50247075]]\n",
      "Error [[-0.50343631]\n",
      " [ 0.49717812]\n",
      " [ 0.49700577]\n",
      " [-0.50247075]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22841019 0.9127299 ]\n",
      " [0.8014438  1.34071425]\n",
      " [0.96225196 1.09037103]\n",
      " [1.53528557 1.51835538]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685558 0.71355846]\n",
      " [0.69028324 0.79260738]\n",
      " [0.72357246 0.74845158]\n",
      " [0.82277834 0.82029617]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01348295]\n",
      " [0.01104473]\n",
      " [0.01174763]\n",
      " [0.00966648]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50337069]\n",
      " [0.50276116]\n",
      " [0.50293687]\n",
      " [0.5024166 ]]\n",
      "Error [[-0.50337069]\n",
      " [ 0.49723884]\n",
      " [ 0.49706313]\n",
      " [-0.5024166 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22840892 0.91273073]\n",
      " [0.80143749 1.34071115]\n",
      " [0.9622467  1.09036184]\n",
      " [1.53527526 1.51834226]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685526 0.71355863]\n",
      " [0.69028189 0.79260687]\n",
      " [0.72357141 0.74844985]\n",
      " [0.82277684 0.82029424]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0132319 ]\n",
      " [0.01081422]\n",
      " [0.01153052]\n",
      " [0.00946294]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50330793]\n",
      " [0.50270353]\n",
      " [0.5028826 ]\n",
      " [0.50236572]]\n",
      "Error [[-0.50330793]\n",
      " [ 0.49729647]\n",
      " [ 0.4971174 ]\n",
      " [-0.50236572]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2284077  0.91273155]\n",
      " [0.8014314  1.340708  ]\n",
      " [0.96224163 1.09035257]\n",
      " [1.53526533 1.51832902]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685496 0.7135588 ]\n",
      " [0.69028059 0.79260635]\n",
      " [0.72357039 0.74844811]\n",
      " [0.82277539 0.82029229]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01299173]\n",
      " [0.01059545]\n",
      " [0.01132509]\n",
      " [0.00927178]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50324789]\n",
      " [0.50264884]\n",
      " [0.50283124]\n",
      " [0.50231793]]\n",
      "Error [[-0.50324789]\n",
      " [ 0.49735116]\n",
      " [ 0.49716876]\n",
      " [-0.50231793]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22840653 0.91273235]\n",
      " [0.80142555 1.3407048 ]\n",
      " [0.96223675 1.09034322]\n",
      " [1.53525578 1.51831566]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685467 0.71355896]\n",
      " [0.69027934 0.79260582]\n",
      " [0.72356942 0.74844635]\n",
      " [0.822774   0.82029032]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01276188]\n",
      " [0.01038781]\n",
      " [0.01113073]\n",
      " [0.00909235]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50319043]\n",
      " [0.50259693]\n",
      " [0.50278265]\n",
      " [0.50227307]]\n",
      "Error [[-0.50319043]\n",
      " [ 0.49740307]\n",
      " [ 0.49721735]\n",
      " [-0.50227307]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22840539 0.91273315]\n",
      " [0.80141994 1.34070155]\n",
      " [0.96223207 1.09033378]\n",
      " [1.53524662 1.51830219]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685439 0.71355912]\n",
      " [0.69027814 0.79260529]\n",
      " [0.72356848 0.74844457]\n",
      " [0.82277266 0.82028833]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0125418 ]\n",
      " [0.01019072]\n",
      " [0.01094687]\n",
      " [0.00892403]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50313541]\n",
      " [0.50254766]\n",
      " [0.50273669]\n",
      " [0.50223099]]\n",
      "Error [[-0.50313541]\n",
      " [ 0.49745234]\n",
      " [ 0.49726331]\n",
      " [-0.50223099]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2284043  0.91273392]\n",
      " [0.80141458 1.34069827]\n",
      " [0.9622276  1.09032427]\n",
      " [1.53523787 1.51828861]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685412 0.71355928]\n",
      " [0.69027699 0.79260475]\n",
      " [0.72356759 0.74844278]\n",
      " [0.82277138 0.82028633]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.012331  ]\n",
      " [0.01000363]\n",
      " [0.01077295]\n",
      " [0.00876626]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50308271]\n",
      " [0.50250089]\n",
      " [0.50269321]\n",
      " [0.50219155]]\n",
      "Error [[-0.50308271]\n",
      " [ 0.49749911]\n",
      " [ 0.49730679]\n",
      " [-0.50219155]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22840326 0.91273469]\n",
      " [0.80140946 1.34069494]\n",
      " [0.96222333 1.09031468]\n",
      " [1.53522952 1.51827493]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685387 0.71355944]\n",
      " [0.6902759  0.7926042 ]\n",
      " [0.72356673 0.74844097]\n",
      " [0.82277017 0.82028431]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01212898]\n",
      " [0.00982601]\n",
      " [0.01060847]\n",
      " [0.00861848]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50303221]\n",
      " [0.50245648]\n",
      " [0.50265209]\n",
      " [0.50215461]]\n",
      "Error [[-0.50303221]\n",
      " [ 0.49754352]\n",
      " [ 0.49734791]\n",
      " [-0.50215461]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22840227 0.91273544]\n",
      " [0.80140459 1.34069157]\n",
      " [0.96221926 1.09030501]\n",
      " [1.53522158 1.51826114]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685362 0.71355959]\n",
      " [0.69027486 0.79260365]\n",
      " [0.72356592 0.74843915]\n",
      " [0.82276901 0.82028228]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01193529]\n",
      " [0.00965739]\n",
      " [0.01045292]\n",
      " [0.00848017]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50298379]\n",
      " [0.50241433]\n",
      " [0.50261321]\n",
      " [0.50212003]]\n",
      "Error [[-0.50298379]\n",
      " [ 0.49758567]\n",
      " [ 0.49738679]\n",
      " [-0.50212003]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22840133 0.91273618]\n",
      " [0.80139998 1.34068816]\n",
      " [0.96221541 1.09029528]\n",
      " [1.53521406 1.51824726]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685339 0.71355974]\n",
      " [0.69027387 0.79260309]\n",
      " [0.72356515 0.74843732]\n",
      " [0.82276791 0.82028024]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0117495 ]\n",
      " [0.00949728]\n",
      " [0.01030585]\n",
      " [0.00835084]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50293734]\n",
      " [0.5023743 ]\n",
      " [0.50257644]\n",
      " [0.5020877 ]]\n",
      "Error [[-0.50293734]\n",
      " [ 0.4976257 ]\n",
      " [ 0.49742356]\n",
      " [-0.5020877 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22840043 0.91273691]\n",
      " [0.80139562 1.34068471]\n",
      " [0.96221178 1.09028548]\n",
      " [1.53520697 1.51823329]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685317 0.71355989]\n",
      " [0.69027294 0.79260252]\n",
      " [0.72356442 0.74843548]\n",
      " [0.82276688 0.82027818]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01157119]\n",
      " [0.00934525]\n",
      " [0.01016682]\n",
      " [0.00823002]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50289277]\n",
      " [0.5023363 ]\n",
      " [0.50254168]\n",
      " [0.50205749]]\n",
      "Error [[-0.50289277]\n",
      " [ 0.4976637 ]\n",
      " [ 0.49745832]\n",
      " [-0.50205749]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839959 0.91273762]\n",
      " [0.80139153 1.34068123]\n",
      " [0.96220837 1.09027561]\n",
      " [1.53520031 1.51821922]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685296 0.71356004]\n",
      " [0.69027206 0.79260195]\n",
      " [0.72356374 0.74843362]\n",
      " [0.82276591 0.8202761 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01139999]\n",
      " [0.00920088]\n",
      " [0.0100354 ]\n",
      " [0.00811727]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50284997]\n",
      " [0.5023002 ]\n",
      " [0.50250883]\n",
      " [0.50202931]]\n",
      "Error [[-0.50284997]\n",
      " [ 0.4976998 ]\n",
      " [ 0.49749117]\n",
      " [-0.50202931]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2283988  0.91273833]\n",
      " [0.80138771 1.34067772]\n",
      " [0.96220517 1.09026568]\n",
      " [1.53519408 1.51820506]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685277 0.71356018]\n",
      " [0.69027125 0.79260137]\n",
      " [0.7235631  0.74843175]\n",
      " [0.822765   0.82027402]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01123551]\n",
      " [0.00906376]\n",
      " [0.0099112 ]\n",
      " [0.00801216]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50280885]\n",
      " [0.50226592]\n",
      " [0.50247778]\n",
      " [0.50200303]]\n",
      "Error [[-0.50280885]\n",
      " [ 0.49773408]\n",
      " [ 0.49752222]\n",
      " [-0.50200303]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839807 0.91273903]\n",
      " [0.80138416 1.34067417]\n",
      " [0.96220221 1.09025569]\n",
      " [1.53518829 1.51819082]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685259 0.71356033]\n",
      " [0.69027049 0.79260079]\n",
      " [0.72356251 0.74842987]\n",
      " [0.82276416 0.82027192]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0110774 ]\n",
      " [0.00893352]\n",
      " [0.00979384]\n",
      " [0.00791431]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50276932]\n",
      " [0.50223336]\n",
      " [0.50244844]\n",
      " [0.50197857]]\n",
      "Error [[-0.50276932]\n",
      " [ 0.49776664]\n",
      " [ 0.49755156]\n",
      " [-0.50197857]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839739 0.91273972]\n",
      " [0.80138088 1.34067059]\n",
      " [0.96219947 1.09024563]\n",
      " [1.53518295 1.5181765 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685242 0.71356047]\n",
      " [0.69026979 0.7926002 ]\n",
      " [0.72356196 0.74842797]\n",
      " [0.82276338 0.8202698 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01092535]\n",
      " [0.0088098 ]\n",
      " [0.00968297]\n",
      " [0.00782332]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50273131]\n",
      " [0.50220244]\n",
      " [0.50242072]\n",
      " [0.50195582]]\n",
      "Error [[-0.50273131]\n",
      " [ 0.49779756]\n",
      " [ 0.49757928]\n",
      " [-0.50195582]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839677 0.9127404 ]\n",
      " [0.80137787 1.34066697]\n",
      " [0.96219696 1.09023552]\n",
      " [1.53517806 1.5181621 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685226 0.71356061]\n",
      " [0.69026914 0.7925996 ]\n",
      " [0.72356146 0.74842607]\n",
      " [0.82276266 0.82026768]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01077902]\n",
      " [0.00869226]\n",
      " [0.00957825]\n",
      " [0.00773885]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50269473]\n",
      " [0.50217305]\n",
      " [0.50239454]\n",
      " [0.5019347 ]]\n",
      "Error [[-0.50269473]\n",
      " [ 0.49782695]\n",
      " [ 0.49760546]\n",
      " [-0.5019347 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2283962  0.91274107]\n",
      " [0.80137515 1.34066333]\n",
      " [0.96219468 1.09022536]\n",
      " [1.53517363 1.51814762]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685212 0.71356074]\n",
      " [0.69026856 0.792599  ]\n",
      " [0.723561   0.74842416]\n",
      " [0.82276202 0.82026555]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01063813]\n",
      " [0.00858059]\n",
      " [0.00947936]\n",
      " [0.00766056]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50265951]\n",
      " [0.50214513]\n",
      " [0.50236982]\n",
      " [0.50191513]]\n",
      "Error [[-0.50265951]\n",
      " [ 0.49785487]\n",
      " [ 0.49763018]\n",
      " [-0.50191513]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839569 0.91274173]\n",
      " [0.8013727  1.34065966]\n",
      " [0.96219264 1.09021514]\n",
      " [1.53516965 1.51813307]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.556852   0.71356088]\n",
      " [0.69026804 0.7925984 ]\n",
      " [0.72356059 0.74842223]\n",
      " [0.82276144 0.8202634 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0105024 ]\n",
      " [0.00847447]\n",
      " [0.00938599]\n",
      " [0.00758811]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50262557]\n",
      " [0.5021186 ]\n",
      " [0.50234648]\n",
      " [0.50189702]]\n",
      "Error [[-0.50262557]\n",
      " [ 0.4978814 ]\n",
      " [ 0.49765352]\n",
      " [-0.50189702]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839524 0.91274238]\n",
      " [0.80137054 1.34065596]\n",
      " [0.96219083 1.09020486]\n",
      " [1.53516613 1.51811844]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685189 0.71356101]\n",
      " [0.69026758 0.79259779]\n",
      " [0.72356023 0.7484203 ]\n",
      " [0.82276092 0.82026124]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01037154]\n",
      " [0.00837361]\n",
      " [0.00929787]\n",
      " [0.00752122]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50259286]\n",
      " [0.50209339]\n",
      " [0.50232445]\n",
      " [0.5018803 ]]\n",
      "Error [[-0.50259286]\n",
      " [ 0.49790661]\n",
      " [ 0.49767555]\n",
      " [-0.5018803 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839485 0.91274303]\n",
      " [0.80136866 1.34065224]\n",
      " [0.96218926 1.09019454]\n",
      " [1.53516308 1.51810374]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685179 0.71356114]\n",
      " [0.69026718 0.79259718]\n",
      " [0.72355992 0.74841835]\n",
      " [0.82276048 0.82025908]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01024532]\n",
      " [0.00827775]\n",
      " [0.00921471]\n",
      " [0.00745958]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50256131]\n",
      " [0.50206943]\n",
      " [0.50230366]\n",
      " [0.50186489]]\n",
      "Error [[-0.50256131]\n",
      " [ 0.49793057]\n",
      " [ 0.49769634]\n",
      " [-0.50186489]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839452 0.91274367]\n",
      " [0.80136708 1.34064849]\n",
      " [0.96218794 1.09018416]\n",
      " [1.53516049 1.51808898]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685171 0.71356128]\n",
      " [0.69026684 0.79259656]\n",
      " [0.72355965 0.7484164 ]\n",
      " [0.8227601  0.8202569 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01012348]\n",
      " [0.00818662]\n",
      " [0.00913626]\n",
      " [0.00740293]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50253085]\n",
      " [0.50204664]\n",
      " [0.50228405]\n",
      " [0.50185072]]\n",
      "Error [[-0.50253085]\n",
      " [ 0.49795336]\n",
      " [ 0.49771595]\n",
      " [-0.50185072]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839424 0.91274431]\n",
      " [0.80136578 1.34064471]\n",
      " [0.96218685 1.09017374]\n",
      " [1.53515838 1.51807415]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685164 0.7135614 ]\n",
      " [0.69026656 0.79259594]\n",
      " [0.72355944 0.74841444]\n",
      " [0.82275979 0.82025471]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.01000581]\n",
      " [0.00809998]\n",
      " [0.00906227]\n",
      " [0.00735101]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50250143]\n",
      " [0.50202498]\n",
      " [0.50226555]\n",
      " [0.50183774]]\n",
      "Error [[-0.50250143]\n",
      " [ 0.49797502]\n",
      " [ 0.49773445]\n",
      " [-0.50183774]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839403 0.91274494]\n",
      " [0.80136477 1.34064091]\n",
      " [0.96218601 1.09016327]\n",
      " [1.53515675 1.51805925]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685159 0.71356153]\n",
      " [0.69026634 0.79259532]\n",
      " [0.72355927 0.74841247]\n",
      " [0.82275956 0.82025252]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00989209]\n",
      " [0.00801759]\n",
      " [0.00899251]\n",
      " [0.00730357]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.502473  ]\n",
      " [0.50200439]\n",
      " [0.50224811]\n",
      " [0.50182588]]\n",
      "Error [[-0.502473  ]\n",
      " [ 0.49799561]\n",
      " [ 0.49775189]\n",
      " [-0.50182588]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839388 0.91274556]\n",
      " [0.80136406 1.34063709]\n",
      " [0.96218541 1.09015276]\n",
      " [1.53515559 1.51804429]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685155 0.71356166]\n",
      " [0.69026619 0.79259469]\n",
      " [0.72355915 0.74841049]\n",
      " [0.82275939 0.82025031]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0097821 ]\n",
      " [0.00793923]\n",
      " [0.00892677]\n",
      " [0.00726037]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50244551]\n",
      " [0.5019848 ]\n",
      " [0.50223168]\n",
      " [0.50181508]]\n",
      "Error [[-0.50244551]\n",
      " [ 0.4980152 ]\n",
      " [ 0.49776832]\n",
      " [-0.50181508]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2283938  0.91274618]\n",
      " [0.80136364 1.34063325]\n",
      " [0.96218506 1.0901422 ]\n",
      " [1.53515491 1.51802927]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685153 0.71356179]\n",
      " [0.6902661  0.79259406]\n",
      " [0.72355908 0.7484085 ]\n",
      " [0.82275929 0.8202481 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00967566]\n",
      " [0.0078647 ]\n",
      " [0.00886482]\n",
      " [0.0072212 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5024189 ]\n",
      " [0.50196616]\n",
      " [0.50221619]\n",
      " [0.50180529]]\n",
      "Error [[-0.5024189 ]\n",
      " [ 0.49803384]\n",
      " [ 0.49778381]\n",
      " [-0.50180529]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839377 0.91274679]\n",
      " [0.80136352 1.34062938]\n",
      " [0.96218496 1.09013159]\n",
      " [1.53515471 1.51801419]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685152 0.71356191]\n",
      " [0.69026608 0.79259342]\n",
      " [0.72355906 0.7484065 ]\n",
      " [0.82275926 0.82024587]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00957258]\n",
      " [0.00779379]\n",
      " [0.00880648]\n",
      " [0.00718584]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50239313]\n",
      " [0.50194844]\n",
      " [0.50220161]\n",
      " [0.50179645]]\n",
      "Error [[-0.50239313]\n",
      " [ 0.49805156]\n",
      " [ 0.49779839]\n",
      " [-0.50179645]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839381 0.91274739]\n",
      " [0.8013637  1.34062549]\n",
      " [0.96218511 1.09012095]\n",
      " [1.535155   1.51799905]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685153 0.71356204]\n",
      " [0.69026611 0.79259278]\n",
      " [0.72355909 0.7484045 ]\n",
      " [0.8227593  0.82024364]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00947269]\n",
      " [0.00772631]\n",
      " [0.00875156]\n",
      " [0.00715411]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50236816]\n",
      " [0.50193157]\n",
      " [0.50218788]\n",
      " [0.50178852]]\n",
      "Error [[-0.50236816]\n",
      " [ 0.49806843]\n",
      " [ 0.49781212]\n",
      " [-0.50178852]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839391 0.91274799]\n",
      " [0.80136418 1.34062158]\n",
      " [0.96218551 1.09011026]\n",
      " [1.53515578 1.51798385]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685156 0.71356216]\n",
      " [0.69026622 0.79259214]\n",
      " [0.72355917 0.74840248]\n",
      " [0.82275941 0.8202414 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00937582]\n",
      " [0.00766209]\n",
      " [0.00869987]\n",
      " [0.0071258 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50234394]\n",
      " [0.50191551]\n",
      " [0.50217495]\n",
      " [0.50178144]]\n",
      "Error [[-0.50234394]\n",
      " [ 0.49808449]\n",
      " [ 0.49782505]\n",
      " [-0.50178144]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839407 0.91274859]\n",
      " [0.80136495 1.34061765]\n",
      " [0.96218616 1.09009954]\n",
      " [1.53515704 1.5179686 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5568516  0.71356228]\n",
      " [0.69026638 0.7925915 ]\n",
      " [0.7235593  0.74840046]\n",
      " [0.8227596  0.82023915]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00928182]\n",
      " [0.00760096]\n",
      " [0.00865126]\n",
      " [0.00710074]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50232044]\n",
      " [0.50190023]\n",
      " [0.5021628 ]\n",
      " [0.50177518]]\n",
      "Error [[-0.50232044]\n",
      " [ 0.49809977]\n",
      " [ 0.4978372 ]\n",
      " [-0.50177518]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2283943  0.91274918]\n",
      " [0.80136604 1.34061371]\n",
      " [0.96218707 1.09008877]\n",
      " [1.5351588  1.5179533 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685166 0.7135624 ]\n",
      " [0.69026661 0.79259085]\n",
      " [0.72355948 0.74839844]\n",
      " [0.82275985 0.8202369 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00919053]\n",
      " [0.00754275]\n",
      " [0.00860556]\n",
      " [0.00707877]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50229762]\n",
      " [0.50188568]\n",
      " [0.50215138]\n",
      " [0.50176968]]\n",
      "Error [[-0.50229762]\n",
      " [ 0.49811432]\n",
      " [ 0.49784862]\n",
      " [-0.50176968]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2283946  0.91274977]\n",
      " [0.80136742 1.34060974]\n",
      " [0.96218822 1.09007797]\n",
      " [1.53516105 1.51793794]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685173 0.71356252]\n",
      " [0.69026691 0.79259019]\n",
      " [0.72355971 0.7483964 ]\n",
      " [0.82276018 0.82023463]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00910182]\n",
      " [0.00748732]\n",
      " [0.00856261]\n",
      " [0.00705971]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50227544]\n",
      " [0.50187182]\n",
      " [0.50214064]\n",
      " [0.50176492]]\n",
      "Error [[-0.50227544]\n",
      " [ 0.49812818]\n",
      " [ 0.49785936]\n",
      " [-0.50176492]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839495 0.91275036]\n",
      " [0.80136911 1.34060575]\n",
      " [0.96218964 1.09006713]\n",
      " [1.53516379 1.51792253]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685182 0.71356264]\n",
      " [0.69026727 0.79258954]\n",
      " [0.72355999 0.74839436]\n",
      " [0.82276058 0.82023236]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00901556]\n",
      " [0.00743453]\n",
      " [0.00852229]\n",
      " [0.00704343]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50225387]\n",
      " [0.50185862]\n",
      " [0.50213056]\n",
      " [0.50176085]]\n",
      "Error [[-0.50225387]\n",
      " [ 0.49814138]\n",
      " [ 0.49786944]\n",
      " [-0.50176085]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839538 0.91275094]\n",
      " [0.80137111 1.34060175]\n",
      " [0.96219131 1.09005625]\n",
      " [1.53516703 1.51790707]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685192 0.71356276]\n",
      " [0.6902677  0.79258888]\n",
      " [0.72356033 0.74839231]\n",
      " [0.82276106 0.82023008]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0089316 ]\n",
      " [0.00738422]\n",
      " [0.00848444]\n",
      " [0.00702977]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50223289]\n",
      " [0.50184605]\n",
      " [0.5021211 ]\n",
      " [0.50175743]]\n",
      "Error [[-0.50223289]\n",
      " [ 0.49815395]\n",
      " [ 0.4978789 ]\n",
      " [-0.50175743]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839587 0.91275152]\n",
      " [0.80137341 1.34059773]\n",
      " [0.96219323 1.09004534]\n",
      " [1.53517077 1.51789156]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685204 0.71356288]\n",
      " [0.69026819 0.79258822]\n",
      " [0.72356071 0.74839026]\n",
      " [0.8227616  0.82022779]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00884984]\n",
      " [0.00733628]\n",
      " [0.00844895]\n",
      " [0.00701859]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50221245]\n",
      " [0.50183406]\n",
      " [0.50211222]\n",
      " [0.50175464]]\n",
      "Error [[-0.50221245]\n",
      " [ 0.49816594]\n",
      " [ 0.49788778]\n",
      " [-0.50175464]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839642 0.91275209]\n",
      " [0.80137602 1.3405937 ]\n",
      " [0.96219542 1.09003439]\n",
      " [1.53517501 1.517876  ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685218 0.713563  ]\n",
      " [0.69026875 0.79258756]\n",
      " [0.72356115 0.7483882 ]\n",
      " [0.82276222 0.8202255 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00877017]\n",
      " [0.00729058]\n",
      " [0.00841569]\n",
      " [0.00700978]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50219253]\n",
      " [0.50182264]\n",
      " [0.50210391]\n",
      " [0.50175244]]\n",
      "Error [[-0.50219253]\n",
      " [ 0.49817736]\n",
      " [ 0.49789609]\n",
      " [-0.50175244]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839704 0.91275266]\n",
      " [0.80137894 1.34058965]\n",
      " [0.96219786 1.09002341]\n",
      " [1.53517975 1.51786039]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685233 0.71356311]\n",
      " [0.69026937 0.79258689]\n",
      " [0.72356164 0.74838613]\n",
      " [0.82276291 0.8202232 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00869247]\n",
      " [0.00724701]\n",
      " [0.00838454]\n",
      " [0.00700321]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5021731 ]\n",
      " [0.50181174]\n",
      " [0.50209612]\n",
      " [0.50175079]]\n",
      "Error [[-0.5021731 ]\n",
      " [ 0.49818826]\n",
      " [ 0.49790388]\n",
      " [-0.50175079]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839773 0.91275323]\n",
      " [0.80138217 1.34058558]\n",
      " [0.96220056 1.09001239]\n",
      " [1.535185   1.51784474]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5568525  0.71356323]\n",
      " [0.69027006 0.79258622]\n",
      " [0.72356218 0.74838406]\n",
      " [0.82276367 0.82022089]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00861664]\n",
      " [0.00720545]\n",
      " [0.00835539]\n",
      " [0.00699875]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50215415]\n",
      " [0.50180135]\n",
      " [0.50208884]\n",
      " [0.50174968]]\n",
      "Error [[-0.50215415]\n",
      " [ 0.49819865]\n",
      " [ 0.49791116]\n",
      " [-0.50174968]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22839848 0.9127538 ]\n",
      " [0.80138571 1.3405815 ]\n",
      " [0.96220352 1.09000134]\n",
      " [1.53519074 1.51782904]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685269 0.71356334]\n",
      " [0.69027082 0.79258555]\n",
      " [0.72356277 0.74838197]\n",
      " [0.82276451 0.82021857]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00854258]\n",
      " [0.0071658 ]\n",
      " [0.00832814]\n",
      " [0.0069963 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50213563]\n",
      " [0.50179144]\n",
      " [0.50208202]\n",
      " [0.50174907]]\n",
      "Error [[-0.50213563]\n",
      " [ 0.49820856]\n",
      " [ 0.49791798]\n",
      " [-0.50174907]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2283993  0.91275436]\n",
      " [0.80138956 1.3405774 ]\n",
      " [0.96220674 1.08999026]\n",
      " [1.53519699 1.5178133 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685289 0.71356346]\n",
      " [0.69027164 0.79258488]\n",
      " [0.72356341 0.74837989]\n",
      " [0.82276542 0.82021625]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00847021]\n",
      " [0.00712797]\n",
      " [0.0083027 ]\n",
      " [0.00699576]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50211754]\n",
      " [0.50178198]\n",
      " [0.50207566]\n",
      " [0.50174893]]\n",
      "Error [[-0.50211754]\n",
      " [ 0.49821802]\n",
      " [ 0.49792434]\n",
      " [-0.50174893]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22840019 0.91275492]\n",
      " [0.80139372 1.34057328]\n",
      " [0.96221022 1.08997915]\n",
      " [1.53520375 1.51779751]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685311 0.71356357]\n",
      " [0.69027253 0.7925842 ]\n",
      " [0.72356411 0.74837779]\n",
      " [0.82276641 0.82021392]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00839943]\n",
      " [0.00709185]\n",
      " [0.00827896]\n",
      " [0.00699702]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50209984]\n",
      " [0.50177295]\n",
      " [0.50206973]\n",
      " [0.50174925]]\n",
      "Error [[-0.50209984]\n",
      " [ 0.49822705]\n",
      " [ 0.49793027]\n",
      " [-0.50174925]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22840115 0.91275548]\n",
      " [0.80139819 1.34056916]\n",
      " [0.96221397 1.089968  ]\n",
      " [1.53521101 1.51778168]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685334 0.71356369]\n",
      " [0.69027349 0.79258352]\n",
      " [0.72356486 0.7483757 ]\n",
      " [0.82276747 0.82021159]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00833016]\n",
      " [0.00705735]\n",
      " [0.00825684]\n",
      " [0.007     ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50208253]\n",
      " [0.50176433]\n",
      " [0.5020642 ]\n",
      " [0.50174999]]\n",
      "Error [[-0.50208253]\n",
      " [ 0.49823567]\n",
      " [ 0.4979358 ]\n",
      " [-0.50174999]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22840217 0.91275603]\n",
      " [0.80140298 1.34056502]\n",
      " [0.96221797 1.08995683]\n",
      " [1.53521879 1.51776581]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5568536  0.7135638 ]\n",
      " [0.69027451 0.79258284]\n",
      " [0.72356566 0.74837359]\n",
      " [0.8227686  0.82020925]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00826233]\n",
      " [0.00702441]\n",
      " [0.00823625]\n",
      " [0.0070046 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50206557]\n",
      " [0.50175609]\n",
      " [0.50205905]\n",
      " [0.50175114]]\n",
      "Error [[-0.50206557]\n",
      " [ 0.49824391]\n",
      " [ 0.49794095]\n",
      " [-0.50175114]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22840326 0.91275659]\n",
      " [0.80140808 1.34056086]\n",
      " [0.96222224 1.08994562]\n",
      " [1.53522707 1.51774989]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685387 0.71356391]\n",
      " [0.6902756  0.79258216]\n",
      " [0.72356651 0.74837148]\n",
      " [0.82276981 0.8202069 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00819586]\n",
      " [0.00699292]\n",
      " [0.00821712]\n",
      " [0.00701074]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50204895]\n",
      " [0.50174822]\n",
      " [0.50205427]\n",
      " [0.50175268]]\n",
      "Error [[-0.50204895]\n",
      " [ 0.49825178]\n",
      " [ 0.49794573]\n",
      " [-0.50175268]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22840441 0.91275714]\n",
      " [0.8014135  1.3405567 ]\n",
      " [0.96222677 1.08993438]\n",
      " [1.53523586 1.51773394]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685415 0.71356403]\n",
      " [0.69027676 0.79258147]\n",
      " [0.72356742 0.74836937]\n",
      " [0.82277109 0.82020455]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00813068]\n",
      " [0.00696283]\n",
      " [0.00819938]\n",
      " [0.00701834]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50203266]\n",
      " [0.5017407 ]\n",
      " [0.50204983]\n",
      " [0.50175458]]\n",
      "Error [[-0.50203266]\n",
      " [ 0.4982593 ]\n",
      " [ 0.49795017]\n",
      " [-0.50175458]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22840564 0.91275769]\n",
      " [0.80141923 1.34055251]\n",
      " [0.96223157 1.08992312]\n",
      " [1.53524516 1.51771794]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685445 0.71356414]\n",
      " [0.69027799 0.79258079]\n",
      " [0.72356838 0.74836724]\n",
      " [0.82277245 0.82020219]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00806673]\n",
      " [0.00693405]\n",
      " [0.00818293]\n",
      " [0.00702732]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50201667]\n",
      " [0.5017335 ]\n",
      " [0.50204572]\n",
      " [0.50175682]]\n",
      "Error [[-0.50201667]\n",
      " [ 0.4982665 ]\n",
      " [ 0.49795428]\n",
      " [-0.50175682]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22840693 0.91275824]\n",
      " [0.80142527 1.34054832]\n",
      " [0.96223663 1.08991182]\n",
      " [1.53525497 1.5177019 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685477 0.71356425]\n",
      " [0.69027928 0.7925801 ]\n",
      " [0.72356939 0.74836512]\n",
      " [0.82277388 0.82019982]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00800393]\n",
      " [0.00690652]\n",
      " [0.00816773]\n",
      " [0.00703761]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50200097]\n",
      " [0.50172662]\n",
      " [0.50204192]\n",
      " [0.50175939]]\n",
      "Error [[-0.50200097]\n",
      " [ 0.49827338]\n",
      " [ 0.49795808]\n",
      " [-0.50175939]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22840829 0.91275879]\n",
      " [0.80143163 1.34054411]\n",
      " [0.96224195 1.0899005 ]\n",
      " [1.53526529 1.51768582]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685511 0.71356436]\n",
      " [0.69028064 0.79257941]\n",
      " [0.72357046 0.74836298]\n",
      " [0.82277538 0.82019745]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00794223]\n",
      " [0.00688017]\n",
      " [0.00815371]\n",
      " [0.00704914]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50198555]\n",
      " [0.50172003]\n",
      " [0.50203842]\n",
      " [0.50176228]]\n",
      "Error [[-0.50198555]\n",
      " [ 0.49827997]\n",
      " [ 0.49796158]\n",
      " [-0.50176228]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22840972 0.91275933]\n",
      " [0.80143831 1.3405399 ]\n",
      " [0.96224754 1.08988915]\n",
      " [1.53527613 1.51766971]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685546 0.71356448]\n",
      " [0.69028207 0.79257871]\n",
      " [0.72357157 0.74836085]\n",
      " [0.82277696 0.82019508]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00788158]\n",
      " [0.00685494]\n",
      " [0.0081408 ]\n",
      " [0.00706185]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50197038]\n",
      " [0.50171373]\n",
      " [0.50203519]\n",
      " [0.50176546]]\n",
      "Error [[-0.50197038]\n",
      " [ 0.49828627]\n",
      " [ 0.49796481]\n",
      " [-0.50176546]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22841122 0.91275988]\n",
      " [0.80144531 1.34053567]\n",
      " [0.96225339 1.08987776]\n",
      " [1.53528748 1.51765355]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685583 0.71356459]\n",
      " [0.69028356 0.79257802]\n",
      " [0.72357274 0.7483587 ]\n",
      " [0.82277862 0.82019269]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00782192]\n",
      " [0.00683077]\n",
      " [0.00812895]\n",
      " [0.00707568]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50195547]\n",
      " [0.50170769]\n",
      " [0.50203223]\n",
      " [0.50176891]]\n",
      "Error [[-0.50195547]\n",
      " [ 0.49829231]\n",
      " [ 0.49796777]\n",
      " [-0.50176891]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22841279 0.91276042]\n",
      " [0.80145262 1.34053142]\n",
      " [0.96225951 1.08986636]\n",
      " [1.53529934 1.51763736]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685622 0.7135647 ]\n",
      " [0.69028512 0.79257732]\n",
      " [0.72357397 0.74835655]\n",
      " [0.82278035 0.82019031]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00776319]\n",
      " [0.00680762]\n",
      " [0.0081181 ]\n",
      " [0.00709057]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50194079]\n",
      " [0.5017019 ]\n",
      " [0.50202951]\n",
      " [0.50177264]]\n",
      "Error [[-0.50194079]\n",
      " [ 0.4982981 ]\n",
      " [ 0.49797049]\n",
      " [-0.50177264]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22841443 0.91276097]\n",
      " [0.80146025 1.34052717]\n",
      " [0.96226589 1.08985492]\n",
      " [1.53531172 1.51762113]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685662 0.71356481]\n",
      " [0.69028676 0.79257662]\n",
      " [0.72357525 0.7483544 ]\n",
      " [0.82278215 0.82018791]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00770536]\n",
      " [0.00678542]\n",
      " [0.0081082 ]\n",
      " [0.00710647]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50192633]\n",
      " [0.50169635]\n",
      " [0.50202704]\n",
      " [0.50177661]]\n",
      "Error [[-0.50192633]\n",
      " [ 0.49830365]\n",
      " [ 0.49797296]\n",
      " [-0.50177661]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22841613 0.91276151]\n",
      " [0.80146819 1.3405229 ]\n",
      " [0.96227254 1.08984346]\n",
      " [1.53532461 1.51760486]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685704 0.71356492]\n",
      " [0.69028845 0.79257592]\n",
      " [0.72357658 0.74835224]\n",
      " [0.82278403 0.82018551]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00764837]\n",
      " [0.00676413]\n",
      " [0.00809921]\n",
      " [0.00712331]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50191208]\n",
      " [0.50169103]\n",
      " [0.50202479]\n",
      " [0.50178082]]\n",
      "Error [[-0.50191208]\n",
      " [ 0.49830897]\n",
      " [ 0.49797521]\n",
      " [-0.50178082]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2284179  0.91276205]\n",
      " [0.80147646 1.34051863]\n",
      " [0.96227946 1.08983197]\n",
      " [1.53533801 1.51758855]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685748 0.71356503]\n",
      " [0.69029022 0.79257522]\n",
      " [0.72357796 0.74835008]\n",
      " [0.82278599 0.82018311]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00759218]\n",
      " [0.0067437 ]\n",
      " [0.00809106]\n",
      " [0.00714106]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50189804]\n",
      " [0.50168592]\n",
      " [0.50202275]\n",
      " [0.50178526]]\n",
      "Error [[-0.50189804]\n",
      " [ 0.49831408]\n",
      " [ 0.49797725]\n",
      " [-0.50178526]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22841974 0.91276259]\n",
      " [0.80148504 1.34051434]\n",
      " [0.96228664 1.08982045]\n",
      " [1.53535194 1.51757221]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685793 0.71356514]\n",
      " [0.69029206 0.79257451]\n",
      " [0.7235794  0.74834791]\n",
      " [0.82278802 0.8201807 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00753675]\n",
      " [0.00672408]\n",
      " [0.00808373]\n",
      " [0.00715966]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50188418]\n",
      " [0.50168101]\n",
      " [0.50202092]\n",
      " [0.50178991]]\n",
      "Error [[-0.50188418]\n",
      " [ 0.49831899]\n",
      " [ 0.49797908]\n",
      " [-0.50178991]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22842166 0.91276312]\n",
      " [0.80149394 1.34051004]\n",
      " [0.96229409 1.08980891]\n",
      " [1.53536638 1.51755583]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685841 0.71356525]\n",
      " [0.69029396 0.79257381]\n",
      " [0.72358089 0.74834574]\n",
      " [0.82279012 0.82017828]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00748204]\n",
      " [0.00670524]\n",
      " [0.00807717]\n",
      " [0.00717908]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5018705 ]\n",
      " [0.5016763 ]\n",
      " [0.50201928]\n",
      " [0.50179476]]\n",
      "Error [[-0.5018705 ]\n",
      " [ 0.4983237 ]\n",
      " [ 0.49798072]\n",
      " [-0.50179476]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22842364 0.91276366]\n",
      " [0.80150316 1.34050573]\n",
      " [0.96230181 1.08979734]\n",
      " [1.53538133 1.51753942]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685889 0.71356536]\n",
      " [0.69029593 0.7925731 ]\n",
      " [0.72358243 0.74834356]\n",
      " [0.8227923  0.82017586]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00742801]\n",
      " [0.00668713]\n",
      " [0.00807134]\n",
      " [0.00719926]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.501857  ]\n",
      " [0.50167178]\n",
      " [0.50201782]\n",
      " [0.50179981]]\n",
      "Error [[-0.501857  ]\n",
      " [ 0.49832822]\n",
      " [ 0.49798218]\n",
      " [-0.50179981]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22842569 0.9127642 ]\n",
      " [0.8015127  1.34050141]\n",
      " [0.96230979 1.08978575]\n",
      " [1.5353968  1.51752297]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5568594  0.71356547]\n",
      " [0.69029797 0.79257239]\n",
      " [0.72358402 0.74834138]\n",
      " [0.82279456 0.82017344]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00737464]\n",
      " [0.00666972]\n",
      " [0.0080662 ]\n",
      " [0.00722018]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50184365]\n",
      " [0.50166742]\n",
      " [0.50201654]\n",
      " [0.50180504]]\n",
      "Error [[-0.50184365]\n",
      " [ 0.49833258]\n",
      " [ 0.49798346]\n",
      " [-0.50180504]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2284278  0.91276474]\n",
      " [0.80152256 1.34049708]\n",
      " [0.96231804 1.08977413]\n",
      " [1.53541279 1.51750648]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55685992 0.71356558]\n",
      " [0.69030008 0.79257167]\n",
      " [0.72358567 0.74833919]\n",
      " [0.82279689 0.820171  ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00732187]\n",
      " [0.00665297]\n",
      " [0.00806171]\n",
      " [0.00724179]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50183046]\n",
      " [0.50166324]\n",
      " [0.50201542]\n",
      " [0.50181044]]\n",
      "Error [[-0.50183046]\n",
      " [ 0.49833676]\n",
      " [ 0.49798458]\n",
      " [-0.50181044]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22842999 0.91276527]\n",
      " [0.80153274 1.34049274]\n",
      " [0.96232656 1.08976249]\n",
      " [1.5354293  1.51748996]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686046 0.71356569]\n",
      " [0.69030225 0.79257096]\n",
      " [0.72358738 0.74833699]\n",
      " [0.8227993  0.82016857]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0072697 ]\n",
      " [0.00663684]\n",
      " [0.00805785]\n",
      " [0.00726405]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50181742]\n",
      " [0.50165921]\n",
      " [0.50201445]\n",
      " [0.501816  ]]\n",
      "Error [[-0.50181742]\n",
      " [ 0.49834079]\n",
      " [ 0.49798555]\n",
      " [-0.501816  ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22843225 0.91276581]\n",
      " [0.80154323 1.34048839]\n",
      " [0.96233534 1.08975082]\n",
      " [1.53544633 1.5174734 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686102 0.7135658 ]\n",
      " [0.6903045  0.79257025]\n",
      " [0.72358914 0.7483348 ]\n",
      " [0.82280178 0.82016613]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00721807]\n",
      " [0.00662131]\n",
      " [0.00805457]\n",
      " [0.00728693]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50180451]\n",
      " [0.50165532]\n",
      " [0.50201363]\n",
      " [0.50182172]]\n",
      "Error [[-0.50180451]\n",
      " [ 0.49834468]\n",
      " [ 0.49798637]\n",
      " [-0.50182172]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22843458 0.91276634]\n",
      " [0.80155405 1.34048403]\n",
      " [0.96234439 1.08973912]\n",
      " [1.53546387 1.51745681]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686159 0.71356591]\n",
      " [0.69030681 0.79256953]\n",
      " [0.72359095 0.74833259]\n",
      " [0.82280434 0.82016368]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00716697]\n",
      " [0.00660634]\n",
      " [0.00805186]\n",
      " [0.00731041]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50179173]\n",
      " [0.50165158]\n",
      " [0.50201295]\n",
      " [0.50182759]]\n",
      "Error [[-0.50179173]\n",
      " [ 0.49834842]\n",
      " [ 0.49798705]\n",
      " [-0.50182759]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22843697 0.91276688]\n",
      " [0.80156519 1.34047966]\n",
      " [0.96235371 1.08972741]\n",
      " [1.53548193 1.51744019]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686219 0.71356602]\n",
      " [0.69030919 0.79256881]\n",
      " [0.72359281 0.74833039]\n",
      " [0.82280697 0.82016123]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00711637]\n",
      " [0.00659191]\n",
      " [0.00804967]\n",
      " [0.00733444]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50177908]\n",
      " [0.50164797]\n",
      " [0.50201241]\n",
      " [0.5018336 ]]\n",
      "Error [[-0.50177908]\n",
      " [ 0.49835203]\n",
      " [ 0.49798759]\n",
      " [-0.5018336 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22843944 0.91276741]\n",
      " [0.80157665 1.34047528]\n",
      " [0.9623633  1.08971566]\n",
      " [1.53550051 1.51742353]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686279 0.71356613]\n",
      " [0.69031164 0.79256809]\n",
      " [0.72359473 0.74832818]\n",
      " [0.82280968 0.82015877]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00706624]\n",
      " [0.00657798]\n",
      " [0.00804799]\n",
      " [0.007359  ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50176655]\n",
      " [0.50164449]\n",
      " [0.50201199]\n",
      " [0.50183974]]\n",
      "Error [[-0.50176655]\n",
      " [ 0.49835551]\n",
      " [ 0.49798801]\n",
      " [-0.50183974]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22844197 0.91276794]\n",
      " [0.80158843 1.34047089]\n",
      " [0.96237316 1.08970389]\n",
      " [1.53551961 1.51740684]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686342 0.71356624]\n",
      " [0.69031416 0.79256737]\n",
      " [0.7235967  0.74832596]\n",
      " [0.82281246 0.82015631]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00701656]\n",
      " [0.00656453]\n",
      " [0.00804679]\n",
      " [0.00738407]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50175413]\n",
      " [0.50164113]\n",
      " [0.50201169]\n",
      " [0.50184601]]\n",
      "Error [[-0.50175413]\n",
      " [ 0.49835887]\n",
      " [ 0.49798831]\n",
      " [-0.50184601]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22844458 0.91276848]\n",
      " [0.80160053 1.34046649]\n",
      " [0.96238328 1.0896921 ]\n",
      " [1.53553923 1.51739012]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686406 0.71356634]\n",
      " [0.69031675 0.79256665]\n",
      " [0.72359872 0.74832374]\n",
      " [0.82281532 0.82015384]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0069673 ]\n",
      " [0.00655154]\n",
      " [0.00804604]\n",
      " [0.00740961]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50174182]\n",
      " [0.50163788]\n",
      " [0.5020115 ]\n",
      " [0.50185239]]\n",
      "Error [[-0.50174182]\n",
      " [ 0.49836212]\n",
      " [ 0.4979885 ]\n",
      " [-0.50185239]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22844725 0.91276901]\n",
      " [0.80161295 1.34046208]\n",
      " [0.96239368 1.08968028]\n",
      " [1.53555937 1.51737336]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686472 0.71356645]\n",
      " [0.6903194  0.79256592]\n",
      " [0.7236008  0.74832151]\n",
      " [0.82281826 0.82015137]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00691845]\n",
      " [0.00653898]\n",
      " [0.00804571]\n",
      " [0.00743561]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50172961]\n",
      " [0.50163474]\n",
      " [0.50201142]\n",
      " [0.50185889]]\n",
      "Error [[-0.50172961]\n",
      " [ 0.49836526]\n",
      " [ 0.49798858]\n",
      " [-0.50185889]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22845    0.91276954]\n",
      " [0.80162569 1.34045766]\n",
      " [0.96240434 1.08966844]\n",
      " [1.53558003 1.51735657]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5568654  0.71356656]\n",
      " [0.69032212 0.79256519]\n",
      " [0.72360294 0.74831928]\n",
      " [0.82282127 0.82014889]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00686998]\n",
      " [0.00652684]\n",
      " [0.0080458 ]\n",
      " [0.00746203]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50171749]\n",
      " [0.5016317 ]\n",
      " [0.50201144]\n",
      " [0.5018655 ]]\n",
      "Error [[-0.50171749]\n",
      " [ 0.4983683 ]\n",
      " [ 0.49798856]\n",
      " [-0.5018655 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22845281 0.91277007]\n",
      " [0.80163875 1.34045324]\n",
      " [0.96241527 1.08965658]\n",
      " [1.53560121 1.51733974]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686609 0.71356667]\n",
      " [0.69032492 0.79256447]\n",
      " [0.72360512 0.74831705]\n",
      " [0.82282436 0.82014641]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00682188]\n",
      " [0.00651508]\n",
      " [0.00804627]\n",
      " [0.00748886]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50170546]\n",
      " [0.50162876]\n",
      " [0.50201156]\n",
      " [0.50187221]]\n",
      "Error [[-0.50170546]\n",
      " [ 0.49837124]\n",
      " [ 0.49798844]\n",
      " [-0.50187221]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2284557  0.91277061]\n",
      " [0.80165213 1.3404488 ]\n",
      " [0.96242647 1.08964469]\n",
      " [1.5356229  1.51732289]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686681 0.71356678]\n",
      " [0.69032778 0.79256374]\n",
      " [0.72360736 0.74831481]\n",
      " [0.82282752 0.82014392]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00677412]\n",
      " [0.00650369]\n",
      " [0.00804711]\n",
      " [0.00751608]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50169352]\n",
      " [0.50162592]\n",
      " [0.50201177]\n",
      " [0.50187901]]\n",
      "Error [[-0.50169352]\n",
      " [ 0.49837408]\n",
      " [ 0.49798823]\n",
      " [-0.50187901]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22845865 0.91277114]\n",
      " [0.80166584 1.34044435]\n",
      " [0.96243794 1.08963278]\n",
      " [1.53564512 1.517306  ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686754 0.71356689]\n",
      " [0.69033071 0.79256301]\n",
      " [0.72360966 0.74831257]\n",
      " [0.82283076 0.82014143]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00672669]\n",
      " [0.00649265]\n",
      " [0.0080483 ]\n",
      " [0.00754366]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50168167]\n",
      " [0.50162316]\n",
      " [0.50201206]\n",
      " [0.50188591]]\n",
      "Error [[-0.50168167]\n",
      " [ 0.49837684]\n",
      " [ 0.49798794]\n",
      " [-0.50188591]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846168 0.91277167]\n",
      " [0.80167986 1.3404399 ]\n",
      " [0.96244967 1.08962085]\n",
      " [1.53566786 1.51728907]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686828 0.713567  ]\n",
      " [0.69033371 0.79256227]\n",
      " [0.723612   0.74831032]\n",
      " [0.82283408 0.82013894]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00667957]\n",
      " [0.00648195]\n",
      " [0.00804982]\n",
      " [0.00757159]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50166989]\n",
      " [0.50162048]\n",
      " [0.50201244]\n",
      " [0.50189289]]\n",
      "Error [[-0.50166989]\n",
      " [ 0.49837952]\n",
      " [ 0.49798756]\n",
      " [-0.50189289]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846477 0.9127722 ]\n",
      " [0.80169421 1.34043543]\n",
      " [0.96246168 1.08960889]\n",
      " [1.53569112 1.51727212]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686905 0.71356711]\n",
      " [0.69033677 0.79256154]\n",
      " [0.7236144  0.74830807]\n",
      " [0.82283747 0.82013644]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00663274]\n",
      " [0.00647156]\n",
      " [0.00805165]\n",
      " [0.00759985]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50165818]\n",
      " [0.50161788]\n",
      " [0.5020129 ]\n",
      " [0.50189995]]\n",
      "Error [[-0.50165818]\n",
      " [ 0.49838212]\n",
      " [ 0.4979871 ]\n",
      " [-0.50189995]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22846793 0.91277273]\n",
      " [0.80170888 1.34043096]\n",
      " [0.96247395 1.08959691]\n",
      " [1.5357149  1.51725513]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55686983 0.71356721]\n",
      " [0.69033991 0.7925608 ]\n",
      " [0.72361686 0.74830581]\n",
      " [0.82284093 0.82013393]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0065862 ]\n",
      " [0.00646147]\n",
      " [0.00805378]\n",
      " [0.00762843]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50164654]\n",
      " [0.50161536]\n",
      " [0.50201343]\n",
      " [0.5019071 ]]\n",
      "Error [[-0.50164654]\n",
      " [ 0.49838464]\n",
      " [ 0.49798657]\n",
      " [-0.5019071 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22847117 0.91277327]\n",
      " [0.80172387 1.34042648]\n",
      " [0.9624865  1.0895849 ]\n",
      " [1.5357392  1.51723811]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55687062 0.71356732]\n",
      " [0.69034311 0.79256007]\n",
      " [0.72361937 0.74830355]\n",
      " [0.82284448 0.82013142]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00653992]\n",
      " [0.00645166]\n",
      " [0.00805619]\n",
      " [0.0076573 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50163497]\n",
      " [0.50161291]\n",
      " [0.50201404]\n",
      " [0.50191431]]\n",
      "Error [[-0.50163497]\n",
      " [ 0.49838709]\n",
      " [ 0.49798596]\n",
      " [-0.50191431]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22847447 0.9127738 ]\n",
      " [0.80173918 1.34042199]\n",
      " [0.96249931 1.08957287]\n",
      " [1.53576402 1.51722106]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55687144 0.71356743]\n",
      " [0.69034639 0.79255933]\n",
      " [0.72362193 0.74830128]\n",
      " [0.82284809 0.8201289 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00649389]\n",
      " [0.00644213]\n",
      " [0.00805887]\n",
      " [0.00768645]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50162347]\n",
      " [0.50161053]\n",
      " [0.50201471]\n",
      " [0.5019216 ]]\n",
      "Error [[-0.50162347]\n",
      " [ 0.49838947]\n",
      " [ 0.49798529]\n",
      " [-0.5019216 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22847784 0.91277433]\n",
      " [0.80175481 1.34041749]\n",
      " [0.96251239 1.08956082]\n",
      " [1.53578936 1.51720398]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55687227 0.71356754]\n",
      " [0.69034973 0.79255859]\n",
      " [0.72362455 0.74829901]\n",
      " [0.82285179 0.82012638]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0064481 ]\n",
      " [0.00643285]\n",
      " [0.0080618 ]\n",
      " [0.00771586]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50161202]\n",
      " [0.50160821]\n",
      " [0.50201544]\n",
      " [0.50192896]]\n",
      "Error [[-0.50161202]\n",
      " [ 0.49839179]\n",
      " [ 0.49798456]\n",
      " [-0.50192896]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22848129 0.91277486]\n",
      " [0.80177077 1.34041298]\n",
      " [0.96252574 1.08954875]\n",
      " [1.53581522 1.51718687]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55687312 0.71356765]\n",
      " [0.69035314 0.79255785]\n",
      " [0.72362722 0.74829674]\n",
      " [0.82285556 0.82012386]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00640255]\n",
      " [0.00642381]\n",
      " [0.00806497]\n",
      " [0.00774553]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50160063]\n",
      " [0.50160595]\n",
      " [0.50201623]\n",
      " [0.50193637]]\n",
      "Error [[-0.50160063]\n",
      " [ 0.49839405]\n",
      " [ 0.49798377]\n",
      " [-0.50193637]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2284848  0.9127754 ]\n",
      " [0.80178705 1.34040847]\n",
      " [0.96253936 1.08953665]\n",
      " [1.53584161 1.51716972]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55687399 0.71356776]\n",
      " [0.69035662 0.79255711]\n",
      " [0.72362994 0.74829446]\n",
      " [0.8228594  0.82012133]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0063572 ]\n",
      " [0.00641501]\n",
      " [0.00806838]\n",
      " [0.00777544]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5015893 ]\n",
      " [0.50160375]\n",
      " [0.50201708]\n",
      " [0.50194385]]\n",
      "Error [[-0.5015893 ]\n",
      " [ 0.49839625]\n",
      " [ 0.49798292]\n",
      " [-0.50194385]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22848839 0.91277593]\n",
      " [0.80180365 1.34040394]\n",
      " [0.96255325 1.08952453]\n",
      " [1.53586851 1.51715255]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55687487 0.71356787]\n",
      " [0.69036017 0.79255636]\n",
      " [0.72363272 0.74829218]\n",
      " [0.82286333 0.8201188 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00631207]\n",
      " [0.00640642]\n",
      " [0.008072  ]\n",
      " [0.00780558]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50157801]\n",
      " [0.5016016 ]\n",
      " [0.50201799]\n",
      " [0.50195138]]\n",
      "Error [[-0.50157801]\n",
      " [ 0.4983984 ]\n",
      " [ 0.49798201]\n",
      " [-0.50195138]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22849204 0.91277646]\n",
      " [0.80182057 1.34039941]\n",
      " [0.96256741 1.08951239]\n",
      " [1.53589594 1.51713534]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55687578 0.71356798]\n",
      " [0.69036378 0.79255562]\n",
      " [0.72363555 0.74828989]\n",
      " [0.82286732 0.82011626]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00626712]\n",
      " [0.00639805]\n",
      " [0.00807582]\n",
      " [0.00783593]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50156678]\n",
      " [0.50159951]\n",
      " [0.50201894]\n",
      " [0.50195897]]\n",
      "Error [[-0.50156678]\n",
      " [ 0.49840049]\n",
      " [ 0.49798106]\n",
      " [-0.50195897]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22849577 0.91277699]\n",
      " [0.80183781 1.34039486]\n",
      " [0.96258184 1.08950023]\n",
      " [1.53592388 1.5171181 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55687669 0.71356809]\n",
      " [0.69036747 0.79255487]\n",
      " [0.72363843 0.7482876 ]\n",
      " [0.8228714  0.82011371]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00622237]\n",
      " [0.00638987]\n",
      " [0.00807984]\n",
      " [0.00786649]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50155559]\n",
      " [0.50159746]\n",
      " [0.50201995]\n",
      " [0.50196661]]\n",
      "Error [[-0.50155559]\n",
      " [ 0.49840254]\n",
      " [ 0.49798005]\n",
      " [-0.50196661]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22849956 0.91277753]\n",
      " [0.80185538 1.34039031]\n",
      " [0.96259654 1.08948804]\n",
      " [1.53595235 1.51710083]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55687763 0.71356819]\n",
      " [0.69037122 0.79255412]\n",
      " [0.72364137 0.7482853 ]\n",
      " [0.82287555 0.82011117]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00617779]\n",
      " [0.00638188]\n",
      " [0.00808405]\n",
      " [0.00789725]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50154444]\n",
      " [0.50159546]\n",
      " [0.502021  ]\n",
      " [0.5019743 ]]\n",
      "Error [[-0.50154444]\n",
      " [ 0.49840454]\n",
      " [ 0.497979  ]\n",
      " [-0.5019743 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22850343 0.91277806]\n",
      " [0.80187326 1.34038575]\n",
      " [0.96261151 1.08947583]\n",
      " [1.53598134 1.51708353]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55687858 0.7135683 ]\n",
      " [0.69037505 0.79255337]\n",
      " [0.72364437 0.748283  ]\n",
      " [0.82287977 0.82010861]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00613337]\n",
      " [0.00637407]\n",
      " [0.00808844]\n",
      " [0.00792819]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50153334]\n",
      " [0.50159351]\n",
      " [0.5020221 ]\n",
      " [0.50198204]]\n",
      "Error [[-0.50153334]\n",
      " [ 0.49840649]\n",
      " [ 0.4979779 ]\n",
      " [-0.50198204]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22850736 0.91277859]\n",
      " [0.80189147 1.34038119]\n",
      " [0.96262674 1.0894636 ]\n",
      " [1.53601085 1.51706619]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55687956 0.71356841]\n",
      " [0.69037894 0.79255262]\n",
      " [0.72364741 0.7482807 ]\n",
      " [0.82288407 0.82010606]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00608912]\n",
      " [0.00636642]\n",
      " [0.00809299]\n",
      " [0.0079593 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50152228]\n",
      " [0.5015916 ]\n",
      " [0.50202324]\n",
      " [0.50198981]]\n",
      "Error [[-0.50152228]\n",
      " [ 0.4984084 ]\n",
      " [ 0.49797676]\n",
      " [-0.50198981]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22851137 0.91277912]\n",
      " [0.80191001 1.34037661]\n",
      " [0.96264225 1.08945134]\n",
      " [1.53604089 1.51704883]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55688054 0.71356852]\n",
      " [0.6903829  0.79255187]\n",
      " [0.72365052 0.74827839]\n",
      " [0.82288845 0.82010349]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00604502]\n",
      " [0.00635894]\n",
      " [0.0080977 ]\n",
      " [0.00799058]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50151125]\n",
      " [0.50158973]\n",
      " [0.50202441]\n",
      " [0.50199763]]\n",
      "Error [[-0.50151125]\n",
      " [ 0.49841027]\n",
      " [ 0.49797559]\n",
      " [-0.50199763]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22851544 0.91277966]\n",
      " [0.80192886 1.34037203]\n",
      " [0.96265802 1.08943907]\n",
      " [1.53607144 1.51703144]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55688155 0.71356863]\n",
      " [0.69038693 0.79255111]\n",
      " [0.72365367 0.74827608]\n",
      " [0.8228929  0.82010093]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00600106]\n",
      " [0.00635162]\n",
      " [0.00810257]\n",
      " [0.00802202]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50150026]\n",
      " [0.5015879 ]\n",
      " [0.50202563]\n",
      " [0.50200549]]\n",
      "Error [[-0.50150026]\n",
      " [ 0.4984121 ]\n",
      " [ 0.49797437]\n",
      " [-0.50200549]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22851959 0.91278019]\n",
      " [0.80194804 1.34036744]\n",
      " [0.96267407 1.08942677]\n",
      " [1.53610252 1.51701401]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55688257 0.71356874]\n",
      " [0.69039103 0.79255036]\n",
      " [0.72365688 0.74827376]\n",
      " [0.82289743 0.82009836]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00595723]\n",
      " [0.00634443]\n",
      " [0.00810757]\n",
      " [0.00805361]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5014893 ]\n",
      " [0.5015861 ]\n",
      " [0.50202688]\n",
      " [0.50201339]]\n",
      "Error [[-0.5014893 ]\n",
      " [ 0.4984139 ]\n",
      " [ 0.49797312]\n",
      " [-0.50201339]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22852381 0.91278073]\n",
      " [0.80196754 1.34036283]\n",
      " [0.96269038 1.08941445]\n",
      " [1.53613412 1.51699656]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55688361 0.71356885]\n",
      " [0.6903952  0.7925496 ]\n",
      " [0.72366014 0.74827144]\n",
      " [0.82290204 0.82009578]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00591354]\n",
      " [0.00633739]\n",
      " [0.00811272]\n",
      " [0.00808534]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50147838]\n",
      " [0.50158434]\n",
      " [0.50202817]\n",
      " [0.50202132]]\n",
      "Error [[-0.50147838]\n",
      " [ 0.49841566]\n",
      " [ 0.49797183]\n",
      " [-0.50202132]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22852809 0.91278126]\n",
      " [0.80198736 1.34035823]\n",
      " [0.96270697 1.0894021 ]\n",
      " [1.53616623 1.51697907]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55688467 0.71356896]\n",
      " [0.69039944 0.79254885]\n",
      " [0.72366346 0.74826912]\n",
      " [0.82290672 0.8200932 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00586997]\n",
      " [0.00633048]\n",
      " [0.00811799]\n",
      " [0.00811721]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50146749]\n",
      " [0.50158261]\n",
      " [0.50202949]\n",
      " [0.50202929]]\n",
      "Error [[-0.50146749]\n",
      " [ 0.49841739]\n",
      " [ 0.49797051]\n",
      " [-0.50202929]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22853245 0.9127818 ]\n",
      " [0.8020075  1.34035361]\n",
      " [0.96272382 1.08938974]\n",
      " [1.53619888 1.51696155]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55688575 0.71356907]\n",
      " [0.69040374 0.79254809]\n",
      " [0.72366683 0.74826679]\n",
      " [0.82291147 0.82009062]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00582652]\n",
      " [0.00632369]\n",
      " [0.00812339]\n",
      " [0.00814921]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50145663]\n",
      " [0.50158092]\n",
      " [0.50203084]\n",
      " [0.50203729]]\n",
      "Error [[-0.50145663]\n",
      " [ 0.49841908]\n",
      " [ 0.49796916]\n",
      " [-0.50203729]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22853688 0.91278233]\n",
      " [0.80202797 1.34034898]\n",
      " [0.96274095 1.08937735]\n",
      " [1.53623204 1.516944  ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55688684 0.71356918]\n",
      " [0.69040812 0.79254733]\n",
      " [0.72367025 0.74826445]\n",
      " [0.82291631 0.82008803]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00578318]\n",
      " [0.00631702]\n",
      " [0.00812891]\n",
      " [0.00818133]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50144579]\n",
      " [0.50157925]\n",
      " [0.50203222]\n",
      " [0.50204532]]\n",
      "Error [[-0.50144579]\n",
      " [ 0.49842075]\n",
      " [ 0.49796778]\n",
      " [-0.50204532]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22854137 0.91278287]\n",
      " [0.80204876 1.34034435]\n",
      " [0.96275834 1.08936494]\n",
      " [1.53626572 1.51692643]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55688795 0.71356929]\n",
      " [0.69041256 0.79254656]\n",
      " [0.72367373 0.74826212]\n",
      " [0.82292122 0.82008544]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00573994]\n",
      " [0.00631046]\n",
      " [0.00813453]\n",
      " [0.00821356]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50143498]\n",
      " [0.50157761]\n",
      " [0.50203362]\n",
      " [0.50205338]]\n",
      "Error [[-0.50143498]\n",
      " [ 0.49842239]\n",
      " [ 0.49796638]\n",
      " [-0.50205338]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22854594 0.9127834 ]\n",
      " [0.80206987 1.34033971]\n",
      " [0.962776   1.08935251]\n",
      " [1.53629993 1.51690882]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55688908 0.71356939]\n",
      " [0.69041707 0.7925458 ]\n",
      " [0.72367726 0.74825978]\n",
      " [0.8229262  0.82008284]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00569681]\n",
      " [0.00630402]\n",
      " [0.00814027]\n",
      " [0.00824591]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5014242 ]\n",
      " [0.501576  ]\n",
      " [0.50203506]\n",
      " [0.50206147]]\n",
      "Error [[-0.5014242 ]\n",
      " [ 0.498424  ]\n",
      " [ 0.49796494]\n",
      " [-0.50206147]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22855058 0.91278394]\n",
      " [0.8020913  1.34033506]\n",
      " [0.96279394 1.08934005]\n",
      " [1.53633466 1.51689118]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55689022 0.7135695 ]\n",
      " [0.69042165 0.79254504]\n",
      " [0.72368085 0.74825743]\n",
      " [0.82293126 0.82008023]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00565377]\n",
      " [0.00629767]\n",
      " [0.0081461 ]\n",
      " [0.00827836]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50141344]\n",
      " [0.50157441]\n",
      " [0.50203651]\n",
      " [0.50206958]]\n",
      "Error [[-0.50141344]\n",
      " [ 0.49842559]\n",
      " [ 0.49796349]\n",
      " [-0.50206958]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22855529 0.91278447]\n",
      " [0.80211306 1.3403304 ]\n",
      " [0.96281214 1.08932758]\n",
      " [1.53636991 1.51687351]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55689138 0.71356961]\n",
      " [0.6904263  0.79254427]\n",
      " [0.72368449 0.74825508]\n",
      " [0.8229364  0.82007763]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00561082]\n",
      " [0.00629142]\n",
      " [0.00815203]\n",
      " [0.00831091]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5014027 ]\n",
      " [0.50157285]\n",
      " [0.502038  ]\n",
      " [0.50207772]]\n",
      "Error [[-0.5014027 ]\n",
      " [ 0.49842715]\n",
      " [ 0.497962  ]\n",
      " [-0.50207772]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22856007 0.91278501]\n",
      " [0.80213514 1.34032574]\n",
      " [0.96283061 1.08931508]\n",
      " [1.53640568 1.51685581]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55689256 0.71356972]\n",
      " [0.69043102 0.7925435 ]\n",
      " [0.72368818 0.74825272]\n",
      " [0.82294161 0.82007502]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00556796]\n",
      " [0.00628527]\n",
      " [0.00815805]\n",
      " [0.00834356]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50139199]\n",
      " [0.50157131]\n",
      " [0.5020395 ]\n",
      " [0.50208588]]\n",
      "Error [[-0.50139199]\n",
      " [ 0.49842869]\n",
      " [ 0.4979605 ]\n",
      " [-0.50208588]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22856492 0.91278555]\n",
      " [0.80215754 1.34032107]\n",
      " [0.96284935 1.08930256]\n",
      " [1.53644197 1.51683808]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55689376 0.71356983]\n",
      " [0.69043581 0.79254274]\n",
      " [0.72369193 0.74825037]\n",
      " [0.8229469  0.8200724 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00552518]\n",
      " [0.0062792 ]\n",
      " [0.00816416]\n",
      " [0.00837629]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50138129]\n",
      " [0.50156979]\n",
      " [0.50204103]\n",
      " [0.50209406]]\n",
      "Error [[-0.50138129]\n",
      " [ 0.49843021]\n",
      " [ 0.49795897]\n",
      " [-0.50209406]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22856984 0.91278608]\n",
      " [0.80218026 1.34031639]\n",
      " [0.96286837 1.08929002]\n",
      " [1.53647879 1.51682032]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55689497 0.71356994]\n",
      " [0.69044067 0.79254197]\n",
      " [0.72369573 0.748248  ]\n",
      " [0.82295226 0.82006978]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00548248]\n",
      " [0.00627322]\n",
      " [0.00817035]\n",
      " [0.00840911]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50137062]\n",
      " [0.5015683 ]\n",
      " [0.50204258]\n",
      " [0.50210227]]\n",
      "Error [[-0.50137062]\n",
      " [ 0.4984317 ]\n",
      " [ 0.49795742]\n",
      " [-0.50210227]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22857483 0.91278662]\n",
      " [0.80220331 1.3403117 ]\n",
      " [0.96288765 1.08927746]\n",
      " [1.53651613 1.51680253]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5568962  0.71357005]\n",
      " [0.69044559 0.7925412 ]\n",
      " [0.72369959 0.74824564]\n",
      " [0.8229577  0.82006715]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00543986]\n",
      " [0.00626731]\n",
      " [0.00817662]\n",
      " [0.00844202]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50135996]\n",
      " [0.50156682]\n",
      " [0.50204414]\n",
      " [0.50211049]]\n",
      "Error [[-0.50135996]\n",
      " [ 0.49843318]\n",
      " [ 0.49795586]\n",
      " [-0.50211049]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22857989 0.91278716]\n",
      " [0.80222668 1.340307  ]\n",
      " [0.9629072  1.08926487]\n",
      " [1.53655399 1.51678471]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55689745 0.71357016]\n",
      " [0.69045059 0.79254042]\n",
      " [0.7237035  0.74824327]\n",
      " [0.82296322 0.82006452]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0053973 ]\n",
      " [0.00626149]\n",
      " [0.00818296]\n",
      " [0.008475  ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50134932]\n",
      " [0.50156537]\n",
      " [0.50204573]\n",
      " [0.50211874]]\n",
      "Error [[-0.50134932]\n",
      " [ 0.49843463]\n",
      " [ 0.49795427]\n",
      " [-0.50211874]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22858503 0.9127877 ]\n",
      " [0.80225037 1.34030229]\n",
      " [0.96292702 1.08925226]\n",
      " [1.53659237 1.51676686]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55689872 0.71357027]\n",
      " [0.69045565 0.79253965]\n",
      " [0.72370746 0.74824089]\n",
      " [0.82296881 0.82006189]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00535482]\n",
      " [0.00625573]\n",
      " [0.00818938]\n",
      " [0.00850805]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5013387 ]\n",
      " [0.50156393]\n",
      " [0.50204733]\n",
      " [0.502127  ]]\n",
      "Error [[-0.5013387 ]\n",
      " [ 0.49843607]\n",
      " [ 0.49795267]\n",
      " [-0.502127  ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22859023 0.91278824]\n",
      " [0.80227439 1.34029758]\n",
      " [0.96294711 1.08923963]\n",
      " [1.53663127 1.51674898]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5569     0.71357038]\n",
      " [0.69046078 0.79253887]\n",
      " [0.72371148 0.74823851]\n",
      " [0.82297448 0.82005925]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0053124 ]\n",
      " [0.00625005]\n",
      " [0.00819586]\n",
      " [0.00854118]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5013281 ]\n",
      " [0.50156251]\n",
      " [0.50204895]\n",
      " [0.50213528]]\n",
      "Error [[-0.5013281 ]\n",
      " [ 0.49843749]\n",
      " [ 0.49795105]\n",
      " [-0.50213528]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2285955  0.91278877]\n",
      " [0.80229873 1.34029286]\n",
      " [0.96296747 1.08922698]\n",
      " [1.5366707  1.51673107]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55690131 0.71357049]\n",
      " [0.69046599 0.7925381 ]\n",
      " [0.72371555 0.74823613]\n",
      " [0.82298022 0.82005661]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00527004]\n",
      " [0.00624443]\n",
      " [0.00820241]\n",
      " [0.00857437]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50131751]\n",
      " [0.5015611 ]\n",
      " [0.50205059]\n",
      " [0.50214358]]\n",
      "Error [[-0.50131751]\n",
      " [ 0.4984389 ]\n",
      " [ 0.49794941]\n",
      " [-0.50214358]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22860085 0.91278931]\n",
      " [0.80232339 1.34028813]\n",
      " [0.9629881  1.08921431]\n",
      " [1.53671065 1.51671313]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55690262 0.7135706 ]\n",
      " [0.69047126 0.79253732]\n",
      " [0.72371967 0.74823374]\n",
      " [0.82298604 0.82005396]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00522774]\n",
      " [0.00623887]\n",
      " [0.00820902]\n",
      " [0.00860763]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50130693]\n",
      " [0.50155971]\n",
      " [0.50205224]\n",
      " [0.50215189]]\n",
      "Error [[-0.50130693]\n",
      " [ 0.49844029]\n",
      " [ 0.49794776]\n",
      " [-0.50215189]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22860626 0.91278985]\n",
      " [0.80234837 1.3402834 ]\n",
      " [0.963009   1.08920162]\n",
      " [1.53675112 1.51669516]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55690396 0.71357071]\n",
      " [0.6904766  0.79253654]\n",
      " [0.72372385 0.74823135]\n",
      " [0.82299194 0.82005131]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00518549]\n",
      " [0.00623338]\n",
      " [0.00821569]\n",
      " [0.00864094]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50129637]\n",
      " [0.50155834]\n",
      " [0.50205391]\n",
      " [0.50216022]]\n",
      "Error [[-0.50129637]\n",
      " [ 0.49844166]\n",
      " [ 0.49794609]\n",
      " [-0.50216022]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22861174 0.91279039]\n",
      " [0.80237368 1.34027865]\n",
      " [0.96303017 1.0891889 ]\n",
      " [1.53679211 1.51667716]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55690531 0.71357082]\n",
      " [0.690482   0.79253576]\n",
      " [0.72372809 0.74822896]\n",
      " [0.82299791 0.82004865]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0051433 ]\n",
      " [0.00622794]\n",
      " [0.00822242]\n",
      " [0.00867432]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50128582]\n",
      " [0.50155698]\n",
      " [0.50205559]\n",
      " [0.50216857]]\n",
      "Error [[-0.50128582]\n",
      " [ 0.49844302]\n",
      " [ 0.49794441]\n",
      " [-0.50216857]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2286173  0.91279093]\n",
      " [0.80239931 1.3402739 ]\n",
      " [0.96305161 1.08917616]\n",
      " [1.53683362 1.51665913]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55690668 0.71357093]\n",
      " [0.69048748 0.79253498]\n",
      " [0.72373237 0.74822656]\n",
      " [0.82300396 0.82004599]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00510116]\n",
      " [0.00622255]\n",
      " [0.0082292 ]\n",
      " [0.00870775]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50127529]\n",
      " [0.50155563]\n",
      " [0.50205729]\n",
      " [0.50217692]]\n",
      "Error [[-0.50127529]\n",
      " [ 0.49844437]\n",
      " [ 0.49794271]\n",
      " [-0.50217692]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22862293 0.91279148]\n",
      " [0.80242526 1.34026914]\n",
      " [0.96307332 1.0891634 ]\n",
      " [1.53687566 1.51664107]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55690807 0.71357105]\n",
      " [0.69049303 0.7925342 ]\n",
      " [0.72373671 0.74822415]\n",
      " [0.82301008 0.82004333]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00505907]\n",
      " [0.00621722]\n",
      " [0.00823603]\n",
      " [0.00874123]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50126476]\n",
      " [0.5015543 ]\n",
      " [0.50205899]\n",
      " [0.50218529]]\n",
      "Error [[-0.50126476]\n",
      " [ 0.4984457 ]\n",
      " [ 0.49794101]\n",
      " [-0.50218529]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22862862 0.91279202]\n",
      " [0.80245153 1.34026437]\n",
      " [0.9630953  1.08915062]\n",
      " [1.53691821 1.51662298]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55690948 0.71357116]\n",
      " [0.69049864 0.79253341]\n",
      " [0.72374111 0.74822174]\n",
      " [0.82301628 0.82004066]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00501702]\n",
      " [0.00621194]\n",
      " [0.0082429 ]\n",
      " [0.00877477]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50125425]\n",
      " [0.50155298]\n",
      " [0.50206071]\n",
      " [0.50219368]]\n",
      "Error [[-0.50125425]\n",
      " [ 0.49844702]\n",
      " [ 0.49793929]\n",
      " [-0.50219368]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22863439 0.91279256]\n",
      " [0.80247813 1.3402596 ]\n",
      " [0.96311755 1.08913782]\n",
      " [1.53696129 1.51660486]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5569109  0.71357127]\n",
      " [0.69050433 0.79253263]\n",
      " [0.72374556 0.74821933]\n",
      " [0.82302255 0.82003798]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00497502]\n",
      " [0.00620671]\n",
      " [0.00824983]\n",
      " [0.00880835]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50124375]\n",
      " [0.50155167]\n",
      " [0.50206245]\n",
      " [0.50220207]]\n",
      "Error [[-0.50124375]\n",
      " [ 0.49844833]\n",
      " [ 0.49793755]\n",
      " [-0.50220207]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22864023 0.9127931 ]\n",
      " [0.80250505 1.34025482]\n",
      " [0.96314007 1.08912499]\n",
      " [1.5370049  1.51658671]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55691234 0.71357138]\n",
      " [0.69051008 0.79253184]\n",
      " [0.72375006 0.74821692]\n",
      " [0.8230289  0.82003531]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00493306]\n",
      " [0.00620152]\n",
      " [0.0082568 ]\n",
      " [0.00884197]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50123326]\n",
      " [0.50155037]\n",
      " [0.50206419]\n",
      " [0.50221048]]\n",
      "Error [[-0.50123326]\n",
      " [ 0.49844963]\n",
      " [ 0.49793581]\n",
      " [-0.50221048]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22864614 0.91279364]\n",
      " [0.80253229 1.34025002]\n",
      " [0.96316286 1.08911215]\n",
      " [1.53704902 1.51656853]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5569138  0.71357149]\n",
      " [0.6905159  0.79253105]\n",
      " [0.72375462 0.7482145 ]\n",
      " [0.82303533 0.82003262]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00489114]\n",
      " [0.00619637]\n",
      " [0.00826381]\n",
      " [0.00887564]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50122278]\n",
      " [0.50154909]\n",
      " [0.50206594]\n",
      " [0.5022189 ]]\n",
      "Error [[-0.50122278]\n",
      " [ 0.49845091]\n",
      " [ 0.49793406]\n",
      " [-0.5022189 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22865212 0.91279419]\n",
      " [0.80255986 1.34024523]\n",
      " [0.96318592 1.08909928]\n",
      " [1.53709367 1.51655032]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55691528 0.7135716 ]\n",
      " [0.69052179 0.79253027]\n",
      " [0.72375923 0.74821207]\n",
      " [0.82304183 0.82002994]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00484926]\n",
      " [0.00619127]\n",
      " [0.00827086]\n",
      " [0.00890936]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50121231]\n",
      " [0.50154781]\n",
      " [0.5020677 ]\n",
      " [0.50222732]]\n",
      "Error [[-0.50121231]\n",
      " [ 0.49845219]\n",
      " [ 0.4979323 ]\n",
      " [-0.50222732]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22865817 0.91279473]\n",
      " [0.80258775 1.34024042]\n",
      " [0.96320925 1.08908639]\n",
      " [1.53713883 1.51653208]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55691677 0.71357171]\n",
      " [0.69052775 0.79252948]\n",
      " [0.72376389 0.74820964]\n",
      " [0.82304841 0.82002724]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00480742]\n",
      " [0.0061862 ]\n",
      " [0.00827795]\n",
      " [0.00894311]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50120185]\n",
      " [0.50154655]\n",
      " [0.50206948]\n",
      " [0.50223576]]\n",
      "Error [[-0.50120185]\n",
      " [ 0.49845345]\n",
      " [ 0.49793052]\n",
      " [-0.50223576]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22866429 0.91279527]\n",
      " [0.80261596 1.34023561]\n",
      " [0.96323285 1.08907348]\n",
      " [1.53718452 1.51651381]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55691828 0.71357182]\n",
      " [0.69053378 0.79252868]\n",
      " [0.72376861 0.74820721]\n",
      " [0.82305507 0.82002455]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00476561]\n",
      " [0.00618118]\n",
      " [0.00828508]\n",
      " [0.0089769 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5011914 ]\n",
      " [0.50154529]\n",
      " [0.50207126]\n",
      " [0.50224421]]\n",
      "Error [[-0.5011914 ]\n",
      " [ 0.49845471]\n",
      " [ 0.49792874]\n",
      " [-0.50224421]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22867048 0.91279582]\n",
      " [0.8026445  1.34023078]\n",
      " [0.96325672 1.08906054]\n",
      " [1.53723074 1.51649551]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55691981 0.71357193]\n",
      " [0.69053988 0.79252789]\n",
      " [0.72377338 0.74820477]\n",
      " [0.8230618  0.82002185]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00472383]\n",
      " [0.00617619]\n",
      " [0.00829225]\n",
      " [0.00901072]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50118096]\n",
      " [0.50154404]\n",
      " [0.50207305]\n",
      " [0.50225267]]\n",
      "Error [[-0.50118096]\n",
      " [ 0.49845596]\n",
      " [ 0.49792695]\n",
      " [-0.50225267]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22867674 0.91279636]\n",
      " [0.80267335 1.34022596]\n",
      " [0.96328086 1.08904759]\n",
      " [1.53727747 1.51647718]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55692135 0.71357204]\n",
      " [0.69054605 0.7925271 ]\n",
      " [0.72377821 0.74820233]\n",
      " [0.8230686  0.82001914]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00468209]\n",
      " [0.00617124]\n",
      " [0.00829944]\n",
      " [0.00904459]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50117052]\n",
      " [0.5015428 ]\n",
      " [0.50207485]\n",
      " [0.50226113]]\n",
      "Error [[-0.50117052]\n",
      " [ 0.4984572 ]\n",
      " [ 0.49792515]\n",
      " [-0.50226113]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22868308 0.91279691]\n",
      " [0.80270254 1.34022112]\n",
      " [0.96330527 1.08903461]\n",
      " [1.53732473 1.51645882]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55692292 0.71357216]\n",
      " [0.69055228 0.7925263 ]\n",
      " [0.72378309 0.74819989]\n",
      " [0.82307548 0.82001643]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00464037]\n",
      " [0.00616632]\n",
      " [0.00830667]\n",
      " [0.00907848]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50116009]\n",
      " [0.50154157]\n",
      " [0.50207666]\n",
      " [0.5022696 ]]\n",
      "Error [[-0.50116009]\n",
      " [ 0.49845843]\n",
      " [ 0.49792334]\n",
      " [-0.5022696 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22868948 0.91279745]\n",
      " [0.80273204 1.34021627]\n",
      " [0.96332995 1.08902162]\n",
      " [1.53737251 1.51644044]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5569245  0.71357227]\n",
      " [0.69055859 0.79252551]\n",
      " [0.72378802 0.74819744]\n",
      " [0.82308244 0.82001372]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00459869]\n",
      " [0.00616143]\n",
      " [0.00831394]\n",
      " [0.00911241]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50114967]\n",
      " [0.50154035]\n",
      " [0.50207847]\n",
      " [0.50227809]]\n",
      "Error [[-0.50114967]\n",
      " [ 0.49845965]\n",
      " [ 0.49792153]\n",
      " [-0.50227809]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22869596 0.912798  ]\n",
      " [0.80276187 1.34021142]\n",
      " [0.9633549  1.0890086 ]\n",
      " [1.53742081 1.51642202]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55692609 0.71357238]\n",
      " [0.69056496 0.79252471]\n",
      " [0.72379301 0.74819499]\n",
      " [0.82308947 0.820011  ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00455703]\n",
      " [0.00615657]\n",
      " [0.00832123]\n",
      " [0.00914637]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50113926]\n",
      " [0.50153914]\n",
      " [0.50208029]\n",
      " [0.50228658]]\n",
      "Error [[-0.50113926]\n",
      " [ 0.49846086]\n",
      " [ 0.49791971]\n",
      " [-0.50228658]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2287025  0.91279855]\n",
      " [0.80279202 1.34020656]\n",
      " [0.96338012 1.08899556]\n",
      " [1.53746963 1.51640357]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55692771 0.71357249]\n",
      " [0.6905714  0.79252391]\n",
      " [0.72379805 0.74819253]\n",
      " [0.82309658 0.82000828]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0045154 ]\n",
      " [0.00615175]\n",
      " [0.00832855]\n",
      " [0.00918035]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50112885]\n",
      " [0.50153793]\n",
      " [0.50208213]\n",
      " [0.50229507]]\n",
      "Error [[-0.50112885]\n",
      " [ 0.49846207]\n",
      " [ 0.49791787]\n",
      " [-0.50229507]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22870912 0.91279909]\n",
      " [0.80282249 1.34020169]\n",
      " [0.96340561 1.08898249]\n",
      " [1.53751898 1.51638509]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55692934 0.7135726 ]\n",
      " [0.69057791 0.79252311]\n",
      " [0.72380315 0.74819007]\n",
      " [0.82310377 0.82000555]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0044738 ]\n",
      " [0.00614695]\n",
      " [0.0083359 ]\n",
      " [0.00921437]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50111845]\n",
      " [0.50153673]\n",
      " [0.50208396]\n",
      " [0.50230358]]\n",
      "Error [[-0.50111845]\n",
      " [ 0.49846327]\n",
      " [ 0.49791604]\n",
      " [-0.50230358]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2287158  0.91279964]\n",
      " [0.80285328 1.34019682]\n",
      " [0.96343136 1.08896941]\n",
      " [1.53756884 1.51636659]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55693099 0.71357271]\n",
      " [0.6905845  0.79252231]\n",
      " [0.7238083  0.7481876 ]\n",
      " [0.82311103 0.82000282]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00443222]\n",
      " [0.00614218]\n",
      " [0.00834327]\n",
      " [0.00924841]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50110805]\n",
      " [0.50153554]\n",
      " [0.50208581]\n",
      " [0.50231209]]\n",
      "Error [[-0.50110805]\n",
      " [ 0.49846446]\n",
      " [ 0.49791419]\n",
      " [-0.50231209]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22872256 0.91280019]\n",
      " [0.8028844  1.34019193]\n",
      " [0.96345739 1.0889563 ]\n",
      " [1.53761923 1.51634805]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55693266 0.71357283]\n",
      " [0.69059114 0.7925215 ]\n",
      " [0.7238135  0.74818514]\n",
      " [0.82311837 0.82000008]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00439066]\n",
      " [0.00613743]\n",
      " [0.00835067]\n",
      " [0.00928248]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50109766]\n",
      " [0.50153435]\n",
      " [0.50208766]\n",
      " [0.5023206 ]]\n",
      "Error [[-0.50109766]\n",
      " [ 0.49846565]\n",
      " [ 0.49791234]\n",
      " [-0.5023206 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22872939 0.91280074]\n",
      " [0.80291585 1.34018704]\n",
      " [0.96348369 1.08894318]\n",
      " [1.53767015 1.51632948]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55693434 0.71357294]\n",
      " [0.69059786 0.7925207 ]\n",
      " [0.72381876 0.74818266]\n",
      " [0.82312578 0.81999734]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00434913]\n",
      " [0.00613271]\n",
      " [0.00835809]\n",
      " [0.00931657]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50108728]\n",
      " [0.50153317]\n",
      " [0.50208951]\n",
      " [0.50232913]]\n",
      "Error [[-0.50108728]\n",
      " [ 0.49846683]\n",
      " [ 0.49791049]\n",
      " [-0.50232913]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22873629 0.91280129]\n",
      " [0.80294761 1.34018215]\n",
      " [0.96351026 1.08893003]\n",
      " [1.53772158 1.51631089]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55693605 0.71357305]\n",
      " [0.69060465 0.79251989]\n",
      " [0.72382407 0.74818019]\n",
      " [0.82313327 0.8199946 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00430762]\n",
      " [0.00612802]\n",
      " [0.00836554]\n",
      " [0.00935069]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5010769 ]\n",
      " [0.501532  ]\n",
      " [0.50209137]\n",
      " [0.50233766]]\n",
      "Error [[-0.5010769 ]\n",
      " [ 0.498468  ]\n",
      " [ 0.49790863]\n",
      " [-0.50233766]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22874326 0.91280183]\n",
      " [0.8029797  1.34017724]\n",
      " [0.9635371  1.08891686]\n",
      " [1.53777354 1.51629226]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55693777 0.71357316]\n",
      " [0.69061151 0.79251909]\n",
      " [0.72382943 0.7481777 ]\n",
      " [0.82314083 0.81999185]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00426613]\n",
      " [0.00612335]\n",
      " [0.00837301]\n",
      " [0.00938483]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50106653]\n",
      " [0.50153083]\n",
      " [0.50209324]\n",
      " [0.50234619]]\n",
      "Error [[-0.50106653]\n",
      " [ 0.49846917]\n",
      " [ 0.49790676]\n",
      " [-0.50234619]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2287503  0.91280238]\n",
      " [0.80301211 1.34017233]\n",
      " [0.96356421 1.08890367]\n",
      " [1.53782601 1.51627361]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5569395  0.71357327]\n",
      " [0.69061843 0.79251828]\n",
      " [0.72383485 0.74817522]\n",
      " [0.82314847 0.81998909]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00422466]\n",
      " [0.0061187 ]\n",
      " [0.0083805 ]\n",
      " [0.009419  ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50105616]\n",
      " [0.50152967]\n",
      " [0.50209511]\n",
      " [0.50235473]]\n",
      "Error [[-0.50105616]\n",
      " [ 0.49847033]\n",
      " [ 0.49790489]\n",
      " [-0.50235473]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22875742 0.91280293]\n",
      " [0.80304484 1.3401674 ]\n",
      " [0.96359159 1.08889045]\n",
      " [1.53787902 1.51625492]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55694126 0.71357339]\n",
      " [0.69062543 0.79251747]\n",
      " [0.72384032 0.74817273]\n",
      " [0.82315618 0.81998634]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0041832 ]\n",
      " [0.00611407]\n",
      " [0.00838802]\n",
      " [0.00945318]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5010458 ]\n",
      " [0.50152851]\n",
      " [0.50209699]\n",
      " [0.50236328]]\n",
      "Error [[-0.5010458 ]\n",
      " [ 0.49847149]\n",
      " [ 0.49790301]\n",
      " [-0.50236328]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2287646  0.91280348]\n",
      " [0.8030779  1.34016248]\n",
      " [0.96361924 1.08887722]\n",
      " [1.53793254 1.51623621]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55694303 0.7135735 ]\n",
      " [0.69063249 0.79251666]\n",
      " [0.72384585 0.74817024]\n",
      " [0.82316398 0.81998357]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00414177]\n",
      " [0.00610947]\n",
      " [0.00839555]\n",
      " [0.00948739]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50103544]\n",
      " [0.50152736]\n",
      " [0.50209888]\n",
      " [0.50237183]]\n",
      "Error [[-0.50103544]\n",
      " [ 0.49847264]\n",
      " [ 0.49790112]\n",
      " [-0.50237183]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22877186 0.91280404]\n",
      " [0.80311128 1.34015754]\n",
      " [0.96364716 1.08886396]\n",
      " [1.53798658 1.51621746]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55694482 0.71357361]\n",
      " [0.69063962 0.79251585]\n",
      " [0.72385143 0.74816774]\n",
      " [0.82317184 0.81998081]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00410035]\n",
      " [0.00610489]\n",
      " [0.0084031 ]\n",
      " [0.00952161]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50102509]\n",
      " [0.50152622]\n",
      " [0.50210076]\n",
      " [0.50238039]]\n",
      "Error [[-0.50102509]\n",
      " [ 0.49847378]\n",
      " [ 0.49789924]\n",
      " [-0.50238039]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22877918 0.91280459]\n",
      " [0.80314499 1.3401526 ]\n",
      " [0.96367535 1.08885068]\n",
      " [1.53804115 1.51619869]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55694663 0.71357372]\n",
      " [0.69064682 0.79251503]\n",
      " [0.72385707 0.74816524]\n",
      " [0.82317979 0.81997804]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00405895]\n",
      " [0.00610032]\n",
      " [0.00841068]\n",
      " [0.00955586]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50101474]\n",
      " [0.50152508]\n",
      " [0.50210266]\n",
      " [0.50238895]]\n",
      "Error [[-0.50101474]\n",
      " [ 0.49847492]\n",
      " [ 0.49789734]\n",
      " [-0.50238895]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22878658 0.91280514]\n",
      " [0.80317901 1.34014764]\n",
      " [0.96370381 1.08883738]\n",
      " [1.53809624 1.51617989]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55694846 0.71357384]\n",
      " [0.69065409 0.79251422]\n",
      " [0.72386276 0.74816273]\n",
      " [0.8231878  0.81997526]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00401757]\n",
      " [0.00609578]\n",
      " [0.00841827]\n",
      " [0.00959012]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50100439]\n",
      " [0.50152394]\n",
      " [0.50210455]\n",
      " [0.50239751]]\n",
      "Error [[-0.50100439]\n",
      " [ 0.49847606]\n",
      " [ 0.49789545]\n",
      " [-0.50239751]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22879405 0.91280569]\n",
      " [0.80321337 1.34014268]\n",
      " [0.96373254 1.08882406]\n",
      " [1.53815186 1.51616105]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5569503  0.71357395]\n",
      " [0.69066143 0.7925134 ]\n",
      " [0.7238685  0.74816022]\n",
      " [0.8231959  0.81997248]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0039762 ]\n",
      " [0.00609125]\n",
      " [0.00842587]\n",
      " [0.0096244 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50099405]\n",
      " [0.50152281]\n",
      " [0.50210646]\n",
      " [0.50240608]]\n",
      "Error [[-0.50099405]\n",
      " [ 0.49847719]\n",
      " [ 0.49789354]\n",
      " [-0.50240608]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22880158 0.91280624]\n",
      " [0.80324804 1.34013772]\n",
      " [0.96376154 1.08881072]\n",
      " [1.53820799 1.51614219]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55695216 0.71357406]\n",
      " [0.69066884 0.79251259]\n",
      " [0.72387429 0.74815771]\n",
      " [0.82320407 0.8199697 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00393485]\n",
      " [0.00608674]\n",
      " [0.0084335 ]\n",
      " [0.0096587 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50098371]\n",
      " [0.50152168]\n",
      " [0.50210836]\n",
      " [0.50241466]]\n",
      "Error [[-0.50098371]\n",
      " [ 0.49847832]\n",
      " [ 0.49789164]\n",
      " [-0.50241466]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22880919 0.9128068 ]\n",
      " [0.80328304 1.34013274]\n",
      " [0.96379081 1.08879735]\n",
      " [1.53826465 1.5161233 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55695404 0.71357418]\n",
      " [0.69067632 0.79251177]\n",
      " [0.72388015 0.74815519]\n",
      " [0.82321231 0.81996691]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00389351]\n",
      " [0.00608225]\n",
      " [0.00844114]\n",
      " [0.00969302]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50097338]\n",
      " [0.50152056]\n",
      " [0.50211027]\n",
      " [0.50242324]]\n",
      "Error [[-0.50097338]\n",
      " [ 0.49847944]\n",
      " [ 0.49788973]\n",
      " [-0.50242324]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22881687 0.91280735]\n",
      " [0.80331836 1.34012776]\n",
      " [0.96382035 1.08878397]\n",
      " [1.53832183 1.51610438]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55695593 0.71357429]\n",
      " [0.69068386 0.79251095]\n",
      " [0.72388605 0.74815267]\n",
      " [0.82322064 0.81996411]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00385218]\n",
      " [0.00607778]\n",
      " [0.0084488 ]\n",
      " [0.00972735]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50096304]\n",
      " [0.50151944]\n",
      " [0.50211219]\n",
      " [0.50243182]]\n",
      "Error [[-0.50096304]\n",
      " [ 0.49848056]\n",
      " [ 0.49788781]\n",
      " [-0.50243182]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22882463 0.91280791]\n",
      " [0.803354   1.34012277]\n",
      " [0.96385016 1.08877056]\n",
      " [1.53837953 1.51608543]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55695784 0.7135744 ]\n",
      " [0.69069148 0.79251013]\n",
      " [0.72389201 0.74815014]\n",
      " [0.82322903 0.81996132]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00381087]\n",
      " [0.00607332]\n",
      " [0.00845647]\n",
      " [0.0097617 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50095272]\n",
      " [0.50151832]\n",
      " [0.5021141 ]\n",
      " [0.50244041]]\n",
      "Error [[-0.50095272]\n",
      " [ 0.49848168]\n",
      " [ 0.4978859 ]\n",
      " [-0.50244041]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22883245 0.91280846]\n",
      " [0.80338997 1.34011777]\n",
      " [0.96388024 1.08875713]\n",
      " [1.53843775 1.51606645]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55695977 0.71357452]\n",
      " [0.69069916 0.79250931]\n",
      " [0.72389802 0.74814761]\n",
      " [0.82323751 0.81995851]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00376957]\n",
      " [0.00606888]\n",
      " [0.00846415]\n",
      " [0.00979607]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50094239]\n",
      " [0.50151721]\n",
      " [0.50211603]\n",
      " [0.502449  ]]\n",
      "Error [[-0.50094239]\n",
      " [ 0.49848279]\n",
      " [ 0.49788397]\n",
      " [-0.502449  ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22884034 0.91280901]\n",
      " [0.80342626 1.34011277]\n",
      " [0.96391059 1.08874368]\n",
      " [1.5384965  1.51604744]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55696172 0.71357463]\n",
      " [0.69070691 0.79250849]\n",
      " [0.72390409 0.74814507]\n",
      " [0.82324605 0.81995571]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00372828]\n",
      " [0.00606445]\n",
      " [0.00847186]\n",
      " [0.00983045]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50093207]\n",
      " [0.50151611]\n",
      " [0.50211795]\n",
      " [0.50245759]]\n",
      "Error [[-0.50093207]\n",
      " [ 0.49848389]\n",
      " [ 0.49788205]\n",
      " [-0.50245759]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22884831 0.91280957]\n",
      " [0.80346287 1.34010776]\n",
      " [0.96394121 1.08873021]\n",
      " [1.53855577 1.5160284 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55696369 0.71357474]\n",
      " [0.69071474 0.79250766]\n",
      " [0.72391021 0.74814254]\n",
      " [0.82325468 0.8199529 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00368701]\n",
      " [0.00606004]\n",
      " [0.00847957]\n",
      " [0.00986484]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50092175]\n",
      " [0.501515  ]\n",
      " [0.50211988]\n",
      " [0.50246619]]\n",
      "Error [[-0.50092175]\n",
      " [ 0.498485  ]\n",
      " [ 0.49788012]\n",
      " [-0.50246619]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22885634 0.91281013]\n",
      " [0.80349981 1.34010274]\n",
      " [0.9639721  1.08871672]\n",
      " [1.53861556 1.51600933]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55696567 0.71357486]\n",
      " [0.69072263 0.79250684]\n",
      " [0.72391638 0.74813999]\n",
      " [0.82326338 0.81995008]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00364574]\n",
      " [0.00605564]\n",
      " [0.0084873 ]\n",
      " [0.00989925]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50091143]\n",
      " [0.50151391]\n",
      " [0.50212181]\n",
      " [0.50247479]]\n",
      "Error [[-0.50091143]\n",
      " [ 0.49848609]\n",
      " [ 0.49787819]\n",
      " [-0.50247479]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22886445 0.91281068]\n",
      " [0.80353707 1.34009771]\n",
      " [0.96400326 1.0887032 ]\n",
      " [1.53867588 1.51599023]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55696767 0.71357497]\n",
      " [0.69073059 0.79250601]\n",
      " [0.72392261 0.74813745]\n",
      " [0.82327215 0.81994726]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00360449]\n",
      " [0.00605126]\n",
      " [0.00849505]\n",
      " [0.00993367]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50090112]\n",
      " [0.50151281]\n",
      " [0.50212375]\n",
      " [0.5024834 ]]\n",
      "Error [[-0.50090112]\n",
      " [ 0.49848719]\n",
      " [ 0.49787625]\n",
      " [-0.5024834 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22887263 0.91281124]\n",
      " [0.80357465 1.34009267]\n",
      " [0.96403469 1.08868966]\n",
      " [1.53873672 1.5159711 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55696969 0.71357508]\n",
      " [0.69073861 0.79250518]\n",
      " [0.72392889 0.7481349 ]\n",
      " [0.82328101 0.81994444]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00356324]\n",
      " [0.00604689]\n",
      " [0.0085028 ]\n",
      " [0.00996811]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50089081]\n",
      " [0.50151172]\n",
      " [0.50212569]\n",
      " [0.50249201]]\n",
      "Error [[-0.50089081]\n",
      " [ 0.49848828]\n",
      " [ 0.49787431]\n",
      " [-0.50249201]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22888088 0.9128118 ]\n",
      " [0.80361256 1.34008763]\n",
      " [0.96406639 1.08867611]\n",
      " [1.53879808 1.51595194]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55697172 0.7135752 ]\n",
      " [0.69074671 0.79250435]\n",
      " [0.72393523 0.74813234]\n",
      " [0.82328993 0.81994161]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00352201]\n",
      " [0.00604254]\n",
      " [0.00851057]\n",
      " [0.01000256]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5008805 ]\n",
      " [0.50151063]\n",
      " [0.50212763]\n",
      " [0.50250062]]\n",
      "Error [[-0.5008805 ]\n",
      " [ 0.49848937]\n",
      " [ 0.49787237]\n",
      " [-0.50250062]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2288892  0.91281236]\n",
      " [0.80365079 1.34008258]\n",
      " [0.96409837 1.08866253]\n",
      " [1.53885996 1.51593275]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55697378 0.71357531]\n",
      " [0.69075488 0.79250352]\n",
      " [0.72394162 0.74812978]\n",
      " [0.82329894 0.81993878]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00348079]\n",
      " [0.0060382 ]\n",
      " [0.00851835]\n",
      " [0.01003702]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5008702 ]\n",
      " [0.50150954]\n",
      " [0.50212958]\n",
      " [0.50250924]]\n",
      "Error [[-0.5008702 ]\n",
      " [ 0.49849046]\n",
      " [ 0.49787042]\n",
      " [-0.50250924]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22889759 0.91281291]\n",
      " [0.80368934 1.34007752]\n",
      " [0.96413061 1.08864893]\n",
      " [1.53892236 1.51591354]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55697585 0.71357543]\n",
      " [0.69076311 0.79250269]\n",
      " [0.72394806 0.74812722]\n",
      " [0.82330801 0.81993594]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00343957]\n",
      " [0.00603387]\n",
      " [0.00852615]\n",
      " [0.0100715 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50085989]\n",
      " [0.50150846]\n",
      " [0.50213152]\n",
      " [0.50251785]]\n",
      "Error [[-0.50085989]\n",
      " [ 0.49849154]\n",
      " [ 0.49786848]\n",
      " [-0.50251785]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22890605 0.91281347]\n",
      " [0.80372822 1.34007246]\n",
      " [0.96416312 1.0886353 ]\n",
      " [1.53898529 1.51589429]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55697794 0.71357554]\n",
      " [0.69077142 0.79250186]\n",
      " [0.72395456 0.74812465]\n",
      " [0.82331717 0.8199331 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00339837]\n",
      " [0.00602955]\n",
      " [0.00853395]\n",
      " [0.01010599]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50084959]\n",
      " [0.50150738]\n",
      " [0.50213348]\n",
      " [0.50252648]]\n",
      "Error [[-0.50084959]\n",
      " [ 0.49849262]\n",
      " [ 0.49786652]\n",
      " [-0.50252648]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22891459 0.91281403]\n",
      " [0.80376742 1.34006739]\n",
      " [0.9641959  1.08862166]\n",
      " [1.53904874 1.51587501]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55698004 0.71357566]\n",
      " [0.69077979 0.79250102]\n",
      " [0.72396111 0.74812208]\n",
      " [0.8233264  0.81993025]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00335717]\n",
      " [0.00602525]\n",
      " [0.00854177]\n",
      " [0.01014049]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50083929]\n",
      " [0.50150631]\n",
      " [0.50213543]\n",
      " [0.5025351 ]]\n",
      "Error [[-0.50083929]\n",
      " [ 0.49849369]\n",
      " [ 0.49786457]\n",
      " [-0.5025351 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22892319 0.91281459]\n",
      " [0.80380695 1.3400623 ]\n",
      " [0.96422896 1.08860799]\n",
      " [1.53911272 1.51585571]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55698217 0.71357577]\n",
      " [0.69078823 0.79250019]\n",
      " [0.72396771 0.74811951]\n",
      " [0.8233357  0.8199274 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00331599]\n",
      " [0.00602096]\n",
      " [0.0085496 ]\n",
      " [0.010175  ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.500829  ]\n",
      " [0.50150524]\n",
      " [0.50213739]\n",
      " [0.50254373]]\n",
      "Error [[-0.500829  ]\n",
      " [ 0.49849476]\n",
      " [ 0.49786261]\n",
      " [-0.50254373]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22893187 0.91281515]\n",
      " [0.8038468  1.34005722]\n",
      " [0.96426228 1.0885943 ]\n",
      " [1.53917721 1.51583637]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55698431 0.71357588]\n",
      " [0.69079675 0.79249935]\n",
      " [0.72397437 0.74811693]\n",
      " [0.82334508 0.81992455]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00327481]\n",
      " [0.00601668]\n",
      " [0.00855744]\n",
      " [0.01020953]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5008187 ]\n",
      " [0.50150417]\n",
      " [0.50213935]\n",
      " [0.50255236]]\n",
      "Error [[-0.5008187 ]\n",
      " [ 0.49849583]\n",
      " [ 0.49786065]\n",
      " [-0.50255236]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22894062 0.91281571]\n",
      " [0.80388697 1.34005212]\n",
      " [0.96429588 1.0885806 ]\n",
      " [1.53924223 1.515817  ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55698646 0.713576  ]\n",
      " [0.69080533 0.79249851]\n",
      " [0.72398109 0.74811434]\n",
      " [0.82335454 0.81992169]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00323363]\n",
      " [0.00601241]\n",
      " [0.00856529]\n",
      " [0.01024406]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50080841]\n",
      " [0.5015031 ]\n",
      " [0.50214131]\n",
      " [0.50256099]]\n",
      "Error [[-0.50080841]\n",
      " [ 0.4984969 ]\n",
      " [ 0.49785869]\n",
      " [-0.50256099]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22894944 0.91281627]\n",
      " [0.80392747 1.34004702]\n",
      " [0.96432974 1.08856686]\n",
      " [1.53930777 1.51579761]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55698864 0.71357611]\n",
      " [0.69081398 0.79249767]\n",
      " [0.72398785 0.74811176]\n",
      " [0.82336407 0.81991882]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00319247]\n",
      " [0.00600816]\n",
      " [0.00857315]\n",
      " [0.01027861]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50079812]\n",
      " [0.50150204]\n",
      " [0.50214327]\n",
      " [0.50256963]]\n",
      "Error [[-0.50079812]\n",
      " [ 0.49849796]\n",
      " [ 0.49785673]\n",
      " [-0.50256963]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22895833 0.91281683]\n",
      " [0.80396829 1.34004191]\n",
      " [0.96436388 1.08855311]\n",
      " [1.53937384 1.51577819]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55699083 0.71357623]\n",
      " [0.6908227  0.79249683]\n",
      " [0.72399467 0.74810917]\n",
      " [0.82337368 0.81991596]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00315131]\n",
      " [0.00600391]\n",
      " [0.00858102]\n",
      " [0.01031317]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50078783]\n",
      " [0.50150097]\n",
      " [0.50214524]\n",
      " [0.50257827]]\n",
      "Error [[-0.50078783]\n",
      " [ 0.49849903]\n",
      " [ 0.49785476]\n",
      " [-0.50257827]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22896729 0.9128174 ]\n",
      " [0.80400943 1.34003679]\n",
      " [0.96439828 1.08853934]\n",
      " [1.53944042 1.51575873]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55699305 0.71357634]\n",
      " [0.69083148 0.79249599]\n",
      " [0.72400155 0.74810657]\n",
      " [0.82338336 0.81991308]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00311016]\n",
      " [0.00599968]\n",
      " [0.0085889 ]\n",
      " [0.01034774]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50077754]\n",
      " [0.50149992]\n",
      " [0.50214721]\n",
      " [0.50258691]]\n",
      "Error [[-0.50077754]\n",
      " [ 0.49850008]\n",
      " [ 0.49785279]\n",
      " [-0.50258691]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22897632 0.91281796]\n",
      " [0.8040509  1.34003166]\n",
      " [0.96443296 1.08852554]\n",
      " [1.53950754 1.51573925]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55699528 0.71357646]\n",
      " [0.69084034 0.79249515]\n",
      " [0.72400848 0.74810397]\n",
      " [0.82339312 0.81991021]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00306902]\n",
      " [0.00599546]\n",
      " [0.00859679]\n",
      " [0.01038232]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50076725]\n",
      " [0.50149886]\n",
      " [0.50214918]\n",
      " [0.50259556]]\n",
      "Error [[-0.50076725]\n",
      " [ 0.49850114]\n",
      " [ 0.49785082]\n",
      " [-0.50259556]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22898543 0.91281852]\n",
      " [0.80409269 1.34002653]\n",
      " [0.96446791 1.08851173]\n",
      " [1.53957517 1.51571974]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55699752 0.71357657]\n",
      " [0.69084927 0.7924943 ]\n",
      " [0.72401546 0.74810137]\n",
      " [0.82340296 0.81990732]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00302789]\n",
      " [0.00599125]\n",
      " [0.00860469]\n",
      " [0.01041691]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50075697]\n",
      " [0.50149781]\n",
      " [0.50215116]\n",
      " [0.5026042 ]]\n",
      "Error [[-0.50075697]\n",
      " [ 0.49850219]\n",
      " [ 0.49784884]\n",
      " [-0.5026042 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2289946  0.91281909]\n",
      " [0.8041348  1.34002139]\n",
      " [0.96450313 1.08849789]\n",
      " [1.53964333 1.51570019]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55699979 0.71357669]\n",
      " [0.69085826 0.79249346]\n",
      " [0.7240225  0.74809876]\n",
      " [0.82341287 0.81990444]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00298676]\n",
      " [0.00598705]\n",
      " [0.0086126 ]\n",
      " [0.01045152]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50074669]\n",
      " [0.50149676]\n",
      " [0.50215314]\n",
      " [0.50261286]]\n",
      "Error [[-0.50074669]\n",
      " [ 0.49850324]\n",
      " [ 0.49784686]\n",
      " [-0.50261286]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22900385 0.91281965]\n",
      " [0.80417724 1.34001624]\n",
      " [0.96453861 1.08848403]\n",
      " [1.539712   1.51568062]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55700207 0.7135768 ]\n",
      " [0.69086732 0.79249261]\n",
      " [0.72402959 0.74809615]\n",
      " [0.82342286 0.81990155]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00294563]\n",
      " [0.00598286]\n",
      " [0.00862052]\n",
      " [0.01048613]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50073641]\n",
      " [0.50149571]\n",
      " [0.50215512]\n",
      " [0.50262151]]\n",
      "Error [[-0.50073641]\n",
      " [ 0.49850429]\n",
      " [ 0.49784488]\n",
      " [-0.50262151]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22901317 0.91282021]\n",
      " [0.80422    1.34001109]\n",
      " [0.96457437 1.08847015]\n",
      " [1.53978121 1.51566102]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55700437 0.71357692]\n",
      " [0.69087646 0.79249176]\n",
      " [0.72403674 0.74809353]\n",
      " [0.82343292 0.81989865]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00290452]\n",
      " [0.00597868]\n",
      " [0.00862845]\n",
      " [0.01052075]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50072613]\n",
      " [0.50149467]\n",
      " [0.5021571 ]\n",
      " [0.50263016]]\n",
      "Error [[-0.50072613]\n",
      " [ 0.49850533]\n",
      " [ 0.4978429 ]\n",
      " [-0.50263016]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22902256 0.91282078]\n",
      " [0.80426309 1.34000592]\n",
      " [0.9646104  1.08845624]\n",
      " [1.53985093 1.51564139]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55700668 0.71357703]\n",
      " [0.69088566 0.79249092]\n",
      " [0.72404393 0.74809091]\n",
      " [0.82344305 0.81989576]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0028634 ]\n",
      " [0.00597451]\n",
      " [0.00863639]\n",
      " [0.01055539]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50071585]\n",
      " [0.50149362]\n",
      " [0.50215909]\n",
      " [0.50263882]]\n",
      "Error [[-0.50071585]\n",
      " [ 0.49850638]\n",
      " [ 0.49784091]\n",
      " [-0.50263882]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22903202 0.91282134]\n",
      " [0.8043065  1.34000075]\n",
      " [0.9646467  1.08844232]\n",
      " [1.53992118 1.51562173]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55700902 0.71357715]\n",
      " [0.69089493 0.79249007]\n",
      " [0.72405119 0.74808829]\n",
      " [0.82345327 0.81989285]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0028223 ]\n",
      " [0.00597035]\n",
      " [0.00864434]\n",
      " [0.01059003]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50070557]\n",
      " [0.50149258]\n",
      " [0.50216107]\n",
      " [0.50264748]]\n",
      "Error [[-0.50070557]\n",
      " [ 0.49850742]\n",
      " [ 0.49783893]\n",
      " [-0.50264748]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22904155 0.91282191]\n",
      " [0.80435023 1.33999557]\n",
      " [0.96468327 1.08842837]\n",
      " [1.53999195 1.51560204]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55701137 0.71357727]\n",
      " [0.69090427 0.79248921]\n",
      " [0.72405849 0.74808566]\n",
      " [0.82346356 0.81988994]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0027812 ]\n",
      " [0.0059662 ]\n",
      " [0.0086523 ]\n",
      " [0.01062468]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5006953 ]\n",
      " [0.50149155]\n",
      " [0.50216306]\n",
      " [0.50265615]]\n",
      "Error [[-0.5006953 ]\n",
      " [ 0.49850845]\n",
      " [ 0.49783694]\n",
      " [-0.50265615]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22905116 0.91282248]\n",
      " [0.80439429 1.33999039]\n",
      " [0.96472011 1.0884144 ]\n",
      " [1.54006325 1.51558232]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55701374 0.71357738]\n",
      " [0.69091368 0.79248836]\n",
      " [0.72406585 0.74808303]\n",
      " [0.82347392 0.81988703]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0027401 ]\n",
      " [0.00596206]\n",
      " [0.00866027]\n",
      " [0.01065935]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50068502]\n",
      " [0.50149051]\n",
      " [0.50216505]\n",
      " [0.50266481]]\n",
      "Error [[-0.50068502]\n",
      " [ 0.49850949]\n",
      " [ 0.49783495]\n",
      " [-0.50266481]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22906083 0.91282304]\n",
      " [0.80443867 1.3399852 ]\n",
      " [0.96475723 1.08840042]\n",
      " [1.54013507 1.51556257]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55701613 0.7135775 ]\n",
      " [0.69092315 0.79248751]\n",
      " [0.72407327 0.74808039]\n",
      " [0.82348436 0.81988412]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00269901]\n",
      " [0.00595793]\n",
      " [0.00866824]\n",
      " [0.01069402]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50067475]\n",
      " [0.50148948]\n",
      " [0.50216705]\n",
      " [0.50267348]]\n",
      "Error [[-0.50067475]\n",
      " [ 0.49851052]\n",
      " [ 0.49783295]\n",
      " [-0.50267348]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22907058 0.91282361]\n",
      " [0.80448338 1.33997999]\n",
      " [0.96479461 1.0883864 ]\n",
      " [1.54020741 1.51554279]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55701853 0.71357761]\n",
      " [0.6909327  0.79248665]\n",
      " [0.72408074 0.74807775]\n",
      " [0.82349487 0.8198812 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00265793]\n",
      " [0.00595381]\n",
      " [0.00867623]\n",
      " [0.01072871]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50066448]\n",
      " [0.50148845]\n",
      " [0.50216904]\n",
      " [0.50268215]]\n",
      "Error [[-0.50066448]\n",
      " [ 0.49851155]\n",
      " [ 0.49783096]\n",
      " [-0.50268215]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2290804  0.91282418]\n",
      " [0.80452841 1.33997479]\n",
      " [0.96483226 1.08837237]\n",
      " [1.54028028 1.51552298]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55702096 0.71357773]\n",
      " [0.69094232 0.7924858 ]\n",
      " [0.72408826 0.7480751 ]\n",
      " [0.82350547 0.81987827]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00261684]\n",
      " [0.0059497 ]\n",
      " [0.00868422]\n",
      " [0.0107634 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50065421]\n",
      " [0.50148742]\n",
      " [0.50217104]\n",
      " [0.50269082]]\n",
      "Error [[-0.50065421]\n",
      " [ 0.49851258]\n",
      " [ 0.49782896]\n",
      " [-0.50269082]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22909029 0.91282475]\n",
      " [0.80457376 1.33996957]\n",
      " [0.96487019 1.08835832]\n",
      " [1.54035367 1.51550314]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5570234  0.71357785]\n",
      " [0.690952   0.79248494]\n",
      " [0.72409584 0.74807246]\n",
      " [0.82351613 0.81987534]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00257577]\n",
      " [0.0059456 ]\n",
      " [0.00869222]\n",
      " [0.0107981 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50064394]\n",
      " [0.5014864 ]\n",
      " [0.50217304]\n",
      " [0.5026995 ]]\n",
      "Error [[-0.50064394]\n",
      " [ 0.4985136 ]\n",
      " [ 0.49782696]\n",
      " [-0.5026995 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22910025 0.91282531]\n",
      " [0.80461944 1.33996435]\n",
      " [0.96490838 1.08834424]\n",
      " [1.54042758 1.51548327]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55702585 0.71357796]\n",
      " [0.69096176 0.79248408]\n",
      " [0.72410347 0.7480698 ]\n",
      " [0.82352687 0.81987241]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0025347 ]\n",
      " [0.00594151]\n",
      " [0.00870023]\n",
      " [0.01083281]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50063367]\n",
      " [0.50148537]\n",
      " [0.50217504]\n",
      " [0.50270818]]\n",
      "Error [[-0.50063367]\n",
      " [ 0.49851463]\n",
      " [ 0.49782496]\n",
      " [-0.50270818]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22911028 0.91282588]\n",
      " [0.80466545 1.33995912]\n",
      " [0.96494685 1.08833014]\n",
      " [1.54050201 1.51546338]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55702833 0.71357808]\n",
      " [0.69097158 0.79248322]\n",
      " [0.72411115 0.74806715]\n",
      " [0.82353769 0.81986947]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00249363]\n",
      " [0.00593743]\n",
      " [0.00870825]\n",
      " [0.01086754]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50062341]\n",
      " [0.50148435]\n",
      " [0.50217705]\n",
      " [0.50271686]]\n",
      "Error [[-0.50062341]\n",
      " [ 0.49851565]\n",
      " [ 0.49782295]\n",
      " [-0.50271686]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22912039 0.91282645]\n",
      " [0.80471177 1.33995388]\n",
      " [0.96498559 1.08831602]\n",
      " [1.54057697 1.51544345]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55703082 0.71357819]\n",
      " [0.69098147 0.79248236]\n",
      " [0.72411889 0.74806449]\n",
      " [0.82354858 0.81986653]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00245257]\n",
      " [0.00593335]\n",
      " [0.00871627]\n",
      " [0.01090227]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50061314]\n",
      " [0.50148333]\n",
      " [0.50217905]\n",
      " [0.50272554]]\n",
      "Error [[-0.50061314]\n",
      " [ 0.49851667]\n",
      " [ 0.49782095]\n",
      " [-0.50272554]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22913056 0.91282702]\n",
      " [0.80475842 1.33994863]\n",
      " [0.9650246  1.08830188]\n",
      " [1.54065246 1.51542349]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55703333 0.71357831]\n",
      " [0.69099143 0.79248149]\n",
      " [0.72412668 0.74806182]\n",
      " [0.82355955 0.81986358]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00241151]\n",
      " [0.00592929]\n",
      " [0.00872431]\n",
      " [0.01093701]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50060288]\n",
      " [0.50148232]\n",
      " [0.50218106]\n",
      " [0.50273423]]\n",
      "Error [[-0.50060288]\n",
      " [ 0.49851768]\n",
      " [ 0.49781894]\n",
      " [-0.50273423]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22914081 0.91282759]\n",
      " [0.8048054  1.33994338]\n",
      " [0.96506388 1.08828772]\n",
      " [1.54072846 1.51540351]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55703586 0.71357843]\n",
      " [0.69100146 0.79248063]\n",
      " [0.72413453 0.74805915]\n",
      " [0.8235706  0.81986063]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00237045]\n",
      " [0.00592523]\n",
      " [0.00873235]\n",
      " [0.01097176]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50059261]\n",
      " [0.5014813 ]\n",
      " [0.50218307]\n",
      " [0.50274291]]\n",
      "Error [[-0.50059261]\n",
      " [ 0.4985187 ]\n",
      " [ 0.49781693]\n",
      " [-0.50274291]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22915113 0.91282816]\n",
      " [0.8048527  1.33993812]\n",
      " [0.96510343 1.08827354]\n",
      " [1.540805   1.51538349]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55703841 0.71357854]\n",
      " [0.69101156 0.79247976]\n",
      " [0.72414243 0.74805648]\n",
      " [0.82358172 0.81985767]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0023294 ]\n",
      " [0.00592119]\n",
      " [0.0087404 ]\n",
      " [0.01100652]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50058235]\n",
      " [0.50148029]\n",
      " [0.50218509]\n",
      " [0.5027516 ]]\n",
      "Error [[-0.50058235]\n",
      " [ 0.49851971]\n",
      " [ 0.49781491]\n",
      " [-0.5027516 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22916152 0.91282874]\n",
      " [0.80490032 1.33993285]\n",
      " [0.96514325 1.08825933]\n",
      " [1.54088205 1.51536345]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55704097 0.71357866]\n",
      " [0.69102173 0.7924789 ]\n",
      " [0.72415039 0.7480538 ]\n",
      " [0.82359291 0.81985471]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00228835]\n",
      " [0.00591715]\n",
      " [0.00874846]\n",
      " [0.01104129]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50057209]\n",
      " [0.50147928]\n",
      " [0.5021871 ]\n",
      " [0.5027603 ]]\n",
      "Error [[-0.50057209]\n",
      " [ 0.49852072]\n",
      " [ 0.4978129 ]\n",
      " [-0.5027603 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22917199 0.91282931]\n",
      " [0.80494827 1.33992757]\n",
      " [0.96518334 1.0882451 ]\n",
      " [1.54095963 1.51534337]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55704355 0.71357878]\n",
      " [0.69103197 0.79247803]\n",
      " [0.72415839 0.74805112]\n",
      " [0.82360418 0.81985174]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0022473 ]\n",
      " [0.00591312]\n",
      " [0.00875652]\n",
      " [0.01107607]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50056183]\n",
      " [0.50147828]\n",
      " [0.50218912]\n",
      " [0.50276899]]\n",
      "Error [[-0.50056183]\n",
      " [ 0.49852172]\n",
      " [ 0.49781088]\n",
      " [-0.50276899]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22918252 0.91282988]\n",
      " [0.80499655 1.33992229]\n",
      " [0.9652237  1.08823086]\n",
      " [1.54103773 1.51532327]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55704615 0.71357889]\n",
      " [0.69104228 0.79247716]\n",
      " [0.72416646 0.74804843]\n",
      " [0.82361553 0.81984878]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00220626]\n",
      " [0.0059091 ]\n",
      " [0.0087646 ]\n",
      " [0.01111086]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50055157]\n",
      " [0.50147727]\n",
      " [0.50219114]\n",
      " [0.50277769]]\n",
      "Error [[-0.50055157]\n",
      " [ 0.49852273]\n",
      " [ 0.49780886]\n",
      " [-0.50277769]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22919313 0.91283045]\n",
      " [0.80504514 1.339917  ]\n",
      " [0.96526434 1.08821658]\n",
      " [1.54111636 1.51530313]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55704877 0.71357901]\n",
      " [0.69105265 0.79247629]\n",
      " [0.72417457 0.74804574]\n",
      " [0.82362695 0.8198458 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00216522]\n",
      " [0.00590509]\n",
      " [0.00877268]\n",
      " [0.01114566]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50054131]\n",
      " [0.50147627]\n",
      " [0.50219316]\n",
      " [0.50278639]]\n",
      "Error [[-0.50054131]\n",
      " [ 0.49852373]\n",
      " [ 0.49780684]\n",
      " [-0.50278639]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2292038  0.91283102]\n",
      " [0.80509407 1.3399117 ]\n",
      " [0.96530524 1.08820229]\n",
      " [1.54119551 1.51528297]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55705141 0.71357913]\n",
      " [0.6910631  0.79247542]\n",
      " [0.72418275 0.74804305]\n",
      " [0.82363845 0.81984282]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00212419]\n",
      " [0.00590109]\n",
      " [0.00878077]\n",
      " [0.01118047]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50053105]\n",
      " [0.50147527]\n",
      " [0.50219518]\n",
      " [0.50279509]]\n",
      "Error [[-0.50053105]\n",
      " [ 0.49852473]\n",
      " [ 0.49780482]\n",
      " [-0.50279509]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22921455 0.9128316 ]\n",
      " [0.80514331 1.3399064 ]\n",
      " [0.96534642 1.08818798]\n",
      " [1.54127518 1.51526278]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55705406 0.71357925]\n",
      " [0.69107361 0.79247455]\n",
      " [0.72419097 0.74804035]\n",
      " [0.82365002 0.81983984]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00208316]\n",
      " [0.00589709]\n",
      " [0.00878887]\n",
      " [0.01121529]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50052079]\n",
      " [0.50147427]\n",
      " [0.5021972 ]\n",
      " [0.50280379]]\n",
      "Error [[-0.50052079]\n",
      " [ 0.49852573]\n",
      " [ 0.4978028 ]\n",
      " [-0.50280379]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22922537 0.91283217]\n",
      " [0.80519288 1.33990108]\n",
      " [0.96538787 1.08817364]\n",
      " [1.54135538 1.51524255]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55705673 0.71357936]\n",
      " [0.69108419 0.79247367]\n",
      " [0.72419925 0.74803765]\n",
      " [0.82366167 0.81983685]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00204213]\n",
      " [0.00589311]\n",
      " [0.00879697]\n",
      " [0.01125011]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50051053]\n",
      " [0.50147327]\n",
      " [0.50219923]\n",
      " [0.5028125 ]]\n",
      "Error [[-0.50051053]\n",
      " [ 0.49852673]\n",
      " [ 0.49780077]\n",
      " [-0.5028125 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22923627 0.91283275]\n",
      " [0.80524278 1.33989576]\n",
      " [0.96542959 1.08815929]\n",
      " [1.5414361  1.5152223 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55705942 0.71357948]\n",
      " [0.69109484 0.7924728 ]\n",
      " [0.72420758 0.74803494]\n",
      " [0.8236734  0.81983386]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0020011 ]\n",
      " [0.00588913]\n",
      " [0.00880509]\n",
      " [0.01128495]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50050027]\n",
      " [0.50147228]\n",
      " [0.50220126]\n",
      " [0.50282121]]\n",
      "Error [[-0.50050027]\n",
      " [ 0.49852772]\n",
      " [ 0.49779874]\n",
      " [-0.50282121]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22924723 0.91283332]\n",
      " [0.805293   1.33989043]\n",
      " [0.96547158 1.08814491]\n",
      " [1.54151735 1.51520202]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55706212 0.7135796 ]\n",
      " [0.69110557 0.79247192]\n",
      " [0.72421597 0.74803223]\n",
      " [0.82368519 0.81983087]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00196008]\n",
      " [0.00588516]\n",
      " [0.00881321]\n",
      " [0.01131979]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50049002]\n",
      " [0.50147129]\n",
      " [0.50220329]\n",
      " [0.50282992]]\n",
      "Error [[-0.50049002]\n",
      " [ 0.49852871]\n",
      " [ 0.49779671]\n",
      " [-0.50282992]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22925827 0.9128339 ]\n",
      " [0.80534355 1.3398851 ]\n",
      " [0.96551384 1.08813051]\n",
      " [1.54159912 1.51518171]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55706484 0.71357972]\n",
      " [0.69111636 0.79247105]\n",
      " [0.72422441 0.74802952]\n",
      " [0.82369707 0.81982787]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00191905]\n",
      " [0.0058812 ]\n",
      " [0.00882134]\n",
      " [0.01135465]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50047976]\n",
      " [0.5014703 ]\n",
      " [0.50220532]\n",
      " [0.50283863]]\n",
      "Error [[-0.50047976]\n",
      " [ 0.4985297 ]\n",
      " [ 0.49779468]\n",
      " [-0.50283863]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22926938 0.91283447]\n",
      " [0.80539442 1.33987976]\n",
      " [0.96555638 1.08811608]\n",
      " [1.54168142 1.51516137]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55706759 0.71357983]\n",
      " [0.69112722 0.79247017]\n",
      " [0.7242329  0.7480268 ]\n",
      " [0.82370902 0.81982486]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00187804]\n",
      " [0.00587725]\n",
      " [0.00882947]\n",
      " [0.01138951]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50046951]\n",
      " [0.50146931]\n",
      " [0.50220735]\n",
      " [0.50284735]]\n",
      "Error [[-0.50046951]\n",
      " [ 0.49853069]\n",
      " [ 0.49779265]\n",
      " [-0.50284735]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22928056 0.91283505]\n",
      " [0.80544561 1.33987441]\n",
      " [0.96559918 1.08810164]\n",
      " [1.54176424 1.515141  ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55707034 0.71357995]\n",
      " [0.69113814 0.79246929]\n",
      " [0.72424145 0.74802408]\n",
      " [0.82372105 0.81982185]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00183702]\n",
      " [0.00587331]\n",
      " [0.00883761]\n",
      " [0.01142438]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50045925]\n",
      " [0.50146832]\n",
      " [0.50220939]\n",
      " [0.50285606]]\n",
      "Error [[-0.50045925]\n",
      " [ 0.49853168]\n",
      " [ 0.49779061]\n",
      " [-0.50285606]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22929181 0.91283563]\n",
      " [0.80549713 1.33986905]\n",
      " [0.96564226 1.08808717]\n",
      " [1.54184758 1.5151206 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55707312 0.71358007]\n",
      " [0.69114914 0.79246841]\n",
      " [0.72425006 0.74802135]\n",
      " [0.82373315 0.81981884]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.001796  ]\n",
      " [0.00586938]\n",
      " [0.00884577]\n",
      " [0.01145927]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.500449  ]\n",
      " [0.50146734]\n",
      " [0.50221143]\n",
      " [0.50286479]]\n",
      "Error [[-0.500449  ]\n",
      " [ 0.49853266]\n",
      " [ 0.49778857]\n",
      " [-0.50286479]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22930313 0.9128362 ]\n",
      " [0.80554898 1.33986368]\n",
      " [0.96568561 1.08807269]\n",
      " [1.54193145 1.51510017]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55707591 0.71358019]\n",
      " [0.69116021 0.79246752]\n",
      " [0.72425871 0.74801862]\n",
      " [0.82374533 0.81981582]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00175499]\n",
      " [0.00586545]\n",
      " [0.00885392]\n",
      " [0.01149416]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50043875]\n",
      " [0.50146636]\n",
      " [0.50221347]\n",
      " [0.50287351]]\n",
      "Error [[-0.50043875]\n",
      " [ 0.49853364]\n",
      " [ 0.49778653]\n",
      " [-0.50287351]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22931453 0.91283678]\n",
      " [0.80560115 1.33985831]\n",
      " [0.96572923 1.08805818]\n",
      " [1.54201584 1.51507971]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55707873 0.71358031]\n",
      " [0.69117134 0.79246664]\n",
      " [0.72426742 0.74801589]\n",
      " [0.82375758 0.8198128 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00171398]\n",
      " [0.00586153]\n",
      " [0.00886209]\n",
      " [0.01152906]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5004285 ]\n",
      " [0.50146538]\n",
      " [0.50221551]\n",
      " [0.50288223]]\n",
      "Error [[-0.5004285 ]\n",
      " [ 0.49853462]\n",
      " [ 0.49778449]\n",
      " [-0.50288223]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.229326   0.91283736]\n",
      " [0.80565364 1.33985293]\n",
      " [0.96577312 1.08804365]\n",
      " [1.54210076 1.51505922]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55708156 0.71358042]\n",
      " [0.69118255 0.79246575]\n",
      " [0.72427619 0.74801315]\n",
      " [0.82376991 0.81980977]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00167297]\n",
      " [0.00585762]\n",
      " [0.00887026]\n",
      " [0.01156397]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50041824]\n",
      " [0.5014644 ]\n",
      " [0.50221755]\n",
      " [0.50289096]]\n",
      "Error [[-0.50041824]\n",
      " [ 0.4985356 ]\n",
      " [ 0.49778245]\n",
      " [-0.50289096]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22933754 0.91283794]\n",
      " [0.80570646 1.33984754]\n",
      " [0.96581728 1.0880291 ]\n",
      " [1.5421862  1.5150387 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5570844  0.71358054]\n",
      " [0.69119382 0.79246487]\n",
      " [0.72428501 0.74801041]\n",
      " [0.82378231 0.81980674]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00163197]\n",
      " [0.00585372]\n",
      " [0.00887844]\n",
      " [0.01159889]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50040799]\n",
      " [0.50146343]\n",
      " [0.5022196 ]\n",
      " [0.50289969]]\n",
      "Error [[-0.50040799]\n",
      " [ 0.49853657]\n",
      " [ 0.4977804 ]\n",
      " [-0.50289969]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22934915 0.91283852]\n",
      " [0.80575961 1.33984215]\n",
      " [0.96586171 1.08801452]\n",
      " [1.54227217 1.51501815]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55708727 0.71358066]\n",
      " [0.69120517 0.79246398]\n",
      " [0.72429388 0.74800766]\n",
      " [0.82379479 0.81980371]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00159096]\n",
      " [0.00584983]\n",
      " [0.00888663]\n",
      " [0.01163382]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50039774]\n",
      " [0.50146245]\n",
      " [0.50222164]\n",
      " [0.50290842]]\n",
      "Error [[-0.50039774]\n",
      " [ 0.49853755]\n",
      " [ 0.49777836]\n",
      " [-0.50290842]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22936083 0.9128391 ]\n",
      " [0.80581308 1.33983674]\n",
      " [0.96590642 1.08799993]\n",
      " [1.54235867 1.51499757]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55709015 0.71358078]\n",
      " [0.69121658 0.79246309]\n",
      " [0.72430281 0.74800491]\n",
      " [0.82380734 0.81980067]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00154996]\n",
      " [0.00584595]\n",
      " [0.00889483]\n",
      " [0.01166876]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50038749]\n",
      " [0.50146148]\n",
      " [0.50222369]\n",
      " [0.50291716]]\n",
      "Error [[-0.50038749]\n",
      " [ 0.49853852]\n",
      " [ 0.49777631]\n",
      " [-0.50291716]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22937259 0.91283968]\n",
      " [0.80586687 1.33983133]\n",
      " [0.9659514  1.08798531]\n",
      " [1.54244568 1.51497696]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55709305 0.7135809 ]\n",
      " [0.69122806 0.7924622 ]\n",
      " [0.72431179 0.74800215]\n",
      " [0.82381997 0.81979762]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00150896]\n",
      " [0.00584207]\n",
      " [0.00890303]\n",
      " [0.01170371]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50037724]\n",
      " [0.50146051]\n",
      " [0.50222574]\n",
      " [0.50292589]]\n",
      "Error [[-0.50037724]\n",
      " [ 0.49853949]\n",
      " [ 0.49777426]\n",
      " [-0.50292589]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22938441 0.91284026]\n",
      " [0.80592099 1.33982591]\n",
      " [0.96599665 1.08797067]\n",
      " [1.54253323 1.51495633]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55709597 0.71358102]\n",
      " [0.69123961 0.79246131]\n",
      " [0.72432083 0.74799939]\n",
      " [0.82383268 0.81979457]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00146796]\n",
      " [0.0058382 ]\n",
      " [0.00891124]\n",
      " [0.01173866]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50036699]\n",
      " [0.50145955]\n",
      " [0.5022278 ]\n",
      " [0.50293463]]\n",
      "Error [[-0.50036699]\n",
      " [ 0.49854045]\n",
      " [ 0.4977722 ]\n",
      " [-0.50293463]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22939631 0.91284084]\n",
      " [0.80597544 1.33982049]\n",
      " [0.96604217 1.08795601]\n",
      " [1.54262129 1.51493566]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55709891 0.71358113]\n",
      " [0.69125123 0.79246042]\n",
      " [0.72432992 0.74799663]\n",
      " [0.82384546 0.81979152]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00142696]\n",
      " [0.00583434]\n",
      " [0.00891946]\n",
      " [0.01177363]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50035674]\n",
      " [0.50145858]\n",
      " [0.50222985]\n",
      " [0.50294337]]\n",
      "Error [[-0.50035674]\n",
      " [ 0.49854142]\n",
      " [ 0.49777015]\n",
      " [-0.50294337]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22940828 0.91284142]\n",
      " [0.80603021 1.33981506]\n",
      " [0.96608796 1.08794133]\n",
      " [1.54270989 1.51491496]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55710186 0.71358125]\n",
      " [0.69126292 0.79245953]\n",
      " [0.72433906 0.74799386]\n",
      " [0.82385832 0.81978846]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00138597]\n",
      " [0.00583049]\n",
      " [0.00892768]\n",
      " [0.01180861]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50034649]\n",
      " [0.50145762]\n",
      " [0.50223191]\n",
      " [0.50295212]]\n",
      "Error [[-0.50034649]\n",
      " [ 0.49854238]\n",
      " [ 0.49776809]\n",
      " [-0.50295212]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22942033 0.912842  ]\n",
      " [0.8060853  1.33980962]\n",
      " [0.96613403 1.08792662]\n",
      " [1.54279901 1.51489424]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55710483 0.71358137]\n",
      " [0.69127468 0.79245863]\n",
      " [0.72434826 0.74799109]\n",
      " [0.82387125 0.8197854 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00134497]\n",
      " [0.00582665]\n",
      " [0.00893592]\n",
      " [0.01184359]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50033624]\n",
      " [0.50145666]\n",
      " [0.50223396]\n",
      " [0.50296086]]\n",
      "Error [[-0.50033624]\n",
      " [ 0.49854334]\n",
      " [ 0.49776604]\n",
      " [-0.50296086]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22943244 0.91284258]\n",
      " [0.80614073 1.33980417]\n",
      " [0.96618037 1.08791189]\n",
      " [1.54288865 1.51487348]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55710782 0.71358149]\n",
      " [0.69128651 0.79245774]\n",
      " [0.72435751 0.74798831]\n",
      " [0.82388426 0.81978233]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00130398]\n",
      " [0.00582281]\n",
      " [0.00894416]\n",
      " [0.01187859]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50032599]\n",
      " [0.5014557 ]\n",
      " [0.50223602]\n",
      " [0.50296961]]\n",
      "Error [[-0.50032599]\n",
      " [ 0.4985443 ]\n",
      " [ 0.49776398]\n",
      " [-0.50296961]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22944463 0.91284317]\n",
      " [0.80619647 1.33979871]\n",
      " [0.96622698 1.08789715]\n",
      " [1.54297882 1.51485269]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55711083 0.71358161]\n",
      " [0.6912984  0.79245684]\n",
      " [0.72436682 0.74798553]\n",
      " [0.82389734 0.81977926]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00126298]\n",
      " [0.00581899]\n",
      " [0.0089524 ]\n",
      " [0.0119136 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50031575]\n",
      " [0.50145474]\n",
      " [0.50223809]\n",
      " [0.50297836]]\n",
      "Error [[-0.50031575]\n",
      " [ 0.49854526]\n",
      " [ 0.49776191]\n",
      " [-0.50297836]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22945689 0.91284375]\n",
      " [0.80625255 1.33979325]\n",
      " [0.96627386 1.08788238]\n",
      " [1.54306951 1.51483188]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55711385 0.71358173]\n",
      " [0.69131037 0.79245594]\n",
      " [0.72437618 0.74798275]\n",
      " [0.8239105  0.81977619]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00122199]\n",
      " [0.00581517]\n",
      " [0.00896066]\n",
      " [0.01194861]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5003055 ]\n",
      " [0.50145379]\n",
      " [0.50224015]\n",
      " [0.50298712]]\n",
      "Error [[-0.5003055 ]\n",
      " [ 0.49854621]\n",
      " [ 0.49775985]\n",
      " [-0.50298712]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22946922 0.91284433]\n",
      " [0.80630894 1.33978778]\n",
      " [0.96632101 1.08786759]\n",
      " [1.54316073 1.51481103]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5571169  0.71358185]\n",
      " [0.69132241 0.79245504]\n",
      " [0.72438559 0.74797996]\n",
      " [0.82392373 0.81977311]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.001181  ]\n",
      " [0.00581136]\n",
      " [0.00896892]\n",
      " [0.01198364]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50029525]\n",
      " [0.50145284]\n",
      " [0.50224221]\n",
      " [0.50299587]]\n",
      "Error [[-0.50029525]\n",
      " [ 0.49854716]\n",
      " [ 0.49775779]\n",
      " [-0.50299587]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22948162 0.91284492]\n",
      " [0.80636567 1.3397823 ]\n",
      " [0.96636844 1.08785277]\n",
      " [1.54325248 1.51479016]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55711996 0.71358197]\n",
      " [0.69133451 0.79245414]\n",
      " [0.72439506 0.74797717]\n",
      " [0.82393704 0.81977002]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00114001]\n",
      " [0.00580756]\n",
      " [0.00897719]\n",
      " [0.01201867]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.500285  ]\n",
      " [0.50145188]\n",
      " [0.50224428]\n",
      " [0.50300463]]\n",
      "Error [[-0.500285  ]\n",
      " [ 0.49854812]\n",
      " [ 0.49775572]\n",
      " [-0.50300463]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2294941  0.9128455 ]\n",
      " [0.80642272 1.33977682]\n",
      " [0.96641613 1.08783794]\n",
      " [1.54334475 1.51476925]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55712303 0.71358209]\n",
      " [0.69134668 0.79245324]\n",
      " [0.72440458 0.74797437]\n",
      " [0.82395043 0.81976693]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00109902]\n",
      " [0.00580376]\n",
      " [0.00898546]\n",
      " [0.01205371]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50027475]\n",
      " [0.50145094]\n",
      " [0.50224635]\n",
      " [0.50301339]]\n",
      "Error [[-0.50027475]\n",
      " [ 0.49854906]\n",
      " [ 0.49775365]\n",
      " [-0.50301339]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22950665 0.91284609]\n",
      " [0.80648009 1.33977133]\n",
      " [0.9664641  1.08782308]\n",
      " [1.54343755 1.51474832]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55712613 0.71358221]\n",
      " [0.69135893 0.79245233]\n",
      " [0.72441416 0.74797157]\n",
      " [0.82396389 0.81976384]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00105803]\n",
      " [0.00579998]\n",
      " [0.00899375]\n",
      " [0.01208877]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50026451]\n",
      " [0.50144999]\n",
      " [0.50224842]\n",
      " [0.50302216]]\n",
      "Error [[-0.50026451]\n",
      " [ 0.49855001]\n",
      " [ 0.49775158]\n",
      " [-0.50302216]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22951927 0.91284667]\n",
      " [0.80653779 1.33976583]\n",
      " [0.96651235 1.0878082 ]\n",
      " [1.54353087 1.51472736]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55712924 0.71358233]\n",
      " [0.69137124 0.79245143]\n",
      " [0.72442379 0.74796877]\n",
      " [0.82397742 0.81976074]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00101704]\n",
      " [0.0057962 ]\n",
      " [0.00900204]\n",
      " [0.01212383]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50025426]\n",
      " [0.50144905]\n",
      " [0.50225049]\n",
      " [0.50303092]]\n",
      "Error [[-0.50025426]\n",
      " [ 0.49855095]\n",
      " [ 0.49774951]\n",
      " [-0.50303092]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22953196 0.91284726]\n",
      " [0.80659582 1.33976032]\n",
      " [0.96656086 1.0877933 ]\n",
      " [1.54362472 1.51470636]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55713238 0.71358245]\n",
      " [0.69138362 0.79245052]\n",
      " [0.72443347 0.74796596]\n",
      " [0.82399104 0.81975764]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00097606]\n",
      " [0.00579243]\n",
      " [0.00901033]\n",
      " [0.01215891]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50024401]\n",
      " [0.5014481 ]\n",
      " [0.50225257]\n",
      " [0.50303969]]\n",
      "Error [[-0.50024401]\n",
      " [ 0.4985519 ]\n",
      " [ 0.49774743]\n",
      " [-0.50303969]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22954472 0.91284785]\n",
      " [0.80665417 1.33975481]\n",
      " [0.96660965 1.08777838]\n",
      " [1.5437191  1.51468534]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55713552 0.71358257]\n",
      " [0.69139607 0.79244962]\n",
      " [0.72444321 0.74796315]\n",
      " [0.82400472 0.81975454]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00093507]\n",
      " [0.00578867]\n",
      " [0.00901864]\n",
      " [0.01219399]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50023377]\n",
      " [0.50144716]\n",
      " [0.50225464]\n",
      " [0.50304846]]\n",
      "Error [[-0.50023377]\n",
      " [ 0.49855284]\n",
      " [ 0.49774536]\n",
      " [-0.50304846]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22955756 0.91284843]\n",
      " [0.80671285 1.33974928]\n",
      " [0.96665871 1.08776344]\n",
      " [1.543814   1.51466429]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55713869 0.71358269]\n",
      " [0.69140859 0.79244871]\n",
      " [0.72445301 0.74796033]\n",
      " [0.82401848 0.81975143]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00089408]\n",
      " [0.00578491]\n",
      " [0.00902695]\n",
      " [0.01222908]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50022352]\n",
      " [0.50144622]\n",
      " [0.50225672]\n",
      " [0.50305723]]\n",
      "Error [[-0.50022352]\n",
      " [ 0.49855378]\n",
      " [ 0.49774328]\n",
      " [-0.50305723]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22957047 0.91284902]\n",
      " [0.80677186 1.33974375]\n",
      " [0.96670804 1.08774847]\n",
      " [1.54390943 1.5146432 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55714188 0.71358281]\n",
      " [0.69142118 0.7924478 ]\n",
      " [0.72446285 0.74795751]\n",
      " [0.82403232 0.81974831]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0008531 ]\n",
      " [0.00578117]\n",
      " [0.00903527]\n",
      " [0.01226418]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50021327]\n",
      " [0.50144529]\n",
      " [0.5022588 ]\n",
      " [0.50306601]]\n",
      "Error [[-0.50021327]\n",
      " [ 0.49855471]\n",
      " [ 0.4977412 ]\n",
      " [-0.50306601]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22958345 0.91284961]\n",
      " [0.80683119 1.33973822]\n",
      " [0.96675764 1.08773348]\n",
      " [1.54400538 1.51462209]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55714508 0.71358293]\n",
      " [0.69143384 0.79244689]\n",
      " [0.72447276 0.74795468]\n",
      " [0.82404624 0.81974519]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00081211]\n",
      " [0.00577743]\n",
      " [0.0090436 ]\n",
      " [0.0122993 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50020303]\n",
      " [0.50144435]\n",
      " [0.50226088]\n",
      " [0.50307479]]\n",
      "Error [[-0.50020303]\n",
      " [ 0.49855565]\n",
      " [ 0.49773912]\n",
      " [-0.50307479]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2295965  0.9128502 ]\n",
      " [0.80689084 1.33973267]\n",
      " [0.96680752 1.08771847]\n",
      " [1.54410186 1.51460095]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5571483  0.71358305]\n",
      " [0.69144657 0.79244598]\n",
      " [0.72448271 0.74795185]\n",
      " [0.82406022 0.81974207]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00077112]\n",
      " [0.0057737 ]\n",
      " [0.00905193]\n",
      " [0.01233442]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50019278]\n",
      " [0.50144342]\n",
      " [0.50226297]\n",
      " [0.50308357]]\n",
      "Error [[-0.50019278]\n",
      " [ 0.49855658]\n",
      " [ 0.49773703]\n",
      " [-0.50308357]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22960963 0.91285079]\n",
      " [0.80695083 1.33972712]\n",
      " [0.96685767 1.08770344]\n",
      " [1.54419887 1.51457978]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55715154 0.71358317]\n",
      " [0.69145936 0.79244506]\n",
      " [0.72449272 0.74794902]\n",
      " [0.82407429 0.81973894]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00073014]\n",
      " [0.00576998]\n",
      " [0.00906027]\n",
      " [0.01236955]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50018253]\n",
      " [0.50144249]\n",
      " [0.50226505]\n",
      " [0.50309235]]\n",
      "Error [[-0.50018253]\n",
      " [ 0.49855751]\n",
      " [ 0.49773495]\n",
      " [-0.50309235]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22962283 0.91285138]\n",
      " [0.80701114 1.33972156]\n",
      " [0.96690809 1.08768839]\n",
      " [1.5442964  1.51455857]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5571548  0.71358329]\n",
      " [0.69147223 0.79244415]\n",
      " [0.72450279 0.74794618]\n",
      " [0.82408843 0.81973581]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00068915]\n",
      " [0.00576627]\n",
      " [0.00906862]\n",
      " [0.0124047 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50017229]\n",
      " [0.50144156]\n",
      " [0.50226714]\n",
      " [0.50310113]]\n",
      "Error [[-0.50017229]\n",
      " [ 0.49855844]\n",
      " [ 0.49773286]\n",
      " [-0.50310113]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2296361  0.91285196]\n",
      " [0.80707177 1.339716  ]\n",
      " [0.96695879 1.08767331]\n",
      " [1.54439446 1.51453734]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55715807 0.71358341]\n",
      " [0.69148517 0.79244323]\n",
      " [0.7245129  0.74794334]\n",
      " [0.82410264 0.81973267]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00064817]\n",
      " [0.00576256]\n",
      " [0.00907698]\n",
      " [0.01243985]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50016204]\n",
      " [0.50144064]\n",
      " [0.50226923]\n",
      " [0.50310992]]\n",
      "Error [[-0.50016204]\n",
      " [ 0.49855936]\n",
      " [ 0.49773077]\n",
      " [-0.50310992]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22964944 0.91285255]\n",
      " [0.80713273 1.33971042]\n",
      " [0.96700976 1.08765822]\n",
      " [1.54449305 1.51451608]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55716136 0.71358353]\n",
      " [0.69149817 0.79244232]\n",
      " [0.72452308 0.74794049]\n",
      " [0.82411693 0.81972953]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00060718]\n",
      " [0.00575887]\n",
      " [0.00908534]\n",
      " [0.01247501]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5001518 ]\n",
      " [0.50143971]\n",
      " [0.50227132]\n",
      " [0.50311871]]\n",
      "Error [[-0.5001518 ]\n",
      " [ 0.49856029]\n",
      " [ 0.49772868]\n",
      " [-0.50311871]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22966286 0.91285315]\n",
      " [0.80719402 1.33970484]\n",
      " [0.967061   1.0876431 ]\n",
      " [1.54459216 1.51449479]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55716467 0.71358365]\n",
      " [0.69151125 0.7924414 ]\n",
      " [0.7245333  0.74793764]\n",
      " [0.8241313  0.81972638]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0005662 ]\n",
      " [0.00575518]\n",
      " [0.00909371]\n",
      " [0.01251019]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50014155]\n",
      " [0.50143879]\n",
      " [0.50227341]\n",
      " [0.50312751]]\n",
      "Error [[-0.50014155]\n",
      " [ 0.49856121]\n",
      " [ 0.49772659]\n",
      " [-0.50312751]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22967634 0.91285374]\n",
      " [0.80725564 1.33969925]\n",
      " [0.96711251 1.08762796]\n",
      " [1.5446918  1.51447347]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.557168   0.71358377]\n",
      " [0.69152439 0.79244048]\n",
      " [0.72454359 0.74793479]\n",
      " [0.82414574 0.81972323]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00052521]\n",
      " [0.0057515 ]\n",
      " [0.00910209]\n",
      " [0.01254537]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.5001313 ]\n",
      " [0.50143787]\n",
      " [0.50227551]\n",
      " [0.5031363 ]]\n",
      "Error [[-0.5001313 ]\n",
      " [ 0.49856213]\n",
      " [ 0.49772449]\n",
      " [-0.5031363 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2296899  0.91285433]\n",
      " [0.80731758 1.33969365]\n",
      " [0.9671643  1.08761279]\n",
      " [1.54479197 1.51445212]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55717135 0.71358389]\n",
      " [0.6915376  0.79243956]\n",
      " [0.72455392 0.74793193]\n",
      " [0.82416026 0.81972007]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00048423]\n",
      " [0.00574783]\n",
      " [0.00911047]\n",
      " [0.01258056]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50012106]\n",
      " [0.50143695]\n",
      " [0.5022776 ]\n",
      " [0.5031451 ]]\n",
      "Error [[-0.50012106]\n",
      " [ 0.49856305]\n",
      " [ 0.4977224 ]\n",
      " [-0.5031451 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22970353 0.91285492]\n",
      " [0.80737985 1.33968805]\n",
      " [0.96721636 1.08759761]\n",
      " [1.54489267 1.51443074]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55717471 0.71358401]\n",
      " [0.69155088 0.79243864]\n",
      " [0.72456431 0.74792907]\n",
      " [0.82417485 0.81971691]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00044324]\n",
      " [0.00574416]\n",
      " [0.00911887]\n",
      " [0.01261577]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50011081]\n",
      " [0.50143604]\n",
      " [0.5022797 ]\n",
      " [0.5031539 ]]\n",
      "Error [[-0.50011081]\n",
      " [ 0.49856396]\n",
      " [ 0.4977203 ]\n",
      " [-0.5031539 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22971724 0.91285551]\n",
      " [0.80744244 1.33968244]\n",
      " [0.96726869 1.0875824 ]\n",
      " [1.54499389 1.51440933]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55717809 0.71358413]\n",
      " [0.69156424 0.79243771]\n",
      " [0.72457475 0.7479262 ]\n",
      " [0.82418952 0.81971375]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00040225]\n",
      " [0.00574051]\n",
      " [0.00912726]\n",
      " [0.01265098]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50010056]\n",
      " [0.50143512]\n",
      " [0.5022818 ]\n",
      " [0.5031627 ]]\n",
      "Error [[-0.50010056]\n",
      " [ 0.49856488]\n",
      " [ 0.4977182 ]\n",
      " [-0.5031627 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22973102 0.91285611]\n",
      " [0.80750536 1.33967682]\n",
      " [0.96732129 1.08756718]\n",
      " [1.54509564 1.51438789]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55718149 0.71358425]\n",
      " [0.69157766 0.79243679]\n",
      " [0.72458525 0.74792333]\n",
      " [0.82420426 0.81971058]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00036126]\n",
      " [0.00573686]\n",
      " [0.00913567]\n",
      " [0.01268621]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50009032]\n",
      " [0.50143421]\n",
      " [0.5022839 ]\n",
      " [0.50317151]]\n",
      "Error [[-0.50009032]\n",
      " [ 0.49856579]\n",
      " [ 0.4977161 ]\n",
      " [-0.50317151]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22974487 0.9128567 ]\n",
      " [0.80756861 1.33967119]\n",
      " [0.96737417 1.08755193]\n",
      " [1.54519792 1.51436642]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55718491 0.71358438]\n",
      " [0.69159115 0.79243586]\n",
      " [0.72459581 0.74792045]\n",
      " [0.82421908 0.81970741]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00032028]\n",
      " [0.00573322]\n",
      " [0.00914409]\n",
      " [0.01272144]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50008007]\n",
      " [0.5014333 ]\n",
      " [0.50228601]\n",
      " [0.50318032]]\n",
      "Error [[-0.50008007]\n",
      " [ 0.4985667 ]\n",
      " [ 0.49771399]\n",
      " [-0.50318032]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22975879 0.91285729]\n",
      " [0.80763218 1.33966556]\n",
      " [0.96742732 1.08753665]\n",
      " [1.54530072 1.51434492]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55718834 0.7135845 ]\n",
      " [0.69160471 0.79243494]\n",
      " [0.72460641 0.74791757]\n",
      " [0.82423397 0.81970423]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00027929]\n",
      " [0.00572959]\n",
      " [0.00915251]\n",
      " [0.01275669]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50006982]\n",
      " [0.50143239]\n",
      " [0.50228811]\n",
      " [0.50318913]]\n",
      "Error [[-0.50006982]\n",
      " [ 0.49856761]\n",
      " [ 0.49771189]\n",
      " [-0.50318913]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22977278 0.91285789]\n",
      " [0.80769608 1.33965992]\n",
      " [0.96748075 1.08752136]\n",
      " [1.54540405 1.51432339]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55719179 0.71358462]\n",
      " [0.69161834 0.79243401]\n",
      " [0.72461707 0.74791469]\n",
      " [0.82424894 0.81970105]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.0002383 ]\n",
      " [0.00572596]\n",
      " [0.00916093]\n",
      " [0.01279194]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50005957]\n",
      " [0.50143149]\n",
      " [0.50229022]\n",
      " [0.50319794]]\n",
      "Error [[-0.50005957]\n",
      " [ 0.49856851]\n",
      " [ 0.49770978]\n",
      " [-0.50319794]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22978685 0.91285848]\n",
      " [0.80776031 1.33965427]\n",
      " [0.96753445 1.08750604]\n",
      " [1.54550791 1.51430183]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55719526 0.71358474]\n",
      " [0.69163204 0.79243308]\n",
      " [0.72462779 0.7479118 ]\n",
      " [0.82426399 0.81969786]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00019731]\n",
      " [0.00572235]\n",
      " [0.00916937]\n",
      " [0.01282721]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50004933]\n",
      " [0.50143058]\n",
      " [0.50229233]\n",
      " [0.50320676]]\n",
      "Error [[-0.50004933]\n",
      " [ 0.49856942]\n",
      " [ 0.49770767]\n",
      " [-0.50320676]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22980099 0.91285908]\n",
      " [0.80782487 1.33964862]\n",
      " [0.96758842 1.08749071]\n",
      " [1.5456123  1.51428025]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55719875 0.71358486]\n",
      " [0.6916458  0.79243215]\n",
      " [0.72463856 0.74790891]\n",
      " [0.82427911 0.81969467]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00015632]\n",
      " [0.00571874]\n",
      " [0.00917781]\n",
      " [0.01286248]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50003908]\n",
      " [0.50142968]\n",
      " [0.50229444]\n",
      " [0.50321558]]\n",
      "Error [[-0.50003908]\n",
      " [ 0.49857032]\n",
      " [ 0.49770556]\n",
      " [-0.50321558]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2298152  0.91285967]\n",
      " [0.80788975 1.33964295]\n",
      " [0.96764266 1.08747535]\n",
      " [1.54571721 1.51425863]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55720226 0.71358498]\n",
      " [0.69165964 0.79243122]\n",
      " [0.72464938 0.74790601]\n",
      " [0.8242943  0.81969148]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[0.00011533]\n",
      " [0.00571514]\n",
      " [0.00918626]\n",
      " [0.01289777]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50002883]\n",
      " [0.50142878]\n",
      " [0.50229655]\n",
      " [0.5032244 ]]\n",
      "Error [[-0.50002883]\n",
      " [ 0.49857122]\n",
      " [ 0.49770345]\n",
      " [-0.5032244 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22982948 0.91286027]\n",
      " [0.80795496 1.33963728]\n",
      " [0.96769718 1.08745996]\n",
      " [1.54582266 1.51423698]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55720578 0.71358511]\n",
      " [0.69167355 0.79243029]\n",
      " [0.72466026 0.74790311]\n",
      " [0.82430957 0.81968828]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[7.43341490e-05]\n",
      " [5.71155226e-03]\n",
      " [9.19472200e-03]\n",
      " [1.29330697e-02]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50001858]\n",
      " [0.50142788]\n",
      " [0.50229866]\n",
      " [0.50323322]]\n",
      "Error [[-0.50001858]\n",
      " [ 0.49857212]\n",
      " [ 0.49770134]\n",
      " [-0.50323322]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22984384 0.91286086]\n",
      " [0.8080205  1.3396316 ]\n",
      " [0.96775198 1.08744456]\n",
      " [1.54592863 1.5142153 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55720933 0.71358523]\n",
      " [0.69168752 0.79242935]\n",
      " [0.72467119 0.74790021]\n",
      " [0.82432492 0.81968507]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[3.33405213e-05]\n",
      " [5.70796980e-03]\n",
      " [9.20318703e-03]\n",
      " [1.29683785e-02]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.50000834]\n",
      " [0.50142699]\n",
      " [0.50230078]\n",
      " [0.50324205]]\n",
      "Error [[-0.50000834]\n",
      " [ 0.49857301]\n",
      " [ 0.49769922]\n",
      " [-0.50324205]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22985827 0.91286146]\n",
      " [0.80808636 1.33962592]\n",
      " [0.96780704 1.08742914]\n",
      " [1.54603513 1.51419359]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55721289 0.71358535]\n",
      " [0.69170157 0.79242842]\n",
      " [0.72468218 0.7478973 ]\n",
      " [0.82434034 0.81968187]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-7.65419796e-06]\n",
      " [ 5.70439553e-03]\n",
      " [ 9.21165939e-03]\n",
      " [ 1.30036979e-02]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49999809]\n",
      " [0.5014261 ]\n",
      " [0.5023029 ]\n",
      " [0.50325088]]\n",
      "Error [[-0.49999809]\n",
      " [ 0.4985739 ]\n",
      " [ 0.4976971 ]\n",
      " [-0.50325088]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22987277 0.91286206]\n",
      " [0.80815255 1.33962023]\n",
      " [0.96786238 1.08741369]\n",
      " [1.54614216 1.51417186]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55721646 0.71358547]\n",
      " [0.69171568 0.79242748]\n",
      " [0.72469322 0.74789439]\n",
      " [0.82435584 0.81967865]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-4.86500752e-05]\n",
      " [ 5.70082945e-03]\n",
      " [ 9.22013908e-03]\n",
      " [ 1.30390281e-02]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49998784]\n",
      " [0.5014252 ]\n",
      " [0.50230502]\n",
      " [0.50325971]]\n",
      "Error [[-0.49998784]\n",
      " [ 0.4985748 ]\n",
      " [ 0.49769498]\n",
      " [-0.50325971]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22988735 0.91286266]\n",
      " [0.80821907 1.33961453]\n",
      " [0.96791799 1.08739822]\n",
      " [1.54624972 1.51415009]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55722006 0.71358559]\n",
      " [0.69172987 0.79242654]\n",
      " [0.72470432 0.74789147]\n",
      " [0.82437141 0.81967544]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-8.96471767e-05]\n",
      " [ 5.69727157e-03]\n",
      " [ 9.22862611e-03]\n",
      " [ 1.30743690e-02]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49997759]\n",
      " [0.50142431]\n",
      " [0.50230714]\n",
      " [0.50326855]]\n",
      "Error [[-0.49997759]\n",
      " [ 0.49857569]\n",
      " [ 0.49769286]\n",
      " [-0.50326855]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.229902   0.91286326]\n",
      " [0.80828592 1.33960882]\n",
      " [0.96797388 1.08738273]\n",
      " [1.5463578  1.51412829]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55722368 0.71358572]\n",
      " [0.69174412 0.7924256 ]\n",
      " [0.72471547 0.74788855]\n",
      " [0.82438706 0.81967221]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00013065]\n",
      " [ 0.00569372]\n",
      " [ 0.00923712]\n",
      " [ 0.01310972]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49996734]\n",
      " [0.50142343]\n",
      " [0.50230926]\n",
      " [0.50327738]]\n",
      "Error [[-0.49996734]\n",
      " [ 0.49857657]\n",
      " [ 0.49769074]\n",
      " [-0.50327738]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22991672 0.91286385]\n",
      " [0.80835309 1.3396031 ]\n",
      " [0.96803004 1.08736721]\n",
      " [1.54646642 1.51410646]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55722731 0.71358584]\n",
      " [0.69175845 0.79242466]\n",
      " [0.72472667 0.74788563]\n",
      " [0.82440279 0.81966899]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00017165]\n",
      " [ 0.00569018]\n",
      " [ 0.00924562]\n",
      " [ 0.01314508]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49995709]\n",
      " [0.50142254]\n",
      " [0.50231139]\n",
      " [0.50328622]]\n",
      "Error [[-0.49995709]\n",
      " [ 0.49857746]\n",
      " [ 0.49768861]\n",
      " [-0.50328622]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22993151 0.91286445]\n",
      " [0.80842059 1.33959738]\n",
      " [0.96808648 1.08735168]\n",
      " [1.54657556 1.51408461]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55723096 0.71358596]\n",
      " [0.69177284 0.79242372]\n",
      " [0.72473793 0.7478827 ]\n",
      " [0.82441859 0.81966576]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00021265]\n",
      " [ 0.00568665]\n",
      " [ 0.00925413]\n",
      " [ 0.01318046]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49994684]\n",
      " [0.50142166]\n",
      " [0.50231352]\n",
      " [0.50329507]]\n",
      "Error [[-0.49994684]\n",
      " [ 0.49857834]\n",
      " [ 0.49768648]\n",
      " [-0.50329507]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22994638 0.91286505]\n",
      " [0.80848842 1.33959165]\n",
      " [0.96814319 1.08733612]\n",
      " [1.54668523 1.51406272]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55723462 0.71358608]\n",
      " [0.6917873  0.79242278]\n",
      " [0.72474924 0.74787976]\n",
      " [0.82443446 0.81966252]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00025365]\n",
      " [ 0.00568312]\n",
      " [ 0.00926265]\n",
      " [ 0.01321584]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49993659]\n",
      " [0.50142078]\n",
      " [0.50231565]\n",
      " [0.50330391]]\n",
      "Error [[-0.49993659]\n",
      " [ 0.49857922]\n",
      " [ 0.49768435]\n",
      " [-0.50330391]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22996132 0.91286565]\n",
      " [0.80855658 1.33958591]\n",
      " [0.96820017 1.08732054]\n",
      " [1.54679543 1.5140408 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55723831 0.71358621]\n",
      " [0.69180183 0.79242184]\n",
      " [0.72476061 0.74787683]\n",
      " [0.82445041 0.81965928]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00029465]\n",
      " [ 0.00567961]\n",
      " [ 0.00927117]\n",
      " [ 0.01325124]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49992634]\n",
      " [0.5014199 ]\n",
      " [0.50231778]\n",
      " [0.50331276]]\n",
      "Error [[-0.49992634]\n",
      " [ 0.4985801 ]\n",
      " [ 0.49768222]\n",
      " [-0.50331276]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22997633 0.91286625]\n",
      " [0.80862506 1.33958017]\n",
      " [0.96825742 1.08730494]\n",
      " [1.54690616 1.51401886]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55724201 0.71358633]\n",
      " [0.69181644 0.79242089]\n",
      " [0.72477203 0.74787388]\n",
      " [0.82446644 0.81965604]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00033566]\n",
      " [ 0.0056761 ]\n",
      " [ 0.0092797 ]\n",
      " [ 0.01328664]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49991609]\n",
      " [0.50141902]\n",
      " [0.50231991]\n",
      " [0.50332161]]\n",
      "Error [[-0.49991609]\n",
      " [ 0.49858098]\n",
      " [ 0.49768009]\n",
      " [-0.50332161]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.22999141 0.91286685]\n",
      " [0.80869388 1.33957442]\n",
      " [0.96831496 1.08728932]\n",
      " [1.54701742 1.51399688]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55724574 0.71358645]\n",
      " [0.69183111 0.79241995]\n",
      " [0.72478351 0.74787094]\n",
      " [0.82448254 0.81965279]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00037667]\n",
      " [ 0.0056726 ]\n",
      " [ 0.00928824]\n",
      " [ 0.01332206]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49990583]\n",
      " [0.50141815]\n",
      " [0.50232204]\n",
      " [0.50333047]]\n",
      "Error [[-0.49990583]\n",
      " [ 0.49858185]\n",
      " [ 0.49767796]\n",
      " [-0.50333047]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23000657 0.91286746]\n",
      " [0.80876302 1.33956866]\n",
      " [0.96837276 1.08727367]\n",
      " [1.54712921 1.51397487]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55724948 0.71358657]\n",
      " [0.69184585 0.792419  ]\n",
      " [0.72479504 0.74786799]\n",
      " [0.82449871 0.81964954]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00041768]\n",
      " [ 0.0056691 ]\n",
      " [ 0.00929679]\n",
      " [ 0.01335749]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49989558]\n",
      " [0.50141727]\n",
      " [0.50232418]\n",
      " [0.50333932]]\n",
      "Error [[-0.49989558]\n",
      " [ 0.49858273]\n",
      " [ 0.49767582]\n",
      " [-0.50333932]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2300218  0.91286806]\n",
      " [0.80883248 1.33956289]\n",
      " [0.96843084 1.087258  ]\n",
      " [1.54724153 1.51395284]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55725323 0.7135867 ]\n",
      " [0.69186066 0.79241805]\n",
      " [0.72480662 0.74786503]\n",
      " [0.82451497 0.81964628]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00045869]\n",
      " [ 0.00566562]\n",
      " [ 0.00930534]\n",
      " [ 0.01339293]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49988533]\n",
      " [0.5014164 ]\n",
      " [0.50232632]\n",
      " [0.50334818]]\n",
      "Error [[-0.49988533]\n",
      " [ 0.4985836 ]\n",
      " [ 0.49767368]\n",
      " [-0.50334818]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2300371  0.91286866]\n",
      " [0.80890228 1.33955712]\n",
      " [0.96848919 1.08724232]\n",
      " [1.54735437 1.51393077]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55725701 0.71358682]\n",
      " [0.69187554 0.7924171 ]\n",
      " [0.72481826 0.74786208]\n",
      " [0.82453129 0.81964302]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0004997 ]\n",
      " [ 0.00566214]\n",
      " [ 0.0093139 ]\n",
      " [ 0.01342838]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49987507]\n",
      " [0.50141553]\n",
      " [0.50232846]\n",
      " [0.50335704]]\n",
      "Error [[-0.49987507]\n",
      " [ 0.49858447]\n",
      " [ 0.49767154]\n",
      " [-0.50335704]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23005248 0.91286926]\n",
      " [0.80897241 1.33955133]\n",
      " [0.96854782 1.0872266 ]\n",
      " [1.54746775 1.51390867]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5572608  0.71358694]\n",
      " [0.69189049 0.79241615]\n",
      " [0.72482995 0.74785911]\n",
      " [0.8245477  0.81963975]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00054071]\n",
      " [ 0.00565868]\n",
      " [ 0.00932247]\n",
      " [ 0.01346384]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49986482]\n",
      " [0.50141467]\n",
      " [0.5023306 ]\n",
      " [0.50336591]]\n",
      "Error [[-0.49986482]\n",
      " [ 0.49858533]\n",
      " [ 0.4976694 ]\n",
      " [-0.50336591]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23006793 0.91286987]\n",
      " [0.80904286 1.33954554]\n",
      " [0.96860673 1.08721087]\n",
      " [1.54758166 1.51388655]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55726461 0.71358707]\n",
      " [0.69190551 0.7924152 ]\n",
      " [0.7248417  0.74785615]\n",
      " [0.82456417 0.81963648]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00058173]\n",
      " [ 0.00565522]\n",
      " [ 0.00933105]\n",
      " [ 0.01349932]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49985457]\n",
      " [0.5014138 ]\n",
      " [0.50233274]\n",
      " [0.50337478]]\n",
      "Error [[-0.49985457]\n",
      " [ 0.4985862 ]\n",
      " [ 0.49766726]\n",
      " [-0.50337478]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23008345 0.91287047]\n",
      " [0.80911364 1.33953975]\n",
      " [0.9686659  1.08719511]\n",
      " [1.54769609 1.51386439]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55726844 0.71358719]\n",
      " [0.69192059 0.79241424]\n",
      " [0.7248535  0.74785318]\n",
      " [0.82458073 0.8196332 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00062275]\n",
      " [ 0.00565177]\n",
      " [ 0.00933963]\n",
      " [ 0.0135348 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49984431]\n",
      " [0.50141294]\n",
      " [0.50233489]\n",
      " [0.50338365]]\n",
      "Error [[-0.49984431]\n",
      " [ 0.49858706]\n",
      " [ 0.49766511]\n",
      " [-0.50338365]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23009904 0.91287108]\n",
      " [0.80918475 1.33953394]\n",
      " [0.96872536 1.08717934]\n",
      " [1.54781106 1.51384221]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55727229 0.71358731]\n",
      " [0.69193575 0.79241329]\n",
      " [0.72486536 0.7478502 ]\n",
      " [0.82459736 0.81962992]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00066377]\n",
      " [ 0.00564833]\n",
      " [ 0.00934822]\n",
      " [ 0.0135703 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49983406]\n",
      " [0.50141208]\n",
      " [0.50233704]\n",
      " [0.50339252]]\n",
      "Error [[-0.49983406]\n",
      " [ 0.49858792]\n",
      " [ 0.49766296]\n",
      " [-0.50339252]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23011471 0.91287168]\n",
      " [0.80925619 1.33952813]\n",
      " [0.96878508 1.08716354]\n",
      " [1.54792656 1.51381999]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55727616 0.71358744]\n",
      " [0.69195098 0.79241233]\n",
      " [0.72487727 0.74784722]\n",
      " [0.82461406 0.81962664]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0007048 ]\n",
      " [ 0.00564489]\n",
      " [ 0.00935682]\n",
      " [ 0.01360581]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4998238 ]\n",
      " [0.50141122]\n",
      " [0.50233919]\n",
      " [0.5034014 ]]\n",
      "Error [[-0.4998238 ]\n",
      " [ 0.49858878]\n",
      " [ 0.49766081]\n",
      " [-0.5034014 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23013045 0.91287228]\n",
      " [0.80932795 1.33952231]\n",
      " [0.96884508 1.08714772]\n",
      " [1.54804259 1.51379774]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55728004 0.71358756]\n",
      " [0.69196628 0.79241138]\n",
      " [0.72488924 0.74784424]\n",
      " [0.82463084 0.81962335]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00074582]\n",
      " [ 0.00564147]\n",
      " [ 0.00936542]\n",
      " [ 0.01364133]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49981354]\n",
      " [0.50141036]\n",
      " [0.50234134]\n",
      " [0.50341028]]\n",
      "Error [[-0.49981354]\n",
      " [ 0.49858964]\n",
      " [ 0.49765866]\n",
      " [-0.50341028]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23014626 0.91287289]\n",
      " [0.80940005 1.33951649]\n",
      " [0.96890536 1.08713187]\n",
      " [1.54815914 1.51377547]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55728394 0.71358769]\n",
      " [0.69198164 0.79241042]\n",
      " [0.72490126 0.74784125]\n",
      " [0.8246477  0.81962006]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00078685]\n",
      " [ 0.00563805]\n",
      " [ 0.00937404]\n",
      " [ 0.01367686]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49980329]\n",
      " [0.50140951]\n",
      " [0.50234349]\n",
      " [0.50341916]]\n",
      "Error [[-0.49980329]\n",
      " [ 0.49859049]\n",
      " [ 0.49765651]\n",
      " [-0.50341916]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23016215 0.9128735 ]\n",
      " [0.80947247 1.33951065]\n",
      " [0.96896591 1.08711601]\n",
      " [1.54827623 1.51375316]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55728786 0.71358781]\n",
      " [0.69199708 0.79240946]\n",
      " [0.72491333 0.74783826]\n",
      " [0.82466463 0.81961676]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00082788]\n",
      " [ 0.00563464]\n",
      " [ 0.00938266]\n",
      " [ 0.0137124 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49979303]\n",
      " [0.50140866]\n",
      " [0.50234565]\n",
      " [0.50342805]]\n",
      "Error [[-0.49979303]\n",
      " [ 0.49859134]\n",
      " [ 0.49765435]\n",
      " [-0.50342805]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23017811 0.9128741 ]\n",
      " [0.80954522 1.33950481]\n",
      " [0.96902674 1.08710012]\n",
      " [1.54839385 1.51373083]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5572918  0.71358793]\n",
      " [0.69201259 0.7924085 ]\n",
      " [0.72492546 0.74783526]\n",
      " [0.82468163 0.81961346]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00086891]\n",
      " [ 0.00563124]\n",
      " [ 0.00939128]\n",
      " [ 0.01374796]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49978277]\n",
      " [0.50140781]\n",
      " [0.5023478 ]\n",
      " [0.50343693]]\n",
      "Error [[-0.49978277]\n",
      " [ 0.49859219]\n",
      " [ 0.4976522 ]\n",
      " [-0.50343693]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23019414 0.91287471]\n",
      " [0.80961831 1.33949896]\n",
      " [0.96908784 1.08708421]\n",
      " [1.548512   1.51370846]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55729575 0.71358806]\n",
      " [0.69202816 0.79240753]\n",
      " [0.72493765 0.74783226]\n",
      " [0.82469871 0.81961015]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00090995]\n",
      " [ 0.00562785]\n",
      " [ 0.00939992]\n",
      " [ 0.01378352]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49977251]\n",
      " [0.50140696]\n",
      " [0.50234996]\n",
      " [0.50344583]]\n",
      "Error [[-0.49977251]\n",
      " [ 0.49859304]\n",
      " [ 0.49765004]\n",
      " [-0.50344583]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23021025 0.91287532]\n",
      " [0.80969172 1.33949311]\n",
      " [0.96914921 1.08706827]\n",
      " [1.54863068 1.51368607]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55729973 0.71358818]\n",
      " [0.69204381 0.79240657]\n",
      " [0.72494989 0.74782926]\n",
      " [0.82471587 0.81960684]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00095099]\n",
      " [ 0.00562446]\n",
      " [ 0.00940856]\n",
      " [ 0.0138191 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49976225]\n",
      " [0.50140611]\n",
      " [0.50235212]\n",
      " [0.50345472]]\n",
      "Error [[-0.49976225]\n",
      " [ 0.49859389]\n",
      " [ 0.49764788]\n",
      " [-0.50345472]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23022643 0.91287593]\n",
      " [0.80976546 1.33948725]\n",
      " [0.96921087 1.08705232]\n",
      " [1.54874989 1.51366364]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55730372 0.71358831]\n",
      " [0.69205952 0.79240561]\n",
      " [0.72496218 0.74782625]\n",
      " [0.8247331  0.81960352]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00099203]\n",
      " [ 0.00562109]\n",
      " [ 0.00941721]\n",
      " [ 0.01385469]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49975199]\n",
      " [0.50140527]\n",
      " [0.50235429]\n",
      " [0.50346362]]\n",
      "Error [[-0.49975199]\n",
      " [ 0.49859473]\n",
      " [ 0.49764571]\n",
      " [-0.50346362]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23024268 0.91287653]\n",
      " [0.80983952 1.33948137]\n",
      " [0.96927279 1.08703634]\n",
      " [1.54886964 1.51364118]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55730773 0.71358843]\n",
      " [0.69207531 0.79240464]\n",
      " [0.72497453 0.74782323]\n",
      " [0.82475041 0.8196002 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00103307]\n",
      " [ 0.00561772]\n",
      " [ 0.00942587]\n",
      " [ 0.01389029]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49974173]\n",
      " [0.50140443]\n",
      " [0.50235645]\n",
      " [0.50347252]]\n",
      "Error [[-0.49974173]\n",
      " [ 0.49859557]\n",
      " [ 0.49764355]\n",
      " [-0.50347252]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.230259   0.91287714]\n",
      " [0.80991392 1.3394755 ]\n",
      " [0.96933499 1.08702034]\n",
      " [1.54898991 1.5136187 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55731176 0.71358855]\n",
      " [0.69209116 0.79240367]\n",
      " [0.72498693 0.74782022]\n",
      " [0.8247678  0.81959688]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00107412]\n",
      " [ 0.00561436]\n",
      " [ 0.00943454]\n",
      " [ 0.0139259 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49973147]\n",
      " [0.50140359]\n",
      " [0.50235862]\n",
      " [0.50348142]]\n",
      "Error [[-0.49973147]\n",
      " [ 0.49859641]\n",
      " [ 0.49764138]\n",
      " [-0.50348142]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2302754  0.91287775]\n",
      " [0.80998865 1.33946961]\n",
      " [0.96939747 1.08700432]\n",
      " [1.54911072 1.51359618]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5573158  0.71358868]\n",
      " [0.69210709 0.79240271]\n",
      " [0.72499938 0.7478172 ]\n",
      " [0.82478525 0.81959355]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00111516]\n",
      " [ 0.00561101]\n",
      " [ 0.00944321]\n",
      " [ 0.01396153]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49972121]\n",
      " [0.50140275]\n",
      " [0.50236078]\n",
      " [0.50349033]]\n",
      "Error [[-0.49972121]\n",
      " [ 0.49859725]\n",
      " [ 0.49763922]\n",
      " [-0.50349033]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23029187 0.91287836]\n",
      " [0.8100637  1.33946372]\n",
      " [0.96946022 1.08698828]\n",
      " [1.54923206 1.51357364]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55731986 0.7135888 ]\n",
      " [0.69212308 0.79240174]\n",
      " [0.7250119  0.74781417]\n",
      " [0.82480279 0.81959022]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00115622]\n",
      " [ 0.00560767]\n",
      " [ 0.00945189]\n",
      " [ 0.01399716]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49971095]\n",
      " [0.50140191]\n",
      " [0.50236295]\n",
      " [0.50349923]]\n",
      "Error [[-0.49971095]\n",
      " [ 0.49859809]\n",
      " [ 0.49763705]\n",
      " [-0.50349923]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23030842 0.91287897]\n",
      " [0.81013909 1.33945782]\n",
      " [0.96952325 1.08697221]\n",
      " [1.54935392 1.51355106]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55732395 0.71358893]\n",
      " [0.69213914 0.79240077]\n",
      " [0.72502446 0.74781114]\n",
      " [0.8248204  0.81958688]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00119727]\n",
      " [ 0.00560433]\n",
      " [ 0.00946058]\n",
      " [ 0.01403281]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49970068]\n",
      " [0.50140108]\n",
      " [0.50236513]\n",
      " [0.50350815]]\n",
      "Error [[-0.49970068]\n",
      " [ 0.49859892]\n",
      " [ 0.49763487]\n",
      " [-0.50350815]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23032503 0.91287958]\n",
      " [0.8102148  1.33945191]\n",
      " [0.96958656 1.08695613]\n",
      " [1.54947633 1.51352846]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55732805 0.71358905]\n",
      " [0.69215528 0.79239979]\n",
      " [0.72503708 0.74780811]\n",
      " [0.82483808 0.81958354]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00123833]\n",
      " [ 0.00560101]\n",
      " [ 0.00946927]\n",
      " [ 0.01406847]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49969042]\n",
      " [0.50140025]\n",
      " [0.5023673 ]\n",
      " [0.50351706]]\n",
      "Error [[-0.49969042]\n",
      " [ 0.49859975]\n",
      " [ 0.4976327 ]\n",
      " [-0.50351706]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23034172 0.91288019]\n",
      " [0.81029085 1.339446  ]\n",
      " [0.96965014 1.08694002]\n",
      " [1.54959926 1.51350582]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55733216 0.71358918]\n",
      " [0.69217148 0.79239882]\n",
      " [0.72504976 0.74780507]\n",
      " [0.82485584 0.81958019]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00127939]\n",
      " [ 0.00559769]\n",
      " [ 0.00947798]\n",
      " [ 0.01410415]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49968015]\n",
      " [0.50139942]\n",
      " [0.50236948]\n",
      " [0.50352598]]\n",
      "Error [[-0.49968015]\n",
      " [ 0.49860058]\n",
      " [ 0.49763052]\n",
      " [-0.50352598]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23035849 0.9128808 ]\n",
      " [0.81036722 1.33944007]\n",
      " [0.96971399 1.08692388]\n",
      " [1.54972272 1.51348315]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5573363  0.7135893 ]\n",
      " [0.69218775 0.79239785]\n",
      " [0.72506249 0.74780203]\n",
      " [0.82487368 0.81957684]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00132045]\n",
      " [ 0.00559438]\n",
      " [ 0.00948669]\n",
      " [ 0.01413983]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49966989]\n",
      " [0.50139859]\n",
      " [0.50237165]\n",
      " [0.5035349 ]]\n",
      "Error [[-0.49966989]\n",
      " [ 0.49860141]\n",
      " [ 0.49762835]\n",
      " [-0.5035349 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23037533 0.91288142]\n",
      " [0.81044392 1.33943414]\n",
      " [0.96977812 1.08690773]\n",
      " [1.54984672 1.51346046]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55734045 0.71358943]\n",
      " [0.69220409 0.79239687]\n",
      " [0.72507527 0.74779898]\n",
      " [0.82489159 0.81957348]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00136152]\n",
      " [ 0.00559108]\n",
      " [ 0.00949541]\n",
      " [ 0.01417553]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49965962]\n",
      " [0.50139777]\n",
      " [0.50237383]\n",
      " [0.50354382]]\n",
      "Error [[-0.49965962]\n",
      " [ 0.49860223]\n",
      " [ 0.49762617]\n",
      " [-0.50354382]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23039224 0.91288203]\n",
      " [0.81052096 1.33942821]\n",
      " [0.96984253 1.08689155]\n",
      " [1.54997125 1.51343773]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55734463 0.71358955]\n",
      " [0.69222051 0.79239589]\n",
      " [0.72508811 0.74779593]\n",
      " [0.82490958 0.81957012]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00140259]\n",
      " [ 0.00558779]\n",
      " [ 0.00950413]\n",
      " [ 0.01421124]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49964935]\n",
      " [0.50139694]\n",
      " [0.50237602]\n",
      " [0.50355275]]\n",
      "Error [[-0.49964935]\n",
      " [ 0.49860306]\n",
      " [ 0.49762398]\n",
      " [-0.50355275]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23040922 0.91288264]\n",
      " [0.81059832 1.33942226]\n",
      " [0.96990721 1.08687536]\n",
      " [1.55009631 1.51341498]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55734882 0.71358968]\n",
      " [0.69223699 0.79239492]\n",
      " [0.725101   0.74779287]\n",
      " [0.82492764 0.81956675]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00144367]\n",
      " [ 0.00558451]\n",
      " [ 0.00951287]\n",
      " [ 0.01424696]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49963908]\n",
      " [0.50139612]\n",
      " [0.5023782 ]\n",
      " [0.50356168]]\n",
      "Error [[-0.49963908]\n",
      " [ 0.49860388]\n",
      " [ 0.4976218 ]\n",
      " [-0.50356168]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23042628 0.91288326]\n",
      " [0.81067601 1.33941631]\n",
      " [0.96997217 1.08685913]\n",
      " [1.55022191 1.51339219]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55735302 0.7135898 ]\n",
      " [0.69225354 0.79239394]\n",
      " [0.72511395 0.74778981]\n",
      " [0.82494578 0.81956339]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00148474]\n",
      " [ 0.00558123]\n",
      " [ 0.00952161]\n",
      " [ 0.0142827 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49962881]\n",
      " [0.5013953 ]\n",
      " [0.50238038]\n",
      " [0.50357061]]\n",
      "Error [[-0.49962881]\n",
      " [ 0.4986047 ]\n",
      " [ 0.49761962]\n",
      " [-0.50357061]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23044341 0.91288387]\n",
      " [0.81075404 1.33941035]\n",
      " [0.97003741 1.08684289]\n",
      " [1.55034804 1.51336937]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55735725 0.71358993]\n",
      " [0.69227016 0.79239296]\n",
      " [0.72512695 0.74778675]\n",
      " [0.82496399 0.81956001]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00152582]\n",
      " [ 0.00557797]\n",
      " [ 0.00953036]\n",
      " [ 0.01431844]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49961854]\n",
      " [0.50139449]\n",
      " [0.50238257]\n",
      " [0.50357955]]\n",
      "Error [[-0.49961854]\n",
      " [ 0.49860551]\n",
      " [ 0.49761743]\n",
      " [-0.50357955]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23046061 0.91288448]\n",
      " [0.81083239 1.33940438]\n",
      " [0.97010292 1.08682663]\n",
      " [1.5504747  1.51334653]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5573615  0.71359005]\n",
      " [0.69228685 0.79239198]\n",
      " [0.72514001 0.74778368]\n",
      " [0.82498228 0.81955663]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00156691]\n",
      " [ 0.00557471]\n",
      " [ 0.00953911]\n",
      " [ 0.0143542 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49960827]\n",
      " [0.50139367]\n",
      " [0.50238476]\n",
      " [0.50358849]]\n",
      "Error [[-0.49960827]\n",
      " [ 0.49860633]\n",
      " [ 0.49761524]\n",
      " [-0.50358849]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23047789 0.9128851 ]\n",
      " [0.81091107 1.33939841]\n",
      " [0.97016871 1.08681034]\n",
      " [1.55060189 1.51332365]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55736576 0.71359018]\n",
      " [0.69230361 0.79239099]\n",
      " [0.72515312 0.74778061]\n",
      " [0.82500065 0.81955325]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.001608  ]\n",
      " [ 0.00557146]\n",
      " [ 0.00954788]\n",
      " [ 0.01438997]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.499598  ]\n",
      " [0.50139286]\n",
      " [0.50238695]\n",
      " [0.50359743]]\n",
      "Error [[-0.499598  ]\n",
      " [ 0.49860714]\n",
      " [ 0.49761305]\n",
      " [-0.50359743]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23049524 0.91288571]\n",
      " [0.81099009 1.33939243]\n",
      " [0.97023477 1.08679403]\n",
      " [1.55072962 1.51330074]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55737004 0.71359031]\n",
      " [0.69232045 0.79239001]\n",
      " [0.72516629 0.74777754]\n",
      " [0.82501909 0.81954986]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00164909]\n",
      " [ 0.00556822]\n",
      " [ 0.00955665]\n",
      " [ 0.01442576]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49958773]\n",
      " [0.50139205]\n",
      " [0.50238914]\n",
      " [0.50360638]]\n",
      "Error [[-0.49958773]\n",
      " [ 0.49860795]\n",
      " [ 0.49761086]\n",
      " [-0.50360638]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23051267 0.91288633]\n",
      " [0.81106943 1.33938644]\n",
      " [0.97030111 1.0867777 ]\n",
      " [1.55085788 1.51327781]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55737434 0.71359043]\n",
      " [0.69233735 0.79238902]\n",
      " [0.72517951 0.74777446]\n",
      " [0.8250376  0.81954647]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00169018]\n",
      " [ 0.00556499]\n",
      " [ 0.00956543]\n",
      " [ 0.01446155]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49957745]\n",
      " [0.50139124]\n",
      " [0.50239134]\n",
      " [0.50361532]]\n",
      "Error [[-0.49957745]\n",
      " [ 0.49860876]\n",
      " [ 0.49760866]\n",
      " [-0.50361532]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23053016 0.91288695]\n",
      " [0.81114911 1.33938044]\n",
      " [0.97036773 1.08676134]\n",
      " [1.55098667 1.51325484]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55737865 0.71359056]\n",
      " [0.69235432 0.79238804]\n",
      " [0.72519279 0.74777137]\n",
      " [0.82505619 0.81954307]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00173128]\n",
      " [ 0.00556176]\n",
      " [ 0.00957422]\n",
      " [ 0.01449736]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49956718]\n",
      " [0.50139044]\n",
      " [0.50239354]\n",
      " [0.50362428]]\n",
      "Error [[-0.49956718]\n",
      " [ 0.49860956]\n",
      " [ 0.49760646]\n",
      " [-0.50362428]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23054773 0.91288756]\n",
      " [0.81122911 1.33937444]\n",
      " [0.97043462 1.08674496]\n",
      " [1.551116   1.51323184]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55738299 0.71359068]\n",
      " [0.69237136 0.79238705]\n",
      " [0.72520612 0.74776828]\n",
      " [0.82507486 0.81953967]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00177239]\n",
      " [ 0.00555855]\n",
      " [ 0.00958301]\n",
      " [ 0.01453318]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4995569 ]\n",
      " [0.50138963]\n",
      " [0.50239573]\n",
      " [0.50363323]]\n",
      "Error [[-0.4995569 ]\n",
      " [ 0.49861037]\n",
      " [ 0.49760427]\n",
      " [-0.50363323]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23056538 0.91288818]\n",
      " [0.81130945 1.33936843]\n",
      " [0.97050179 1.08672856]\n",
      " [1.55124586 1.51320882]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55738734 0.71359081]\n",
      " [0.69238847 0.79238606]\n",
      " [0.7252195  0.74776519]\n",
      " [0.8250936  0.81953627]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00181349]\n",
      " [ 0.00555534]\n",
      " [ 0.00959181]\n",
      " [ 0.01456902]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49954663]\n",
      " [0.50138883]\n",
      " [0.50239794]\n",
      " [0.50364219]]\n",
      "Error [[-0.49954663]\n",
      " [ 0.49861117]\n",
      " [ 0.49760206]\n",
      " [-0.50364219]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2305831  0.9128888 ]\n",
      " [0.81139011 1.33936241]\n",
      " [0.97056924 1.08671214]\n",
      " [1.55137626 1.51318576]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55739171 0.71359094]\n",
      " [0.69240565 0.79238507]\n",
      " [0.72523295 0.74776209]\n",
      " [0.82511242 0.81953286]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00185461]\n",
      " [ 0.00555215]\n",
      " [ 0.00960063]\n",
      " [ 0.01460486]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49953635]\n",
      " [0.50138803]\n",
      " [0.50240014]\n",
      " [0.50365115]]\n",
      "Error [[-0.49953635]\n",
      " [ 0.49861197]\n",
      " [ 0.49759986]\n",
      " [-0.50365115]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23060089 0.91288941]\n",
      " [0.81147111 1.33935639]\n",
      " [0.97063697 1.0866957 ]\n",
      " [1.55150719 1.51316267]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5573961  0.71359106]\n",
      " [0.6924229  0.79238408]\n",
      " [0.72524644 0.74775899]\n",
      " [0.82513131 0.81952944]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00189572]\n",
      " [ 0.00554896]\n",
      " [ 0.00960944]\n",
      " [ 0.01464072]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49952607]\n",
      " [0.50138724]\n",
      " [0.50240234]\n",
      " [0.50366012]]\n",
      "Error [[-0.49952607]\n",
      " [ 0.49861276]\n",
      " [ 0.49759766]\n",
      " [-0.50366012]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23061876 0.91289003]\n",
      " [0.81155244 1.33935035]\n",
      " [0.97070497 1.08667923]\n",
      " [1.55163865 1.51313955]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55740051 0.71359119]\n",
      " [0.69244022 0.79238309]\n",
      " [0.72525999 0.74775588]\n",
      " [0.82515028 0.81952602]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00193684]\n",
      " [ 0.00554578]\n",
      " [ 0.00961827]\n",
      " [ 0.0146766 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49951579]\n",
      " [0.50138644]\n",
      " [0.50240455]\n",
      " [0.50366908]]\n",
      "Error [[-0.49951579]\n",
      " [ 0.49861356]\n",
      " [ 0.49759545]\n",
      " [-0.50366908]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23063669 0.91289065]\n",
      " [0.8116341  1.33934431]\n",
      " [0.97077324 1.08666274]\n",
      " [1.55177065 1.51311641]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55740494 0.71359132]\n",
      " [0.69245761 0.79238209]\n",
      " [0.7252736  0.74775277]\n",
      " [0.82516932 0.8195226 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00197796]\n",
      " [ 0.0055426 ]\n",
      " [ 0.0096271 ]\n",
      " [ 0.01471248]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49950551]\n",
      " [0.50138565]\n",
      " [0.50240676]\n",
      " [0.50367805]]\n",
      "Error [[-0.49950551]\n",
      " [ 0.49861435]\n",
      " [ 0.49759324]\n",
      " [-0.50367805]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23065471 0.91289127]\n",
      " [0.81171609 1.33933826]\n",
      " [0.9708418  1.08664623]\n",
      " [1.55190318 1.51309323]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55740938 0.71359144]\n",
      " [0.69247507 0.7923811 ]\n",
      " [0.72528725 0.74774966]\n",
      " [0.82518844 0.81951917]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00201909]\n",
      " [ 0.00553944]\n",
      " [ 0.00963595]\n",
      " [ 0.01474838]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49949523]\n",
      " [0.50138486]\n",
      " [0.50240897]\n",
      " [0.50368703]]\n",
      "Error [[-0.49949523]\n",
      " [ 0.49861514]\n",
      " [ 0.49759103]\n",
      " [-0.50368703]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23067279 0.91289189]\n",
      " [0.81179841 1.33933221]\n",
      " [0.97091063 1.0866297 ]\n",
      " [1.55203625 1.51307002]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55741384 0.71359157]\n",
      " [0.6924926  0.7923801 ]\n",
      " [0.72530097 0.74774654]\n",
      " [0.82520763 0.81951574]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00206022]\n",
      " [ 0.00553628]\n",
      " [ 0.00964479]\n",
      " [ 0.01478429]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49948494]\n",
      " [0.50138407]\n",
      " [0.50241118]\n",
      " [0.50369601]]\n",
      "Error [[-0.49948494]\n",
      " [ 0.49861593]\n",
      " [ 0.49758882]\n",
      " [-0.50369601]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23069095 0.91289251]\n",
      " [0.81188106 1.33932615]\n",
      " [0.97097974 1.08661314]\n",
      " [1.55216985 1.51304678]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55741832 0.7135917 ]\n",
      " [0.6925102  0.7923791 ]\n",
      " [0.72531474 0.74774342]\n",
      " [0.8252269  0.8195123 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00210136]\n",
      " [ 0.00553314]\n",
      " [ 0.00965365]\n",
      " [ 0.01482021]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49947466]\n",
      " [0.50138328]\n",
      " [0.50241339]\n",
      " [0.50370499]]\n",
      "Error [[-0.49947466]\n",
      " [ 0.49861672]\n",
      " [ 0.49758661]\n",
      " [-0.50370499]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23070919 0.91289313]\n",
      " [0.81196405 1.33932008]\n",
      " [0.97104913 1.08659657]\n",
      " [1.55230399 1.51302351]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55742282 0.71359182]\n",
      " [0.69252787 0.79237811]\n",
      " [0.72532856 0.74774029]\n",
      " [0.82524625 0.81950886]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0021425 ]\n",
      " [ 0.00553   ]\n",
      " [ 0.00966252]\n",
      " [ 0.01485615]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49946437]\n",
      " [0.5013825 ]\n",
      " [0.50241561]\n",
      " [0.50371397]]\n",
      "Error [[-0.49946437]\n",
      " [ 0.4986175 ]\n",
      " [ 0.49758439]\n",
      " [-0.50371397]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23072749 0.91289375]\n",
      " [0.81204736 1.339314  ]\n",
      " [0.97111879 1.08657997]\n",
      " [1.55243866 1.51300021]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55742734 0.71359195]\n",
      " [0.69254561 0.79237711]\n",
      " [0.72534244 0.74773716]\n",
      " [0.82526567 0.81950541]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00218365]\n",
      " [ 0.00552687]\n",
      " [ 0.00967139]\n",
      " [ 0.0148921 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49945409]\n",
      " [0.50138171]\n",
      " [0.50241783]\n",
      " [0.50372296]]\n",
      "Error [[-0.49945409]\n",
      " [ 0.49861829]\n",
      " [ 0.49758217]\n",
      " [-0.50372296]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23074587 0.91289437]\n",
      " [0.81213101 1.33930792]\n",
      " [0.97118874 1.08656334]\n",
      " [1.55257387 1.51297688]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55743187 0.71359208]\n",
      " [0.69256342 0.79237611]\n",
      " [0.72535637 0.74773402]\n",
      " [0.82528517 0.81950196]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0022248 ]\n",
      " [ 0.00552375]\n",
      " [ 0.00968027]\n",
      " [ 0.01492807]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4994438 ]\n",
      " [0.50138093]\n",
      " [0.50242005]\n",
      " [0.50373195]]\n",
      "Error [[-0.4994438 ]\n",
      " [ 0.49861907]\n",
      " [ 0.49757995]\n",
      " [-0.50373195]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23076433 0.912895  ]\n",
      " [0.81221499 1.33930182]\n",
      " [0.97125896 1.0865467 ]\n",
      " [1.55270961 1.51295353]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55743642 0.7135922 ]\n",
      " [0.6925813  0.7923751 ]\n",
      " [0.72537036 0.74773088]\n",
      " [0.82530474 0.81949851]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00226595]\n",
      " [ 0.00552064]\n",
      " [ 0.00968916]\n",
      " [ 0.01496404]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49943351]\n",
      " [0.50138016]\n",
      " [0.50242227]\n",
      " [0.50374094]]\n",
      "Error [[-0.49943351]\n",
      " [ 0.49861984]\n",
      " [ 0.49757773]\n",
      " [-0.50374094]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23078286 0.91289562]\n",
      " [0.8122993  1.33929572]\n",
      " [0.97132945 1.08653003]\n",
      " [1.55284589 1.51293014]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55744099 0.71359233]\n",
      " [0.69259925 0.7923741 ]\n",
      " [0.72538441 0.74772774]\n",
      " [0.82532439 0.81949505]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00230711]\n",
      " [ 0.00551754]\n",
      " [ 0.00969806]\n",
      " [ 0.01500003]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49942322]\n",
      " [0.50137938]\n",
      " [0.50242449]\n",
      " [0.50374994]]\n",
      "Error [[-0.49942322]\n",
      " [ 0.49862062]\n",
      " [ 0.49757551]\n",
      " [-0.50374994]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23080146 0.91289624]\n",
      " [0.81238394 1.33928962]\n",
      " [0.97140023 1.08651334]\n",
      " [1.55298271 1.51290672]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55744558 0.71359246]\n",
      " [0.69261727 0.79237309]\n",
      " [0.7253985  0.74772459]\n",
      " [0.82534411 0.81949158]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00234827]\n",
      " [ 0.00551444]\n",
      " [ 0.00970696]\n",
      " [ 0.01503604]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49941293]\n",
      " [0.50137861]\n",
      " [0.50242672]\n",
      " [0.50375894]]\n",
      "Error [[-0.49941293]\n",
      " [ 0.49862139]\n",
      " [ 0.49757328]\n",
      " [-0.50375894]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23082014 0.91289686]\n",
      " [0.81246891 1.3392835 ]\n",
      " [0.97147128 1.08649663]\n",
      " [1.55312006 1.51288327]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55745019 0.71359258]\n",
      " [0.69263536 0.79237209]\n",
      " [0.72541266 0.74772144]\n",
      " [0.82536391 0.81948811]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00238944]\n",
      " [ 0.00551136]\n",
      " [ 0.00971587]\n",
      " [ 0.01507205]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49940264]\n",
      " [0.50137784]\n",
      " [0.50242895]\n",
      " [0.50376794]]\n",
      "Error [[-0.49940264]\n",
      " [ 0.49862216]\n",
      " [ 0.49757105]\n",
      " [-0.50376794]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23083889 0.91289749]\n",
      " [0.81255422 1.33927738]\n",
      " [0.97154261 1.08647989]\n",
      " [1.55325794 1.51285979]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55745482 0.71359271]\n",
      " [0.69265353 0.79237108]\n",
      " [0.72542687 0.74771828]\n",
      " [0.82538378 0.81948464]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00243062]\n",
      " [ 0.00550828]\n",
      " [ 0.00972479]\n",
      " [ 0.01510808]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49939235]\n",
      " [0.50137707]\n",
      " [0.50243118]\n",
      " [0.50377695]]\n",
      "Error [[-0.49939235]\n",
      " [ 0.49862293]\n",
      " [ 0.49756882]\n",
      " [-0.50377695]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23085771 0.91289811]\n",
      " [0.81263986 1.33927125]\n",
      " [0.97161422 1.08646314]\n",
      " [1.55339637 1.51283627]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55745946 0.71359284]\n",
      " [0.69267176 0.79237007]\n",
      " [0.72544113 0.74771512]\n",
      " [0.82540373 0.81948116]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0024718 ]\n",
      " [ 0.00550521]\n",
      " [ 0.00973372]\n",
      " [ 0.01514413]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49938205]\n",
      " [0.5013763 ]\n",
      " [0.50243341]\n",
      " [0.50378596]]\n",
      "Error [[-0.49938205]\n",
      " [ 0.4986237 ]\n",
      " [ 0.49756659]\n",
      " [-0.50378596]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23087661 0.91289874]\n",
      " [0.81272583 1.33926512]\n",
      " [0.97168611 1.08644636]\n",
      " [1.55353533 1.51281273]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55746412 0.71359297]\n",
      " [0.69269006 0.79236906]\n",
      " [0.72545545 0.74771196]\n",
      " [0.82542376 0.81947768]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00251298]\n",
      " [ 0.00550215]\n",
      " [ 0.00974266]\n",
      " [ 0.01518018]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49937176]\n",
      " [0.50137554]\n",
      " [0.50243564]\n",
      " [0.50379497]]\n",
      "Error [[-0.49937176]\n",
      " [ 0.49862446]\n",
      " [ 0.49756436]\n",
      " [-0.50379497]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23089558 0.91289936]\n",
      " [0.81281213 1.33925897]\n",
      " [0.97175827 1.08642955]\n",
      " [1.55367482 1.51278916]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5574688  0.7135931 ]\n",
      " [0.69270843 0.79236805]\n",
      " [0.72546982 0.74770879]\n",
      " [0.82544386 0.81947419]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00255417]\n",
      " [ 0.0054991 ]\n",
      " [ 0.0097516 ]\n",
      " [ 0.01521625]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49936146]\n",
      " [0.50137477]\n",
      " [0.50243788]\n",
      " [0.50380399]]\n",
      "Error [[-0.49936146]\n",
      " [ 0.49862523]\n",
      " [ 0.49756212]\n",
      " [-0.50380399]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23091462 0.91289999]\n",
      " [0.81289876 1.33925282]\n",
      " [0.97183072 1.08641273]\n",
      " [1.55381486 1.51276556]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5574735  0.71359322]\n",
      " [0.69272687 0.79236704]\n",
      " [0.72548425 0.74770561]\n",
      " [0.82546403 0.8194707 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00259536]\n",
      " [ 0.00549606]\n",
      " [ 0.00976055]\n",
      " [ 0.01525234]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49935116]\n",
      " [0.50137401]\n",
      " [0.50244012]\n",
      " [0.50381301]]\n",
      "Error [[-0.49935116]\n",
      " [ 0.49862599]\n",
      " [ 0.49755988]\n",
      " [-0.50381301]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23093374 0.91290062]\n",
      " [0.81298573 1.33924666]\n",
      " [0.97190344 1.08639588]\n",
      " [1.55395543 1.51274193]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55747822 0.71359335]\n",
      " [0.69274538 0.79236603]\n",
      " [0.72549873 0.74770244]\n",
      " [0.82548428 0.81946721]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00263656]\n",
      " [ 0.00549303]\n",
      " [ 0.00976951]\n",
      " [ 0.01528843]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49934086]\n",
      " [0.50137325]\n",
      " [0.50244236]\n",
      " [0.50382203]]\n",
      "Error [[-0.49934086]\n",
      " [ 0.49862675]\n",
      " [ 0.49755764]\n",
      " [-0.50382203]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23095294 0.91290124]\n",
      " [0.81307303 1.3392405 ]\n",
      " [0.97197644 1.08637901]\n",
      " [1.55409653 1.51271827]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55748295 0.71359348]\n",
      " [0.69276396 0.79236501]\n",
      " [0.72551327 0.74769925]\n",
      " [0.82550461 0.8194637 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00267777]\n",
      " [ 0.00549   ]\n",
      " [ 0.00977848]\n",
      " [ 0.01532454]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49933056]\n",
      " [0.5013725 ]\n",
      " [0.5024446 ]\n",
      " [0.50383106]]\n",
      "Error [[-0.49933056]\n",
      " [ 0.4986275 ]\n",
      " [ 0.4975554 ]\n",
      " [-0.50383106]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2309722  0.91290187]\n",
      " [0.81316066 1.33923432]\n",
      " [0.97204972 1.08636212]\n",
      " [1.55423818 1.51269457]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55748771 0.71359361]\n",
      " [0.69278261 0.792364  ]\n",
      " [0.72552786 0.74769607]\n",
      " [0.82552501 0.8194602 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00271898]\n",
      " [ 0.00548699]\n",
      " [ 0.00978745]\n",
      " [ 0.01536067]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49932026]\n",
      " [0.50137174]\n",
      " [0.50244684]\n",
      " [0.50384009]]\n",
      "Error [[-0.49932026]\n",
      " [ 0.49862826]\n",
      " [ 0.49755316]\n",
      " [-0.50384009]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23099155 0.9129025 ]\n",
      " [0.81324863 1.33922814]\n",
      " [0.97212328 1.0863452 ]\n",
      " [1.55438036 1.51267085]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55749248 0.71359374]\n",
      " [0.69280134 0.79236298]\n",
      " [0.72554251 0.74769288]\n",
      " [0.82554549 0.81945669]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00276019]\n",
      " [ 0.00548398]\n",
      " [ 0.00979644]\n",
      " [ 0.01539681]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49930995]\n",
      " [0.50137099]\n",
      " [0.50244909]\n",
      " [0.50384913]]\n",
      "Error [[-0.49930995]\n",
      " [ 0.49862901]\n",
      " [ 0.49755091]\n",
      " [-0.50384913]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23101096 0.91290312]\n",
      " [0.81333693 1.33922196]\n",
      " [0.97219711 1.08632827]\n",
      " [1.55452308 1.5126471 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55749727 0.71359386]\n",
      " [0.69282013 0.79236196]\n",
      " [0.72555721 0.74768968]\n",
      " [0.82556605 0.81945318]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00280141]\n",
      " [ 0.00548098]\n",
      " [ 0.00980543]\n",
      " [ 0.01543296]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49929965]\n",
      " [0.50137024]\n",
      " [0.50245134]\n",
      " [0.50385816]]\n",
      "Error [[-0.49929965]\n",
      " [ 0.49862976]\n",
      " [ 0.49754866]\n",
      " [-0.50385816]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23103045 0.91290375]\n",
      " [0.81342556 1.33921576]\n",
      " [0.97227123 1.08631131]\n",
      " [1.55466634 1.51262331]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55750208 0.71359399]\n",
      " [0.69283899 0.79236094]\n",
      " [0.72557197 0.74768648]\n",
      " [0.82558667 0.81944966]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00284264]\n",
      " [ 0.005478  ]\n",
      " [ 0.00981443]\n",
      " [ 0.01546913]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49928934]\n",
      " [0.5013695 ]\n",
      " [0.50245359]\n",
      " [0.5038672 ]]\n",
      "Error [[-0.49928934]\n",
      " [ 0.4986305 ]\n",
      " [ 0.49754641]\n",
      " [-0.5038672 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23105001 0.91290438]\n",
      " [0.81351452 1.33920956]\n",
      " [0.97234562 1.08629432]\n",
      " [1.55481013 1.5125995 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5575069  0.71359412]\n",
      " [0.69285792 0.79235992]\n",
      " [0.72558678 0.74768328]\n",
      " [0.82560738 0.81944613]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00288387]\n",
      " [ 0.00547502]\n",
      " [ 0.00982344]\n",
      " [ 0.01550531]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49927903]\n",
      " [0.50136875]\n",
      " [0.50245584]\n",
      " [0.50387625]]\n",
      "Error [[-0.49927903]\n",
      " [ 0.49863125]\n",
      " [ 0.49754416]\n",
      " [-0.50387625]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23106965 0.91290501]\n",
      " [0.81360382 1.33920335]\n",
      " [0.9724203  1.08627732]\n",
      " [1.55495446 1.51257566]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55751175 0.71359425]\n",
      " [0.69287692 0.7923589 ]\n",
      " [0.72560165 0.74768007]\n",
      " [0.82562816 0.81944261]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00292511]\n",
      " [ 0.00547204]\n",
      " [ 0.00983245]\n",
      " [ 0.0155415 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49926872]\n",
      " [0.50136801]\n",
      " [0.50245809]\n",
      " [0.5038853 ]]\n",
      "Error [[-0.49926872]\n",
      " [ 0.49863199]\n",
      " [ 0.49754191]\n",
      " [-0.5038853 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23108936 0.91290564]\n",
      " [0.81369345 1.33919713]\n",
      " [0.97249525 1.08626029]\n",
      " [1.55509934 1.51255178]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55751661 0.71359438]\n",
      " [0.692896   0.79235788]\n",
      " [0.72561657 0.74767686]\n",
      " [0.82564901 0.81943907]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00296635]\n",
      " [ 0.00546908]\n",
      " [ 0.00984148]\n",
      " [ 0.01557771]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49925841]\n",
      " [0.50136727]\n",
      " [0.50246035]\n",
      " [0.50389435]]\n",
      "Error [[-0.49925841]\n",
      " [ 0.49863273]\n",
      " [ 0.49753965]\n",
      " [-0.50389435]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23110915 0.91290627]\n",
      " [0.81378342 1.33919091]\n",
      " [0.97257048 1.08624324]\n",
      " [1.55524475 1.51252788]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55752149 0.71359451]\n",
      " [0.69291514 0.79235685]\n",
      " [0.72563155 0.74767364]\n",
      " [0.82566995 0.81943554]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0030076 ]\n",
      " [ 0.00546613]\n",
      " [ 0.00985051]\n",
      " [ 0.01561393]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4992481 ]\n",
      " [0.50136653]\n",
      " [0.50246261]\n",
      " [0.5039034 ]]\n",
      "Error [[-0.4992481 ]\n",
      " [ 0.49863347]\n",
      " [ 0.49753739]\n",
      " [-0.5039034 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23112901 0.9129069 ]\n",
      " [0.81387371 1.33918467]\n",
      " [0.97264599 1.08622617]\n",
      " [1.5553907  1.51250394]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55752639 0.71359464]\n",
      " [0.69293435 0.79235583]\n",
      " [0.72564659 0.74767042]\n",
      " [0.82569095 0.81943199]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00304886]\n",
      " [ 0.00546318]\n",
      " [ 0.00985955]\n",
      " [ 0.01565017]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49923779]\n",
      " [0.50136579]\n",
      " [0.50246487]\n",
      " [0.50391246]]\n",
      "Error [[-0.49923779]\n",
      " [ 0.49863421]\n",
      " [ 0.49753513]\n",
      " [-0.50391246]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23114894 0.91290753]\n",
      " [0.81396434 1.33917844]\n",
      " [0.97272178 1.08620907]\n",
      " [1.55553718 1.51247997]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55753131 0.71359477]\n",
      " [0.69295364 0.7923548 ]\n",
      " [0.72566167 0.74766719]\n",
      " [0.82571203 0.81942845]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00309012]\n",
      " [ 0.00546025]\n",
      " [ 0.0098686 ]\n",
      " [ 0.01568642]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49922747]\n",
      " [0.50136506]\n",
      " [0.50246713]\n",
      " [0.50392152]]\n",
      "Error [[-0.49922747]\n",
      " [ 0.49863494]\n",
      " [ 0.49753287]\n",
      " [-0.50392152]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23116895 0.91290817]\n",
      " [0.81405531 1.33917219]\n",
      " [0.97279785 1.08619195]\n",
      " [1.55568421 1.51245598]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55753624 0.71359489]\n",
      " [0.69297299 0.79235378]\n",
      " [0.72567682 0.74766396]\n",
      " [0.82573319 0.8194249 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00313138]\n",
      " [ 0.00545732]\n",
      " [ 0.00987765]\n",
      " [ 0.01572268]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49921715]\n",
      " [0.50136433]\n",
      " [0.50246939]\n",
      " [0.50393059]]\n",
      "Error [[-0.49921715]\n",
      " [ 0.49863567]\n",
      " [ 0.49753061]\n",
      " [-0.50393059]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23118903 0.9129088 ]\n",
      " [0.81414661 1.33916593]\n",
      " [0.9728742  1.08617481]\n",
      " [1.55583178 1.51243195]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5575412  0.71359502]\n",
      " [0.69299242 0.79235275]\n",
      " [0.72569202 0.74766073]\n",
      " [0.82575443 0.81942134]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00317266]\n",
      " [ 0.0054544 ]\n",
      " [ 0.00988672]\n",
      " [ 0.01575896]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49920684]\n",
      " [0.5013636 ]\n",
      " [0.50247166]\n",
      " [0.50393966]]\n",
      "Error [[-0.49920684]\n",
      " [ 0.4986364 ]\n",
      " [ 0.49752834]\n",
      " [-0.50393966]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23120919 0.91290943]\n",
      " [0.81423824 1.33915967]\n",
      " [0.97295083 1.08615765]\n",
      " [1.55597988 1.51240789]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55754617 0.71359515]\n",
      " [0.69301191 0.79235172]\n",
      " [0.72570727 0.74765749]\n",
      " [0.82577574 0.81941778]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00321394]\n",
      " [ 0.00545149]\n",
      " [ 0.00989579]\n",
      " [ 0.01579525]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49919652]\n",
      " [0.50136287]\n",
      " [0.50247393]\n",
      " [0.50394873]]\n",
      "Error [[-0.49919652]\n",
      " [ 0.49863713]\n",
      " [ 0.49752607]\n",
      " [-0.50394873]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23122942 0.91291006]\n",
      " [0.81433021 1.3391534 ]\n",
      " [0.97302774 1.08614046]\n",
      " [1.55612853 1.5123838 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55755116 0.71359528]\n",
      " [0.69303148 0.79235068]\n",
      " [0.72572258 0.74765425]\n",
      " [0.82579712 0.81941422]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00325522]\n",
      " [ 0.00544859]\n",
      " [ 0.00990487]\n",
      " [ 0.01583156]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4991862 ]\n",
      " [0.50136215]\n",
      " [0.5024762 ]\n",
      " [0.50395781]]\n",
      "Error [[-0.4991862 ]\n",
      " [ 0.49863785]\n",
      " [ 0.4975238 ]\n",
      " [-0.50395781]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23124973 0.9129107 ]\n",
      " [0.81442251 1.33914713]\n",
      " [0.97310493 1.08612325]\n",
      " [1.55627771 1.51235969]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55755617 0.71359541]\n",
      " [0.69305111 0.79234965]\n",
      " [0.72573794 0.747651  ]\n",
      " [0.82581858 0.81941065]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00329651]\n",
      " [ 0.0054457 ]\n",
      " [ 0.00991396]\n",
      " [ 0.01586788]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49917587]\n",
      " [0.50136142]\n",
      " [0.50247847]\n",
      " [0.50396689]]\n",
      "Error [[-0.49917587]\n",
      " [ 0.49863858]\n",
      " [ 0.49752153]\n",
      " [-0.50396689]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23127011 0.91291133]\n",
      " [0.81451514 1.33914084]\n",
      " [0.9731824  1.08610602]\n",
      " [1.55642744 1.51233554]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5575612  0.71359554]\n",
      " [0.69307082 0.79234862]\n",
      " [0.72575336 0.74764775]\n",
      " [0.82584012 0.81940708]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00333781]\n",
      " [ 0.00544282]\n",
      " [ 0.00992305]\n",
      " [ 0.01590422]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49916555]\n",
      " [0.5013607 ]\n",
      " [0.50248074]\n",
      " [0.50397597]]\n",
      "Error [[-0.49916555]\n",
      " [ 0.4986393 ]\n",
      " [ 0.49751926]\n",
      " [-0.50397597]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23129056 0.91291197]\n",
      " [0.81460811 1.33913455]\n",
      " [0.97326015 1.08608877]\n",
      " [1.5565777  1.51231136]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55756624 0.71359567]\n",
      " [0.69309059 0.79234758]\n",
      " [0.72576884 0.7476445 ]\n",
      " [0.82586173 0.8194035 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00337911]\n",
      " [ 0.00543995]\n",
      " [ 0.00993216]\n",
      " [ 0.01594057]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49915522]\n",
      " [0.50135998]\n",
      " [0.50248302]\n",
      " [0.50398506]]\n",
      "Error [[-0.49915522]\n",
      " [ 0.49864002]\n",
      " [ 0.49751698]\n",
      " [-0.50398506]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23131109 0.9129126 ]\n",
      " [0.81470142 1.33912826]\n",
      " [0.97333818 1.08607149]\n",
      " [1.55672851 1.51228715]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55757131 0.7135958 ]\n",
      " [0.69311044 0.79234655]\n",
      " [0.72578437 0.74764124]\n",
      " [0.82588341 0.81939991]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00342042]\n",
      " [ 0.00543708]\n",
      " [ 0.00994127]\n",
      " [ 0.01597693]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49914489]\n",
      " [0.50135927]\n",
      " [0.5024853 ]\n",
      " [0.50399415]]\n",
      "Error [[-0.49914489]\n",
      " [ 0.49864073]\n",
      " [ 0.4975147 ]\n",
      " [-0.50399415]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23133169 0.91291324]\n",
      " [0.81479505 1.33912195]\n",
      " [0.97341649 1.08605419]\n",
      " [1.55687985 1.51226291]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55757639 0.71359593]\n",
      " [0.69313036 0.79234551]\n",
      " [0.72579995 0.74763797]\n",
      " [0.82590518 0.81939633]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00346174]\n",
      " [ 0.00543423]\n",
      " [ 0.00995039]\n",
      " [ 0.01601331]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49913457]\n",
      " [0.50135855]\n",
      " [0.50248758]\n",
      " [0.50400324]]\n",
      "Error [[-0.49913457]\n",
      " [ 0.49864145]\n",
      " [ 0.49751242]\n",
      " [-0.50400324]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23135237 0.91291387]\n",
      " [0.81488903 1.33911564]\n",
      " [0.97349508 1.08603687]\n",
      " [1.55703174 1.51223864]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55758149 0.71359606]\n",
      " [0.69315035 0.79234447]\n",
      " [0.72581559 0.7476347 ]\n",
      " [0.82592701 0.81939274]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00350307]\n",
      " [ 0.00543138]\n",
      " [ 0.00995952]\n",
      " [ 0.01604971]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49912423]\n",
      " [0.50135784]\n",
      " [0.50248986]\n",
      " [0.50401234]]\n",
      "Error [[-0.49912423]\n",
      " [ 0.49864216]\n",
      " [ 0.49751014]\n",
      " [-0.50401234]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23137312 0.91291451]\n",
      " [0.81498333 1.33910932]\n",
      " [0.97357395 1.08601952]\n",
      " [1.55718416 1.51221433]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55758661 0.71359619]\n",
      " [0.6931704  0.79234343]\n",
      " [0.72583129 0.74763143]\n",
      " [0.82594893 0.81938914]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0035444 ]\n",
      " [ 0.00542855]\n",
      " [ 0.00996866]\n",
      " [ 0.01608612]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4991139 ]\n",
      " [0.50135713]\n",
      " [0.50249214]\n",
      " [0.50402144]]\n",
      "Error [[-0.4991139 ]\n",
      " [ 0.49864287]\n",
      " [ 0.49750786]\n",
      " [-0.50402144]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23139394 0.91291514]\n",
      " [0.81507798 1.33910299]\n",
      " [0.9736531  1.08600216]\n",
      " [1.55733713 1.51219   ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55759174 0.71359632]\n",
      " [0.69319053 0.79234239]\n",
      " [0.72584704 0.74762815]\n",
      " [0.82597092 0.81938554]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00358573]\n",
      " [ 0.00542572]\n",
      " [ 0.0099778 ]\n",
      " [ 0.01612254]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49910357]\n",
      " [0.50135643]\n",
      " [0.50249443]\n",
      " [0.50403055]]\n",
      "Error [[-0.49910357]\n",
      " [ 0.49864357]\n",
      " [ 0.49750557]\n",
      " [-0.50403055]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23141485 0.91291578]\n",
      " [0.81517295 1.33909665]\n",
      " [0.97373253 1.08598477]\n",
      " [1.55749064 1.51216564]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5575969  0.71359645]\n",
      " [0.69321073 0.79234135]\n",
      " [0.72586285 0.74762487]\n",
      " [0.82599298 0.81938193]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00362708]\n",
      " [ 0.0054229 ]\n",
      " [ 0.00998696]\n",
      " [ 0.01615898]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49909323]\n",
      " [0.50135572]\n",
      " [0.50249672]\n",
      " [0.50403966]]\n",
      "Error [[-0.49909323]\n",
      " [ 0.49864428]\n",
      " [ 0.49750328]\n",
      " [-0.50403966]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23143582 0.91291642]\n",
      " [0.81526827 1.33909031]\n",
      " [0.97381225 1.08596735]\n",
      " [1.55764469 1.51214124]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55760207 0.71359658]\n",
      " [0.693231   0.7923403 ]\n",
      " [0.72587871 0.74762159]\n",
      " [0.82601512 0.81937832]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00366843]\n",
      " [ 0.00542009]\n",
      " [ 0.00999612]\n",
      " [ 0.01619543]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49908289]\n",
      " [0.50135502]\n",
      " [0.50249901]\n",
      " [0.50404877]]\n",
      "Error [[-0.49908289]\n",
      " [ 0.49864498]\n",
      " [ 0.49750099]\n",
      " [-0.50404877]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23145687 0.91291706]\n",
      " [0.81536391 1.33908396]\n",
      " [0.97389224 1.08594992]\n",
      " [1.55779929 1.51211682]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55760727 0.71359671]\n",
      " [0.69325134 0.79233926]\n",
      " [0.72589462 0.7476183 ]\n",
      " [0.82603734 0.81937471]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00370978]\n",
      " [ 0.00541729]\n",
      " [ 0.01000529]\n",
      " [ 0.0162319 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49907256]\n",
      " [0.50135432]\n",
      " [0.5025013 ]\n",
      " [0.50405789]]\n",
      "Error [[-0.49907256]\n",
      " [ 0.49864568]\n",
      " [ 0.4974987 ]\n",
      " [-0.50405789]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23147799 0.9129177 ]\n",
      " [0.8154599  1.33907761]\n",
      " [0.97397252 1.08593246]\n",
      " [1.55795442 1.51209237]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55761248 0.71359684]\n",
      " [0.69327175 0.79233821]\n",
      " [0.7259106  0.747615  ]\n",
      " [0.82605963 0.81937109]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00375115]\n",
      " [ 0.0054145 ]\n",
      " [ 0.01001447]\n",
      " [ 0.01626838]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49906221]\n",
      " [0.50135362]\n",
      " [0.5025036 ]\n",
      " [0.50406701]]\n",
      "Error [[-0.49906221]\n",
      " [ 0.49864638]\n",
      " [ 0.4974964 ]\n",
      " [-0.50406701]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23149919 0.91291834]\n",
      " [0.81555622 1.33907124]\n",
      " [0.97405307 1.08591498]\n",
      " [1.5581101  1.51206788]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55761771 0.71359697]\n",
      " [0.69329223 0.79233717]\n",
      " [0.72592662 0.7476117 ]\n",
      " [0.826082   0.81936746]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00379252]\n",
      " [ 0.00541171]\n",
      " [ 0.01002366]\n",
      " [ 0.01630488]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49905187]\n",
      " [0.50135292]\n",
      " [0.50250589]\n",
      " [0.50407613]]\n",
      "Error [[-0.49905187]\n",
      " [ 0.49864708]\n",
      " [ 0.49749411]\n",
      " [-0.50407613]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23152047 0.91291898]\n",
      " [0.81565287 1.33906487]\n",
      " [0.97413391 1.08589747]\n",
      " [1.55826631 1.51204337]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55762296 0.7135971 ]\n",
      " [0.69331279 0.79233612]\n",
      " [0.72594271 0.7476084 ]\n",
      " [0.82610444 0.81936384]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0038339 ]\n",
      " [ 0.00540894]\n",
      " [ 0.01003285]\n",
      " [ 0.01634139]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49904153]\n",
      " [0.50135223]\n",
      " [0.50250819]\n",
      " [0.50408526]]\n",
      "Error [[-0.49904153]\n",
      " [ 0.49864777]\n",
      " [ 0.49749181]\n",
      " [-0.50408526]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23154181 0.91291962]\n",
      " [0.81574986 1.33905849]\n",
      " [0.97421503 1.08587994]\n",
      " [1.55842307 1.51201882]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55762822 0.71359723]\n",
      " [0.69333341 0.79233507]\n",
      " [0.72595884 0.74760509]\n",
      " [0.82612696 0.8193602 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00387528]\n",
      " [ 0.00540617]\n",
      " [ 0.01004205]\n",
      " [ 0.01637792]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49903118]\n",
      " [0.50135154]\n",
      " [0.50251049]\n",
      " [0.50409439]]\n",
      "Error [[-0.49903118]\n",
      " [ 0.49864846]\n",
      " [ 0.49748951]\n",
      " [-0.50409439]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23156324 0.91292026]\n",
      " [0.81584718 1.3390521 ]\n",
      " [0.97429643 1.08586239]\n",
      " [1.55858038 1.51199424]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55763351 0.71359737]\n",
      " [0.6933541  0.79233402]\n",
      " [0.72597504 0.74760178]\n",
      " [0.82614955 0.81935657]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00391667]\n",
      " [ 0.00540342]\n",
      " [ 0.01005127]\n",
      " [ 0.01641446]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49902083]\n",
      " [0.50135085]\n",
      " [0.5025128 ]\n",
      " [0.50410352]]\n",
      "Error [[-0.49902083]\n",
      " [ 0.49864915]\n",
      " [ 0.4974872 ]\n",
      " [-0.50410352]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23158473 0.9129209 ]\n",
      " [0.81594485 1.33904571]\n",
      " [0.97437811 1.08584482]\n",
      " [1.55873822 1.51196963]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55763881 0.7135975 ]\n",
      " [0.69337487 0.79233297]\n",
      " [0.72599129 0.74759847]\n",
      " [0.82617222 0.81935292]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00395807]\n",
      " [ 0.00540067]\n",
      " [ 0.01006049]\n",
      " [ 0.01645102]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49901048]\n",
      " [0.50135016]\n",
      " [0.5025151 ]\n",
      " [0.50411266]]\n",
      "Error [[-0.49901048]\n",
      " [ 0.49864984]\n",
      " [ 0.4974849 ]\n",
      " [-0.50411266]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2316063  0.91292154]\n",
      " [0.81604284 1.33903931]\n",
      " [0.97446007 1.08582722]\n",
      " [1.55889661 1.511945  ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55764413 0.71359763]\n",
      " [0.6933957  0.79233191]\n",
      " [0.72600759 0.74759515]\n",
      " [0.82619497 0.81934928]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00399948]\n",
      " [ 0.00539794]\n",
      " [ 0.01006972]\n",
      " [ 0.0164876 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49900013]\n",
      " [0.50134948]\n",
      " [0.50251741]\n",
      " [0.50412181]]\n",
      "Error [[-0.49900013]\n",
      " [ 0.49865052]\n",
      " [ 0.49748259]\n",
      " [-0.50412181]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggrigation in hidden layer\n",
      "[[0.23162795 0.91292218]\n",
      " [0.81614118 1.3390329 ]\n",
      " [0.97454232 1.08580961]\n",
      " [1.55905554 1.51192033]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55764947 0.71359776]\n",
      " [0.69341661 0.79233086]\n",
      " [0.72602395 0.74759182]\n",
      " [0.82621779 0.81934562]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0040409 ]\n",
      " [ 0.00539521]\n",
      " [ 0.01007895]\n",
      " [ 0.01652418]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49898978]\n",
      " [0.5013488 ]\n",
      " [0.50251972]\n",
      " [0.50413095]]\n",
      "Error [[-0.49898978]\n",
      " [ 0.4986512 ]\n",
      " [ 0.49748028]\n",
      " [-0.50413095]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23164967 0.91292282]\n",
      " [0.81623985 1.33902649]\n",
      " [0.97462484 1.08579196]\n",
      " [1.55921502 1.51189563]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55765483 0.71359789]\n",
      " [0.69343758 0.7923298 ]\n",
      " [0.72604037 0.74758849]\n",
      " [0.82624068 0.81934197]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00408232]\n",
      " [ 0.00539249]\n",
      " [ 0.0100882 ]\n",
      " [ 0.01656079]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49897942]\n",
      " [0.50134812]\n",
      " [0.50252203]\n",
      " [0.5041401 ]]\n",
      "Error [[-0.49897942]\n",
      " [ 0.49865188]\n",
      " [ 0.49747797]\n",
      " [-0.5041401 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23167147 0.91292347]\n",
      " [0.81633885 1.33902006]\n",
      " [0.97470765 1.0857743 ]\n",
      " [1.55937504 1.5118709 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5576602  0.71359802]\n",
      " [0.69345863 0.79232874]\n",
      " [0.72605684 0.74758516]\n",
      " [0.82626366 0.81933831]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00412375]\n",
      " [ 0.00538978]\n",
      " [ 0.01009745]\n",
      " [ 0.01659741]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49896906]\n",
      " [0.50134744]\n",
      " [0.50252434]\n",
      " [0.50414926]]\n",
      "Error [[-0.49896906]\n",
      " [ 0.49865256]\n",
      " [ 0.49747566]\n",
      " [-0.50414926]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23169334 0.91292411]\n",
      " [0.81643819 1.33901363]\n",
      " [0.97479075 1.08575661]\n",
      " [1.5595356  1.51184614]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5576656  0.71359815]\n",
      " [0.69347974 0.79232769]\n",
      " [0.72607336 0.74758182]\n",
      " [0.8262867  0.81933464]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00416518]\n",
      " [ 0.00538708]\n",
      " [ 0.01010671]\n",
      " [ 0.01663404]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49895871]\n",
      " [0.50134677]\n",
      " [0.50252666]\n",
      " [0.50415841]]\n",
      "Error [[-0.49895871]\n",
      " [ 0.49865323]\n",
      " [ 0.49747334]\n",
      " [-0.50415841]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23171528 0.91292475]\n",
      " [0.81653787 1.33900719]\n",
      " [0.97487412 1.0857389 ]\n",
      " [1.55969671 1.51182134]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55767101 0.71359828]\n",
      " [0.69350093 0.79232663]\n",
      " [0.72608995 0.74757848]\n",
      " [0.82630983 0.81933097]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00420663]\n",
      " [ 0.00538439]\n",
      " [ 0.01011598]\n",
      " [ 0.01667069]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49894834]\n",
      " [0.50134609]\n",
      " [0.50252897]\n",
      " [0.50416758]]\n",
      "Error [[-0.49894834]\n",
      " [ 0.49865391]\n",
      " [ 0.49747103]\n",
      " [-0.50416758]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2317373  0.9129254 ]\n",
      " [0.81663789 1.33900075]\n",
      " [0.97495777 1.08572117]\n",
      " [1.55985836 1.51179652]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55767644 0.71359842]\n",
      " [0.69352219 0.79232557]\n",
      " [0.72610658 0.74757513]\n",
      " [0.82633303 0.8193273 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00424808]\n",
      " [ 0.00538171]\n",
      " [ 0.01012526]\n",
      " [ 0.01670736]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49893798]\n",
      " [0.50134542]\n",
      " [0.50253129]\n",
      " [0.50417674]]\n",
      "Error [[-0.49893798]\n",
      " [ 0.49865458]\n",
      " [ 0.49746871]\n",
      " [-0.50417674]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2317594  0.91292604]\n",
      " [0.81673824 1.3389943 ]\n",
      " [0.97504171 1.08570341]\n",
      " [1.56002055 1.51177167]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55768189 0.71359855]\n",
      " [0.69354352 0.79232451]\n",
      " [0.72612328 0.74757178]\n",
      " [0.8263563  0.81932362]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00428954]\n",
      " [ 0.00537903]\n",
      " [ 0.01013455]\n",
      " [ 0.01674404]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49892762]\n",
      " [0.50134476]\n",
      " [0.50253362]\n",
      " [0.50418591]]\n",
      "Error [[-0.49892762]\n",
      " [ 0.49865524]\n",
      " [ 0.49746638]\n",
      " [-0.50418591]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23178157 0.91292669]\n",
      " [0.81683893 1.33898784]\n",
      " [0.97512593 1.08568563]\n",
      " [1.56018329 1.51174678]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55768736 0.71359868]\n",
      " [0.69356492 0.79232344]\n",
      " [0.72614003 0.74756843]\n",
      " [0.82637965 0.81931994]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00433101]\n",
      " [ 0.00537637]\n",
      " [ 0.01014385]\n",
      " [ 0.01678074]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49891725]\n",
      " [0.50134409]\n",
      " [0.50253594]\n",
      " [0.50419509]]\n",
      "Error [[-0.49891725]\n",
      " [ 0.49865591]\n",
      " [ 0.49746406]\n",
      " [-0.50419509]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23180381 0.91292733]\n",
      " [0.81693996 1.33898137]\n",
      " [0.97521044 1.08566783]\n",
      " [1.56034658 1.51172187]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55769285 0.71359881]\n",
      " [0.69358639 0.79232238]\n",
      " [0.72615683 0.74756507]\n",
      " [0.82640308 0.81931625]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00437249]\n",
      " [ 0.00537372]\n",
      " [ 0.01015315]\n",
      " [ 0.01681745]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49890688]\n",
      " [0.50134343]\n",
      " [0.50253827]\n",
      " [0.50420426]]\n",
      "Error [[-0.49890688]\n",
      " [ 0.49865657]\n",
      " [ 0.49746173]\n",
      " [-0.50420426]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23182613 0.91292798]\n",
      " [0.81704132 1.3389749 ]\n",
      " [0.97529522 1.08565001]\n",
      " [1.56051041 1.51169692]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55769836 0.71359894]\n",
      " [0.69360793 0.79232131]\n",
      " [0.72617369 0.7475617 ]\n",
      " [0.82642658 0.81931255]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00441397]\n",
      " [ 0.00537107]\n",
      " [ 0.01016246]\n",
      " [ 0.01685417]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49889651]\n",
      " [0.50134276]\n",
      " [0.50254059]\n",
      " [0.50421344]]\n",
      "Error [[-0.49889651]\n",
      " [ 0.49865724]\n",
      " [ 0.49745941]\n",
      " [-0.50421344]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23184853 0.91292863]\n",
      " [0.81714302 1.33896841]\n",
      " [0.97538029 1.08563216]\n",
      " [1.56067478 1.51167195]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55770388 0.71359908]\n",
      " [0.69362955 0.79232025]\n",
      " [0.7261906  0.74755834]\n",
      " [0.82645016 0.81930886]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00445546]\n",
      " [ 0.00536844]\n",
      " [ 0.01017178]\n",
      " [ 0.01689092]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49888614]\n",
      " [0.50134211]\n",
      " [0.50254292]\n",
      " [0.50422263]]\n",
      "Error [[-0.49888614]\n",
      " [ 0.49865789]\n",
      " [ 0.49745708]\n",
      " [-0.50422263]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.231871   0.91292927]\n",
      " [0.81724506 1.33896192]\n",
      " [0.97546564 1.08561429]\n",
      " [1.5608397  1.51164694]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55770942 0.71359921]\n",
      " [0.69365123 0.79231918]\n",
      " [0.72620757 0.74755496]\n",
      " [0.82647381 0.81930515]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00449696]\n",
      " [ 0.00536581]\n",
      " [ 0.01018111]\n",
      " [ 0.01692768]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49887576]\n",
      " [0.50134145]\n",
      " [0.50254526]\n",
      " [0.50423182]]\n",
      "Error [[-0.49887576]\n",
      " [ 0.49865855]\n",
      " [ 0.49745474]\n",
      " [-0.50423182]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23189354 0.91292992]\n",
      " [0.81734743 1.33895543]\n",
      " [0.97555128 1.08559639]\n",
      " [1.56100517 1.5116219 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55771498 0.71359934]\n",
      " [0.69367298 0.79231811]\n",
      " [0.7262246  0.74755159]\n",
      " [0.82649754 0.81930145]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00453847]\n",
      " [ 0.00536319]\n",
      " [ 0.01019045]\n",
      " [ 0.01696445]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49886538]\n",
      " [0.5013408 ]\n",
      " [0.50254759]\n",
      " [0.50424101]]\n",
      "Error [[-0.49886538]\n",
      " [ 0.4986592 ]\n",
      " [ 0.49745241]\n",
      " [-0.50424101]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23191616 0.91293057]\n",
      " [0.81745015 1.33894892]\n",
      " [0.9756372  1.08557848]\n",
      " [1.56117118 1.51159683]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55772056 0.71359947]\n",
      " [0.69369481 0.79231704]\n",
      " [0.72624168 0.74754821]\n",
      " [0.82652135 0.81929774]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00457999]\n",
      " [ 0.00536059]\n",
      " [ 0.0101998 ]\n",
      " [ 0.01700124]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49885501]\n",
      " [0.50134014]\n",
      " [0.50254993]\n",
      " [0.50425021]]\n",
      "Error [[-0.49885501]\n",
      " [ 0.49865986]\n",
      " [ 0.49745007]\n",
      " [-0.50425021]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23193886 0.91293122]\n",
      " [0.8175532  1.33894241]\n",
      " [0.9757234  1.08556054]\n",
      " [1.56133774 1.51157173]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55772616 0.71359961]\n",
      " [0.69371671 0.79231597]\n",
      " [0.72625882 0.74754482]\n",
      " [0.82654523 0.81929402]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00462151]\n",
      " [ 0.00535799]\n",
      " [ 0.01020915]\n",
      " [ 0.01703805]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49884462]\n",
      " [0.50133949]\n",
      " [0.50255227]\n",
      " [0.50425941]]\n",
      "Error [[-0.49884462]\n",
      " [ 0.49866051]\n",
      " [ 0.49744773]\n",
      " [-0.50425941]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23196162 0.91293187]\n",
      " [0.81765659 1.33893589]\n",
      " [0.97580988 1.08554257]\n",
      " [1.56150484 1.5115466 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55773178 0.71359974]\n",
      " [0.69373867 0.7923149 ]\n",
      " [0.72627601 0.74754143]\n",
      " [0.82656918 0.8192903 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00466304]\n",
      " [ 0.0053554 ]\n",
      " [ 0.01021852]\n",
      " [ 0.01707487]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49883424]\n",
      " [0.50133885]\n",
      " [0.50255461]\n",
      " [0.50426861]]\n",
      "Error [[-0.49883424]\n",
      " [ 0.49866115]\n",
      " [ 0.49744539]\n",
      " [-0.50426861]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23198447 0.91293252]\n",
      " [0.81776031 1.33892937]\n",
      " [0.97589665 1.08552459]\n",
      " [1.56167249 1.51152144]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55773741 0.71359987]\n",
      " [0.69376071 0.79231382]\n",
      " [0.72629326 0.74753804]\n",
      " [0.82659321 0.81928657]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00470459]\n",
      " [ 0.00535282]\n",
      " [ 0.01022789]\n",
      " [ 0.01711171]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49882386]\n",
      " [0.5013382 ]\n",
      " [0.50255695]\n",
      " [0.50427782]]\n",
      "Error [[-0.49882386]\n",
      " [ 0.4986618 ]\n",
      " [ 0.49744305]\n",
      " [-0.50427782]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23200739 0.91293317]\n",
      " [0.81786438 1.33892284]\n",
      " [0.9759837  1.08550658]\n",
      " [1.56184069 1.51149625]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55774307 0.7136    ]\n",
      " [0.69378282 0.79231275]\n",
      " [0.72631057 0.74753464]\n",
      " [0.82661732 0.81928284]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00474614]\n",
      " [ 0.00535025]\n",
      " [ 0.01023727]\n",
      " [ 0.01714857]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49881347]\n",
      " [0.50133756]\n",
      " [0.5025593 ]\n",
      " [0.50428704]]\n",
      "Error [[-0.49881347]\n",
      " [ 0.49866244]\n",
      " [ 0.4974407 ]\n",
      " [-0.50428704]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23203038 0.91293382]\n",
      " [0.81796878 1.3389163 ]\n",
      " [0.97607104 1.08548854]\n",
      " [1.56200944 1.51147102]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55774874 0.71360014]\n",
      " [0.693805   0.79231167]\n",
      " [0.72632793 0.74753123]\n",
      " [0.8266415  0.81927911]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00478769]\n",
      " [ 0.00534769]\n",
      " [ 0.01024666]\n",
      " [ 0.01718544]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49880308]\n",
      " [0.50133692]\n",
      " [0.50256164]\n",
      " [0.50429625]]\n",
      "Error [[-0.49880308]\n",
      " [ 0.49866308]\n",
      " [ 0.49743836]\n",
      " [-0.50429625]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23205345 0.91293447]\n",
      " [0.81807352 1.33890975]\n",
      " [0.97615866 1.08547049]\n",
      " [1.56217873 1.51144577]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55775443 0.71360027]\n",
      " [0.69382725 0.79231059]\n",
      " [0.72634535 0.74752783]\n",
      " [0.82666576 0.81927537]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00482926]\n",
      " [ 0.00534514]\n",
      " [ 0.01025606]\n",
      " [ 0.01722233]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49879269]\n",
      " [0.50133628]\n",
      " [0.50256399]\n",
      " [0.50430548]]\n",
      "Error [[-0.49879269]\n",
      " [ 0.49866372]\n",
      " [ 0.49743601]\n",
      " [-0.50430548]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2320766  0.91293512]\n",
      " [0.8181786  1.33890319]\n",
      " [0.97624656 1.08545241]\n",
      " [1.56234857 1.51142048]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55776014 0.7136004 ]\n",
      " [0.69384957 0.79230951]\n",
      " [0.72636282 0.74752441]\n",
      " [0.8266901  0.81927163]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00487084]\n",
      " [ 0.0053426 ]\n",
      " [ 0.01026547]\n",
      " [ 0.01725923]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49878229]\n",
      " [0.50133565]\n",
      " [0.50256634]\n",
      " [0.5043147 ]]\n",
      "Error [[-0.49878229]\n",
      " [ 0.49866435]\n",
      " [ 0.49743366]\n",
      " [-0.5043147 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23209982 0.91293577]\n",
      " [0.81828402 1.33889663]\n",
      " [0.97633475 1.08543431]\n",
      " [1.56251895 1.51139517]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55776587 0.71360054]\n",
      " [0.69387196 0.79230843]\n",
      " [0.72638035 0.747521  ]\n",
      " [0.82671451 0.81926788]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00491242]\n",
      " [ 0.00534006]\n",
      " [ 0.01027488]\n",
      " [ 0.01729615]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4987719 ]\n",
      " [0.50133501]\n",
      " [0.5025687 ]\n",
      " [0.50432393]]\n",
      "Error [[-0.4987719 ]\n",
      " [ 0.49866499]\n",
      " [ 0.4974313 ]\n",
      " [-0.50432393]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23212312 0.91293642]\n",
      " [0.81838978 1.33889006]\n",
      " [0.97642322 1.08541618]\n",
      " [1.56268989 1.51136982]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55777161 0.71360067]\n",
      " [0.69389443 0.79230735]\n",
      " [0.72639793 0.74751758]\n",
      " [0.826739   0.81926413]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00495401]\n",
      " [ 0.00533754]\n",
      " [ 0.01028431]\n",
      " [ 0.01733308]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4987615 ]\n",
      " [0.50133438]\n",
      " [0.50257105]\n",
      " [0.50433316]]\n",
      "Error [[-0.4987615 ]\n",
      " [ 0.49866562]\n",
      " [ 0.49742895]\n",
      " [-0.50433316]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23214649 0.91293708]\n",
      " [0.81849587 1.33888348]\n",
      " [0.97651198 1.08539804]\n",
      " [1.56286137 1.51134444]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55777738 0.7136008 ]\n",
      " [0.69391696 0.79230627]\n",
      " [0.72641557 0.74751415]\n",
      " [0.82676356 0.81926037]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00499562]\n",
      " [ 0.00533503]\n",
      " [ 0.01029374]\n",
      " [ 0.01737004]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4987511 ]\n",
      " [0.50133375]\n",
      " [0.50257341]\n",
      " [0.5043424 ]]\n",
      "Error [[-0.4987511 ]\n",
      " [ 0.49866625]\n",
      " [ 0.49742659]\n",
      " [-0.5043424 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23216993 0.91293773]\n",
      " [0.81860231 1.3388769 ]\n",
      " [0.97660102 1.08537986]\n",
      " [1.5630334  1.51131903]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55778316 0.71360094]\n",
      " [0.69393957 0.79230519]\n",
      " [0.72643326 0.74751072]\n",
      " [0.82678819 0.81925661]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00503723]\n",
      " [ 0.00533252]\n",
      " [ 0.01030318]\n",
      " [ 0.01740701]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4987407 ]\n",
      " [0.50133313]\n",
      " [0.50257577]\n",
      " [0.50435164]]\n",
      "Error [[-0.4987407 ]\n",
      " [ 0.49866687]\n",
      " [ 0.49742423]\n",
      " [-0.50435164]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23219345 0.91293838]\n",
      " [0.81870908 1.33887031]\n",
      " [0.97669035 1.08536167]\n",
      " [1.56320598 1.51129359]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55778896 0.71360107]\n",
      " [0.69396225 0.7923041 ]\n",
      " [0.72645102 0.74750729]\n",
      " [0.82681291 0.81925284]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00507885]\n",
      " [ 0.00533003]\n",
      " [ 0.01031263]\n",
      " [ 0.01744399]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49873029]\n",
      " [0.5013325 ]\n",
      " [0.50257814]\n",
      " [0.50436089]]\n",
      "Error [[-0.49873029]\n",
      " [ 0.4986675 ]\n",
      " [ 0.49742186]\n",
      " [-0.50436089]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23221705 0.91293904]\n",
      " [0.8188162  1.33886371]\n",
      " [0.97677996 1.08534345]\n",
      " [1.5633791  1.51126812]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55779478 0.7136012 ]\n",
      " [0.69398499 0.79230302]\n",
      " [0.72646882 0.74750385]\n",
      " [0.8268377  0.81924907]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00512048]\n",
      " [ 0.00532754]\n",
      " [ 0.01032209]\n",
      " [ 0.01748099]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49871988]\n",
      " [0.50133188]\n",
      " [0.5025805 ]\n",
      " [0.50437014]]\n",
      "Error [[-0.49871988]\n",
      " [ 0.49866812]\n",
      " [ 0.4974195 ]\n",
      " [-0.50437014]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23224072 0.91293969]\n",
      " [0.81892365 1.3388571 ]\n",
      " [0.97686985 1.08532521]\n",
      " [1.56355278 1.51124262]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55780062 0.71360134]\n",
      " [0.69400781 0.79230193]\n",
      " [0.72648669 0.74750041]\n",
      " [0.82686256 0.81924529]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00516212]\n",
      " [ 0.00532507]\n",
      " [ 0.01033156]\n",
      " [ 0.01751801]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49870947]\n",
      " [0.50133126]\n",
      " [0.50258287]\n",
      " [0.50437939]]\n",
      "Error [[-0.49870947]\n",
      " [ 0.49866874]\n",
      " [ 0.49741713]\n",
      " [-0.50437939]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23226447 0.91294035]\n",
      " [0.81903144 1.33885049]\n",
      " [0.97696003 1.08530695]\n",
      " [1.563727   1.51121709]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55780648 0.71360147]\n",
      " [0.6940307  0.79230084]\n",
      " [0.7265046  0.74749696]\n",
      " [0.8268875  0.81924151]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00520376]\n",
      " [ 0.0053226 ]\n",
      " [ 0.01034103]\n",
      " [ 0.01755505]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49869906]\n",
      " [0.50133065]\n",
      " [0.50258524]\n",
      " [0.50438865]]\n",
      "Error [[-0.49869906]\n",
      " [ 0.49866935]\n",
      " [ 0.49741476]\n",
      " [-0.50438865]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23228829 0.912941  ]\n",
      " [0.81913957 1.33884387]\n",
      " [0.9770505  1.08528866]\n",
      " [1.56390178 1.51119153]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55781235 0.71360161]\n",
      " [0.69405366 0.79229975]\n",
      " [0.72652258 0.74749351]\n",
      " [0.82691252 0.81923772]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00524542]\n",
      " [ 0.00532015]\n",
      " [ 0.01035052]\n",
      " [ 0.0175921 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49868865]\n",
      " [0.50133003]\n",
      " [0.50258761]\n",
      " [0.50439791]]\n",
      "Error [[-0.49868865]\n",
      " [ 0.49866997]\n",
      " [ 0.49741239]\n",
      " [-0.50439791]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23231219 0.91294166]\n",
      " [0.81924805 1.33883724]\n",
      " [0.97714125 1.08527035]\n",
      " [1.5640771  1.51116593]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55781825 0.71360174]\n",
      " [0.6940767  0.79229866]\n",
      " [0.72654061 0.74749005]\n",
      " [0.82693761 0.81923393]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00528709]\n",
      " [ 0.0053177 ]\n",
      " [ 0.01036001]\n",
      " [ 0.01762917]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49867823]\n",
      " [0.50132942]\n",
      " [0.50258998]\n",
      " [0.50440718]]\n",
      "Error [[-0.49867823]\n",
      " [ 0.49867058]\n",
      " [ 0.49741002]\n",
      " [-0.50440718]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23233616 0.91294232]\n",
      " [0.81935686 1.3388306 ]\n",
      " [0.97723228 1.08525202]\n",
      " [1.56425298 1.5111403 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55782416 0.71360187]\n",
      " [0.6940998  0.79229757]\n",
      " [0.7265587  0.74748659]\n",
      " [0.82696278 0.81923014]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00532876]\n",
      " [ 0.00531526]\n",
      " [ 0.01036952]\n",
      " [ 0.01766625]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49866781]\n",
      " [0.50132881]\n",
      " [0.50259236]\n",
      " [0.50441645]]\n",
      "Error [[-0.49866781]\n",
      " [ 0.49867119]\n",
      " [ 0.49740764]\n",
      " [-0.50441645]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23236021 0.91294297]\n",
      " [0.81946601 1.33882396]\n",
      " [0.97732361 1.08523366]\n",
      " [1.5644294  1.51111465]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55783009 0.71360201]\n",
      " [0.69412298 0.79229648]\n",
      " [0.72657684 0.74748313]\n",
      " [0.82698802 0.81922634]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00537045]\n",
      " [ 0.00531284]\n",
      " [ 0.01037903]\n",
      " [ 0.01770335]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49865739]\n",
      " [0.50132821]\n",
      " [0.50259473]\n",
      " [0.50442572]]\n",
      "Error [[-0.49865739]\n",
      " [ 0.49867179]\n",
      " [ 0.49740527]\n",
      " [-0.50442572]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23238434 0.91294363]\n",
      " [0.8195755  1.33881731]\n",
      " [0.97741521 1.08521528]\n",
      " [1.56460638 1.51108896]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55783604 0.71360214]\n",
      " [0.69414622 0.79229538]\n",
      " [0.72659504 0.74747966]\n",
      " [0.82701334 0.81922253]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00541214]\n",
      " [ 0.00531042]\n",
      " [ 0.01038855]\n",
      " [ 0.01774047]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49864697]\n",
      " [0.5013276 ]\n",
      " [0.50259711]\n",
      " [0.504435  ]]\n",
      "Error [[-0.49864697]\n",
      " [ 0.4986724 ]\n",
      " [ 0.49740289]\n",
      " [-0.504435  ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23240854 0.91294429]\n",
      " [0.81968533 1.33881065]\n",
      " [0.97750711 1.08519688]\n",
      " [1.5647839  1.51106324]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55784201 0.71360228]\n",
      " [0.69416954 0.79229429]\n",
      " [0.72661329 0.74747618]\n",
      " [0.82703874 0.81921873]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00545384]\n",
      " [ 0.00530801]\n",
      " [ 0.01039808]\n",
      " [ 0.01777761]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49863654]\n",
      " [0.501327  ]\n",
      " [0.5025995 ]\n",
      " [0.50444428]]\n",
      "Error [[-0.49863654]\n",
      " [ 0.498673  ]\n",
      " [ 0.4974005 ]\n",
      " [-0.50444428]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23243281 0.91294495]\n",
      " [0.81979551 1.33880399]\n",
      " [0.97759928 1.08517845]\n",
      " [1.56496198 1.51103749]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.557848   0.71360241]\n",
      " [0.69419293 0.79229319]\n",
      " [0.7266316  0.74747271]\n",
      " [0.82706421 0.81921491]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00549556]\n",
      " [ 0.00530561]\n",
      " [ 0.01040762]\n",
      " [ 0.01781476]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49862611]\n",
      " [0.5013264 ]\n",
      " [0.50260188]\n",
      " [0.50445357]]\n",
      "Error [[-0.49862611]\n",
      " [ 0.4986736 ]\n",
      " [ 0.49739812]\n",
      " [-0.50445357]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23245717 0.91294561]\n",
      " [0.81990602 1.33879731]\n",
      " [0.97769175 1.08516   ]\n",
      " [1.5651406  1.51101171]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55785401 0.71360255]\n",
      " [0.69421639 0.79229209]\n",
      " [0.72664997 0.74746922]\n",
      " [0.82708976 0.81921109]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00553728]\n",
      " [ 0.00530322]\n",
      " [ 0.01041716]\n",
      " [ 0.01785193]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49861568]\n",
      " [0.5013258 ]\n",
      " [0.50260427]\n",
      " [0.50446286]]\n",
      "Error [[-0.49861568]\n",
      " [ 0.4986742 ]\n",
      " [ 0.49739573]\n",
      " [-0.50446286]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23248159 0.91294627]\n",
      " [0.82001687 1.33879063]\n",
      " [0.9777845  1.08514153]\n",
      " [1.56531978 1.5109859 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55786003 0.71360268]\n",
      " [0.69423992 0.79229099]\n",
      " [0.72666839 0.74746574]\n",
      " [0.82711538 0.81920727]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00557901]\n",
      " [ 0.00530084]\n",
      " [ 0.01042672]\n",
      " [ 0.01788911]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49860525]\n",
      " [0.50132521]\n",
      " [0.50260666]\n",
      " [0.50447216]]\n",
      "Error [[-0.49860525]\n",
      " [ 0.49867479]\n",
      " [ 0.49739334]\n",
      " [-0.50447216]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23250609 0.91294693]\n",
      " [0.82012807 1.33878395]\n",
      " [0.97787754 1.08512303]\n",
      " [1.56549951 1.51096005]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55786608 0.71360282]\n",
      " [0.69426352 0.79228989]\n",
      " [0.72668687 0.74746224]\n",
      " [0.82714108 0.81920344]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00562076]\n",
      " [ 0.00529847]\n",
      " [ 0.01043628]\n",
      " [ 0.01792632]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49859481]\n",
      " [0.50132461]\n",
      " [0.50260905]\n",
      " [0.50448146]]\n",
      "Error [[-0.49859481]\n",
      " [ 0.49867539]\n",
      " [ 0.49739095]\n",
      " [-0.50448146]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23253067 0.91294759]\n",
      " [0.8202396  1.33877725]\n",
      " [0.97797086 1.08510451]\n",
      " [1.56567979 1.51093418]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55787214 0.71360295]\n",
      " [0.6942872  0.79228879]\n",
      " [0.72670541 0.74745875]\n",
      " [0.82716686 0.81919961]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00566251]\n",
      " [ 0.00529611]\n",
      " [ 0.01044586]\n",
      " [ 0.01796354]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49858438]\n",
      " [0.50132402]\n",
      " [0.50261144]\n",
      " [0.50449076]]\n",
      "Error [[-0.49858438]\n",
      " [ 0.49867598]\n",
      " [ 0.49738856]\n",
      " [-0.50449076]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23255533 0.91294825]\n",
      " [0.82035148 1.33877055]\n",
      " [0.97806447 1.08508597]\n",
      " [1.56586062 1.51090827]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55787822 0.71360309]\n",
      " [0.69431094 0.79228769]\n",
      " [0.726724   0.74745525]\n",
      " [0.82719271 0.81919577]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00570427]\n",
      " [ 0.00529376]\n",
      " [ 0.01045544]\n",
      " [ 0.01800078]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49857394]\n",
      " [0.50132344]\n",
      " [0.50261384]\n",
      " [0.50450007]]\n",
      "Error [[-0.49857394]\n",
      " [ 0.49867656]\n",
      " [ 0.49738616]\n",
      " [-0.50450007]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23258006 0.91294891]\n",
      " [0.8204637  1.33876384]\n",
      " [0.97815837 1.0850674 ]\n",
      " [1.56604201 1.51088233]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55788432 0.71360322]\n",
      " [0.69433476 0.79228658]\n",
      " [0.72674264 0.74745174]\n",
      " [0.82721863 0.81919193]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00574605]\n",
      " [ 0.00529142]\n",
      " [ 0.01046503]\n",
      " [ 0.01803803]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49856349]\n",
      " [0.50132285]\n",
      " [0.50261623]\n",
      " [0.50450939]]\n",
      "Error [[-0.49856349]\n",
      " [ 0.49867715]\n",
      " [ 0.49738377]\n",
      " [-0.50450939]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23260486 0.91294957]\n",
      " [0.82057626 1.33875712]\n",
      " [0.97825255 1.08504881]\n",
      " [1.56622394 1.51085637]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55789044 0.71360336]\n",
      " [0.69435865 0.79228548]\n",
      " [0.72676135 0.74744823]\n",
      " [0.82724463 0.81918809]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00578783]\n",
      " [ 0.00528909]\n",
      " [ 0.01047463]\n",
      " [ 0.0180753 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49855305]\n",
      " [0.50132227]\n",
      " [0.50261863]\n",
      " [0.5045187 ]]\n",
      "Error [[-0.49855305]\n",
      " [ 0.49867773]\n",
      " [ 0.49738137]\n",
      " [-0.5045187 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23262974 0.91295023]\n",
      " [0.82068916 1.3387504 ]\n",
      " [0.97834702 1.0850302 ]\n",
      " [1.56640643 1.51083037]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55789657 0.71360349]\n",
      " [0.69438261 0.79228437]\n",
      " [0.72678011 0.74744472]\n",
      " [0.82727071 0.81918423]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00582962]\n",
      " [ 0.00528677]\n",
      " [ 0.01048424]\n",
      " [ 0.01811259]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4985426 ]\n",
      " [0.50132169]\n",
      " [0.50262104]\n",
      " [0.50452802]]\n",
      "Error [[-0.4985426 ]\n",
      " [ 0.49867831]\n",
      " [ 0.49737896]\n",
      " [-0.50452802]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2326547  0.9129509 ]\n",
      " [0.8208024  1.33874367]\n",
      " [0.97844177 1.08501156]\n",
      " [1.56658947 1.51080434]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55790273 0.71360363]\n",
      " [0.69440664 0.79228326]\n",
      " [0.72679892 0.7474412 ]\n",
      " [0.82729687 0.81918038]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00587142]\n",
      " [ 0.00528446]\n",
      " [ 0.01049386]\n",
      " [ 0.0181499 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49853215]\n",
      " [0.50132111]\n",
      " [0.50262344]\n",
      " [0.50453735]]\n",
      "Error [[-0.49853215]\n",
      " [ 0.49867889]\n",
      " [ 0.49737656]\n",
      " [-0.50453735]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23267973 0.91295156]\n",
      " [0.82091598 1.33873693]\n",
      " [0.97853682 1.0849929 ]\n",
      " [1.56677307 1.51077827]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5579089  0.71360376]\n",
      " [0.69443074 0.79228215]\n",
      " [0.72681779 0.74743768]\n",
      " [0.8273231  0.81917652]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00591324]\n",
      " [ 0.00528215]\n",
      " [ 0.01050348]\n",
      " [ 0.01818723]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49852169]\n",
      " [0.50132054]\n",
      " [0.50262585]\n",
      " [0.50454668]]\n",
      "Error [[-0.49852169]\n",
      " [ 0.49867946]\n",
      " [ 0.49737415]\n",
      " [-0.50454668]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23270484 0.91295222]\n",
      " [0.82102991 1.33873019]\n",
      " [0.97863215 1.08497422]\n",
      " [1.56695722 1.51075218]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5579151  0.7136039 ]\n",
      " [0.69445492 0.79228104]\n",
      " [0.72683672 0.74743415]\n",
      " [0.8273494  0.81917265]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00595506]\n",
      " [ 0.00527986]\n",
      " [ 0.01051312]\n",
      " [ 0.01822457]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49851124]\n",
      " [0.50131996]\n",
      " [0.50262826]\n",
      " [0.50455602]]\n",
      "Error [[-0.49851124]\n",
      " [ 0.49868004]\n",
      " [ 0.49737174]\n",
      " [-0.50455602]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23273002 0.91295289]\n",
      " [0.82114418 1.33872343]\n",
      " [0.97872777 1.08495551]\n",
      " [1.56714192 1.51072606]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55792131 0.71360403]\n",
      " [0.69447916 0.79227993]\n",
      " [0.7268557  0.74743062]\n",
      " [0.82737578 0.81916878]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0059969 ]\n",
      " [ 0.00527758]\n",
      " [ 0.01052276]\n",
      " [ 0.01826193]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49850078]\n",
      " [0.50131939]\n",
      " [0.50263067]\n",
      " [0.50456536]]\n",
      "Error [[-0.49850078]\n",
      " [ 0.49868061]\n",
      " [ 0.49736933]\n",
      " [-0.50456536]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23275528 0.91295355]\n",
      " [0.82125879 1.33871667]\n",
      " [0.97882367 1.08493678]\n",
      " [1.56732718 1.5106999 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55792754 0.71360417]\n",
      " [0.69450348 0.79227882]\n",
      " [0.72687475 0.74742709]\n",
      " [0.82740224 0.81916491]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00603874]\n",
      " [ 0.00527531]\n",
      " [ 0.01053242]\n",
      " [ 0.01829931]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49849032]\n",
      " [0.50131882]\n",
      " [0.50263308]\n",
      " [0.5045747 ]]\n",
      "Error [[-0.49849032]\n",
      " [ 0.49868118]\n",
      " [ 0.49736692]\n",
      " [-0.5045747 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23278062 0.91295422]\n",
      " [0.82137374 1.33870991]\n",
      " [0.97891987 1.08491803]\n",
      " [1.56751299 1.51067371]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55793379 0.71360431]\n",
      " [0.69452787 0.79227771]\n",
      " [0.72689384 0.74742355]\n",
      " [0.82742878 0.81916103]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0060806 ]\n",
      " [ 0.00527305]\n",
      " [ 0.01054208]\n",
      " [ 0.0183367 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49847986]\n",
      " [0.50131826]\n",
      " [0.5026355 ]\n",
      " [0.50458405]]\n",
      "Error [[-0.49847986]\n",
      " [ 0.49868174]\n",
      " [ 0.4973645 ]\n",
      " [-0.50458405]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23280603 0.91295489]\n",
      " [0.82148903 1.33870313]\n",
      " [0.97901635 1.08489925]\n",
      " [1.56769935 1.51064749]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55794005 0.71360444]\n",
      " [0.69455233 0.79227659]\n",
      " [0.72691299 0.74742   ]\n",
      " [0.82745539 0.81915715]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00612246]\n",
      " [ 0.00527079]\n",
      " [ 0.01055175]\n",
      " [ 0.01837411]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49846939]\n",
      " [0.5013177 ]\n",
      " [0.50263791]\n",
      " [0.5045934 ]]\n",
      "Error [[-0.49846939]\n",
      " [ 0.4986823 ]\n",
      " [ 0.49736209]\n",
      " [-0.5045934 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23283152 0.91295555]\n",
      " [0.82160467 1.33869635]\n",
      " [0.97911312 1.08488045]\n",
      " [1.56788627 1.51062124]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55794634 0.71360458]\n",
      " [0.69457686 0.79227547]\n",
      " [0.7269322  0.74741645]\n",
      " [0.82748207 0.81915326]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00616434]\n",
      " [ 0.00526855]\n",
      " [ 0.01056143]\n",
      " [ 0.01841154]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49845892]\n",
      " [0.50131713]\n",
      " [0.50264033]\n",
      " [0.50460276]]\n",
      "Error [[-0.49845892]\n",
      " [ 0.49868287]\n",
      " [ 0.49735967]\n",
      " [-0.50460276]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23285708 0.91295622]\n",
      " [0.82172065 1.33868956]\n",
      " [0.97921018 1.08486162]\n",
      " [1.56807375 1.51059496]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55795265 0.71360472]\n",
      " [0.69460146 0.79227436]\n",
      " [0.72695147 0.7474129 ]\n",
      " [0.82750883 0.81914936]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00620623]\n",
      " [ 0.00526632]\n",
      " [ 0.01057112]\n",
      " [ 0.01844899]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49844845]\n",
      " [0.50131658]\n",
      " [0.50264276]\n",
      " [0.50461212]]\n",
      "Error [[-0.49844845]\n",
      " [ 0.49868342]\n",
      " [ 0.49735724]\n",
      " [-0.50461212]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23288272 0.91295689]\n",
      " [0.82183697 1.33868276]\n",
      " [0.97930752 1.08484277]\n",
      " [1.56826177 1.51056865]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55795897 0.71360485]\n",
      " [0.69462614 0.79227324]\n",
      " [0.72697079 0.74740934]\n",
      " [0.82753567 0.81914547]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00624813]\n",
      " [ 0.00526409]\n",
      " [ 0.01058082]\n",
      " [ 0.01848646]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49843797]\n",
      " [0.50131602]\n",
      " [0.50264518]\n",
      " [0.50462148]]\n",
      "Error [[-0.49843797]\n",
      " [ 0.49868398]\n",
      " [ 0.49735482]\n",
      " [-0.50462148]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23290844 0.91295755]\n",
      " [0.82195364 1.33867596]\n",
      " [0.97940515 1.0848239 ]\n",
      " [1.56845036 1.51054231]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55796531 0.71360499]\n",
      " [0.69465089 0.79227212]\n",
      " [0.72699017 0.74740578]\n",
      " [0.82756258 0.81914156]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00629004]\n",
      " [ 0.00526188]\n",
      " [ 0.01059053]\n",
      " [ 0.01852394]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4984275 ]\n",
      " [0.50131547]\n",
      " [0.50264761]\n",
      " [0.50463085]]\n",
      "Error [[-0.4984275 ]\n",
      " [ 0.49868453]\n",
      " [ 0.49735239]\n",
      " [-0.50463085]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23293423 0.91295822]\n",
      " [0.82207065 1.33866915]\n",
      " [0.97950308 1.08480501]\n",
      " [1.5686395  1.51051593]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55797167 0.71360512]\n",
      " [0.6946757  0.792271  ]\n",
      " [0.7270096  0.74740221]\n",
      " [0.82758957 0.81913766]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00633196]\n",
      " [ 0.00525968]\n",
      " [ 0.01060025]\n",
      " [ 0.01856144]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49841702]\n",
      " [0.50131492]\n",
      " [0.50265004]\n",
      " [0.50464023]]\n",
      "Error [[-0.49841702]\n",
      " [ 0.49868508]\n",
      " [ 0.49734996]\n",
      " [-0.50464023]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23296009 0.91295889]\n",
      " [0.822188   1.33866233]\n",
      " [0.97960129 1.08478609]\n",
      " [1.56882919 1.51048953]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55797805 0.71360526]\n",
      " [0.69470059 0.79226988]\n",
      " [0.7270291  0.74739864]\n",
      " [0.82761664 0.81913374]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00637389]\n",
      " [ 0.00525748]\n",
      " [ 0.01060998]\n",
      " [ 0.01859896]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49840653]\n",
      " [0.50131437]\n",
      " [0.50265247]\n",
      " [0.50464961]]\n",
      "Error [[-0.49840653]\n",
      " [ 0.49868563]\n",
      " [ 0.49734753]\n",
      " [-0.50464961]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23298604 0.91295956]\n",
      " [0.8223057  1.3386555 ]\n",
      " [0.97969979 1.08476715]\n",
      " [1.56901945 1.51046309]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55798445 0.7136054 ]\n",
      " [0.69472556 0.79226875]\n",
      " [0.72704864 0.74739506]\n",
      " [0.82764378 0.81912983]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00641583]\n",
      " [ 0.0052553 ]\n",
      " [ 0.01061971]\n",
      " [ 0.0186365 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49839605]\n",
      " [0.50131382]\n",
      " [0.5026549 ]\n",
      " [0.50465899]]\n",
      "Error [[-0.49839605]\n",
      " [ 0.49868618]\n",
      " [ 0.4973451 ]\n",
      " [-0.50465899]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23301206 0.91296023]\n",
      " [0.82242374 1.33864867]\n",
      " [0.97979857 1.08474818]\n",
      " [1.56921025 1.51043662]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55799087 0.71360554]\n",
      " [0.69475059 0.79226763]\n",
      " [0.72706825 0.74739148]\n",
      " [0.82767099 0.8191259 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00645778]\n",
      " [ 0.00525313]\n",
      " [ 0.01062946]\n",
      " [ 0.01867406]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49838556]\n",
      " [0.50131328]\n",
      " [0.50265734]\n",
      " [0.50466838]]\n",
      "Error [[-0.49838556]\n",
      " [ 0.49868672]\n",
      " [ 0.49734266]\n",
      " [-0.50466838]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23303815 0.9129609 ]\n",
      " [0.82254212 1.33864183]\n",
      " [0.97989765 1.08472919]\n",
      " [1.56940162 1.51041012]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55799731 0.71360567]\n",
      " [0.6947757  0.7922665 ]\n",
      " [0.72708791 0.7473879 ]\n",
      " [0.82769829 0.81912198]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00649975]\n",
      " [ 0.00525096]\n",
      " [ 0.01063921]\n",
      " [ 0.01871163]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49837507]\n",
      " [0.50131274]\n",
      " [0.50265978]\n",
      " [0.50467777]]\n",
      "Error [[-0.49837507]\n",
      " [ 0.49868726]\n",
      " [ 0.49734022]\n",
      " [-0.50467777]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23306433 0.91296157]\n",
      " [0.82266085 1.33863498]\n",
      " [0.97999702 1.08471018]\n",
      " [1.56959354 1.51038359]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55800376 0.71360581]\n",
      " [0.69480087 0.79226537]\n",
      " [0.72710762 0.74738431]\n",
      " [0.82772566 0.81911805]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00654172]\n",
      " [ 0.00524881]\n",
      " [ 0.01064897]\n",
      " [ 0.01874922]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49836458]\n",
      " [0.5013122 ]\n",
      " [0.50266222]\n",
      " [0.50468717]]\n",
      "Error [[-0.49836458]\n",
      " [ 0.4986878 ]\n",
      " [ 0.49733778]\n",
      " [-0.50468717]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23309057 0.91296224]\n",
      " [0.82277992 1.33862812]\n",
      " [0.98009667 1.08469114]\n",
      " [1.56978602 1.51035702]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55801023 0.71360595]\n",
      " [0.69482612 0.79226425]\n",
      " [0.7271274  0.74738071]\n",
      " [0.8277531  0.81911411]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00658371]\n",
      " [ 0.00524667]\n",
      " [ 0.01065875]\n",
      " [ 0.01878684]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49835408]\n",
      " [0.50131166]\n",
      " [0.50266466]\n",
      " [0.50469657]]\n",
      "Error [[-0.49835408]\n",
      " [ 0.49868834]\n",
      " [ 0.49733534]\n",
      " [-0.50469657]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2331169  0.91296291]\n",
      " [0.82289934 1.33862126]\n",
      " [0.98019662 1.08467208]\n",
      " [1.56997906 1.51033043]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55801673 0.71360608]\n",
      " [0.69485144 0.79226312]\n",
      " [0.72714723 0.74737711]\n",
      " [0.82778062 0.81911017]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00662571]\n",
      " [ 0.00524453]\n",
      " [ 0.01066853]\n",
      " [ 0.01882446]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49834358]\n",
      " [0.50131113]\n",
      " [0.50266711]\n",
      " [0.50470598]]\n",
      "Error [[-0.49834358]\n",
      " [ 0.49868887]\n",
      " [ 0.49733289]\n",
      " [-0.50470598]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2331433  0.91296359]\n",
      " [0.8230191  1.33861439]\n",
      " [0.98029685 1.084653  ]\n",
      " [1.57017265 1.5103038 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55802324 0.71360622]\n",
      " [0.69487683 0.79226199]\n",
      " [0.72716711 0.74737351]\n",
      " [0.82780822 0.81910623]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00666772]\n",
      " [ 0.00524241]\n",
      " [ 0.01067832]\n",
      " [ 0.01886211]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49833308]\n",
      " [0.5013106 ]\n",
      " [0.50266955]\n",
      " [0.50471539]]\n",
      "Error [[-0.49833308]\n",
      " [ 0.4986894 ]\n",
      " [ 0.49733045]\n",
      " [-0.50471539]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23316978 0.91296426]\n",
      " [0.8231392  1.33860751]\n",
      " [0.98039738 1.08463389]\n",
      " [1.5703668  1.51027714]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55802977 0.71360636]\n",
      " [0.6949023  0.79226085]\n",
      " [0.72718706 0.7473699 ]\n",
      " [0.82783589 0.81910228]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00670974]\n",
      " [ 0.0052403 ]\n",
      " [ 0.01068812]\n",
      " [ 0.01889978]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49832257]\n",
      " [0.50131007]\n",
      " [0.502672  ]\n",
      " [0.5047248 ]]\n",
      "Error [[-0.49832257]\n",
      " [ 0.49868993]\n",
      " [ 0.497328  ]\n",
      " [-0.5047248 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23319633 0.91296493]\n",
      " [0.82325965 1.33860063]\n",
      " [0.98049819 1.08461476]\n",
      " [1.57056151 1.51025045]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55803632 0.7136065 ]\n",
      " [0.69492783 0.79225972]\n",
      " [0.72720706 0.74736629]\n",
      " [0.82786364 0.81909832]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00675177]\n",
      " [ 0.00523819]\n",
      " [ 0.01069793]\n",
      " [ 0.01893746]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49831206]\n",
      " [0.50130955]\n",
      " [0.50267446]\n",
      " [0.50473422]]\n",
      "Error [[-0.49831206]\n",
      " [ 0.49869045]\n",
      " [ 0.49732554]\n",
      " [-0.50473422]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23322296 0.91296561]\n",
      " [0.82338044 1.33859374]\n",
      " [0.98059929 1.0845956 ]\n",
      " [1.57075678 1.51022373]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55804288 0.71360663]\n",
      " [0.69495344 0.79225859]\n",
      " [0.72722711 0.74736267]\n",
      " [0.82789147 0.81909436]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00679382]\n",
      " [ 0.0052361 ]\n",
      " [ 0.01070775]\n",
      " [ 0.01897516]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49830155]\n",
      " [0.50130902]\n",
      " [0.50267691]\n",
      " [0.50474365]]\n",
      "Error [[-0.49830155]\n",
      " [ 0.49869098]\n",
      " [ 0.49732309]\n",
      " [-0.50474365]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23324966 0.91296628]\n",
      " [0.82350158 1.33858684]\n",
      " [0.98070069 1.08457642]\n",
      " [1.5709526  1.51019698]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55804947 0.71360677]\n",
      " [0.69497912 0.79225745]\n",
      " [0.72724723 0.74735905]\n",
      " [0.82791937 0.8190904 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00683588]\n",
      " [ 0.00523402]\n",
      " [ 0.01071758]\n",
      " [ 0.01901289]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49829104]\n",
      " [0.5013085 ]\n",
      " [0.50267937]\n",
      " [0.50475308]]\n",
      "Error [[-0.49829104]\n",
      " [ 0.4986915 ]\n",
      " [ 0.49732063]\n",
      " [-0.50475308]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23327645 0.91296696]\n",
      " [0.82362306 1.33857993]\n",
      " [0.98080237 1.08455722]\n",
      " [1.57114899 1.5101702 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55805608 0.71360691]\n",
      " [0.69500487 0.79225631]\n",
      " [0.7272674  0.74735543]\n",
      " [0.82794734 0.81908643]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00687794]\n",
      " [ 0.00523194]\n",
      " [ 0.01072741]\n",
      " [ 0.01905063]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49828052]\n",
      " [0.50130798]\n",
      " [0.50268183]\n",
      " [0.50476251]]\n",
      "Error [[-0.49828052]\n",
      " [ 0.49869202]\n",
      " [ 0.49731817]\n",
      " [-0.50476251]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2333033  0.91296763]\n",
      " [0.82374489 1.33857302]\n",
      " [0.98090435 1.08453799]\n",
      " [1.57134593 1.51014338]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5580627  0.71360705]\n",
      " [0.6950307  0.79225518]\n",
      " [0.72728762 0.7473518 ]\n",
      " [0.8279754  0.81908245]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00692002]\n",
      " [ 0.00522988]\n",
      " [ 0.01073726]\n",
      " [ 0.01908838]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49827   ]\n",
      " [0.50130747]\n",
      " [0.50268429]\n",
      " [0.50477195]]\n",
      "Error [[-0.49827   ]\n",
      " [ 0.49869253]\n",
      " [ 0.49731571]\n",
      " [-0.50477195]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23333024 0.91296831]\n",
      " [0.82386707 1.3385661 ]\n",
      " [0.98100661 1.08451874]\n",
      " [1.57154344 1.51011653]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55806934 0.71360719]\n",
      " [0.69505659 0.79225404]\n",
      " [0.7273079  0.74734816]\n",
      " [0.82800353 0.81907848]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00696212]\n",
      " [ 0.00522783]\n",
      " [ 0.01074712]\n",
      " [ 0.01912616]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49825948]\n",
      " [0.50130695]\n",
      " [0.50268675]\n",
      " [0.50478139]]\n",
      "Error [[-0.49825948]\n",
      " [ 0.49869305]\n",
      " [ 0.49731325]\n",
      " [-0.50478139]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23335725 0.91296898]\n",
      " [0.82398959 1.33855917]\n",
      " [0.98110917 1.08449947]\n",
      " [1.5717415  1.51008965]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.558076   0.71360732]\n",
      " [0.69508256 0.7922529 ]\n",
      " [0.72732824 0.74734452]\n",
      " [0.82803173 0.81907449]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00700422]\n",
      " [ 0.00522579]\n",
      " [ 0.01075698]\n",
      " [ 0.01916396]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49824895]\n",
      " [0.50130644]\n",
      " [0.50268922]\n",
      " [0.50479084]]\n",
      "Error [[-0.49824895]\n",
      " [ 0.49869356]\n",
      " [ 0.49731078]\n",
      " [-0.50479084]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23338434 0.91296966]\n",
      " [0.82411245 1.33855223]\n",
      " [0.98121201 1.08448017]\n",
      " [1.57194013 1.51006274]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55808269 0.71360746]\n",
      " [0.6951086  0.79225176]\n",
      " [0.72734864 0.74734088]\n",
      " [0.82806001 0.81907051]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00704634]\n",
      " [ 0.00522375]\n",
      " [ 0.01076686]\n",
      " [ 0.01920177]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49823842]\n",
      " [0.50130594]\n",
      " [0.50269169]\n",
      " [0.5048003 ]]\n",
      "Error [[-0.49823842]\n",
      " [ 0.49869406]\n",
      " [ 0.49730831]\n",
      " [-0.5048003 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2334115  0.91297034]\n",
      " [0.82423566 1.33854529]\n",
      " [0.98131515 1.08446085]\n",
      " [1.57213931 1.5100358 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55808938 0.7136076 ]\n",
      " [0.69513471 0.79225061]\n",
      " [0.72736909 0.74733723]\n",
      " [0.82808837 0.81906651]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00708847]\n",
      " [ 0.00522173]\n",
      " [ 0.01077674]\n",
      " [ 0.01923961]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49822789]\n",
      " [0.50130543]\n",
      " [0.50269416]\n",
      " [0.50480975]]\n",
      "Error [[-0.49822789]\n",
      " [ 0.49869457]\n",
      " [ 0.49730584]\n",
      " [-0.50480975]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23343874 0.91297102]\n",
      " [0.82435922 1.33853834]\n",
      " [0.98141858 1.08444151]\n",
      " [1.57233906 1.51000883]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5580961  0.71360774]\n",
      " [0.6951609  0.79224947]\n",
      " [0.7273896  0.74733358]\n",
      " [0.8281168  0.81906252]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00713061]\n",
      " [ 0.00521972]\n",
      " [ 0.01078664]\n",
      " [ 0.01927746]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49821736]\n",
      " [0.50130493]\n",
      " [0.50269663]\n",
      " [0.50481922]]\n",
      "Error [[-0.49821736]\n",
      " [ 0.49869507]\n",
      " [ 0.49730337]\n",
      " [-0.50481922]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23346606 0.91297169]\n",
      " [0.82448312 1.33853138]\n",
      " [0.9815223  1.08442214]\n",
      " [1.57253936 1.50998182]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55810284 0.71360788]\n",
      " [0.69518715 0.79224832]\n",
      " [0.72741017 0.74732992]\n",
      " [0.82814531 0.81905851]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00717276]\n",
      " [ 0.00521772]\n",
      " [ 0.01079654]\n",
      " [ 0.01931533]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49820682]\n",
      " [0.50130443]\n",
      " [0.50269911]\n",
      " [0.50482868]]\n",
      "Error [[-0.49820682]\n",
      " [ 0.49869557]\n",
      " [ 0.49730089]\n",
      " [-0.50482868]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23349345 0.91297237]\n",
      " [0.82460737 1.33852442]\n",
      " [0.98162631 1.08440274]\n",
      " [1.57274023 1.50995478]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5581096  0.71360802]\n",
      " [0.69521348 0.79224718]\n",
      " [0.72743079 0.74732626]\n",
      " [0.8281739  0.81905451]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00721493]\n",
      " [ 0.00521572]\n",
      " [ 0.01080645]\n",
      " [ 0.01935322]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49819628]\n",
      " [0.50130393]\n",
      " [0.50270159]\n",
      " [0.50483815]]\n",
      "Error [[-0.49819628]\n",
      " [ 0.49869607]\n",
      " [ 0.49729841]\n",
      " [-0.50483815]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23352093 0.91297305]\n",
      " [0.82473197 1.33851744]\n",
      " [0.98173061 1.08438333]\n",
      " [1.57294166 1.50992772]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55811637 0.71360816]\n",
      " [0.69523988 0.79224603]\n",
      " [0.72745147 0.74732259]\n",
      " [0.82820256 0.81905049]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0072571 ]\n",
      " [ 0.00521374]\n",
      " [ 0.01081637]\n",
      " [ 0.01939113]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49818573]\n",
      " [0.50130343]\n",
      " [0.50270407]\n",
      " [0.50484763]]\n",
      "Error [[-0.49818573]\n",
      " [ 0.49869657]\n",
      " [ 0.49729593]\n",
      " [-0.50484763]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23354847 0.91297373]\n",
      " [0.82485691 1.33851046]\n",
      " [0.98183521 1.08436389]\n",
      " [1.57314364 1.50990062]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55812316 0.71360829]\n",
      " [0.69526635 0.79224488]\n",
      " [0.72747221 0.74731892]\n",
      " [0.8282313  0.81904648]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00729929]\n",
      " [ 0.00521177]\n",
      " [ 0.01082631]\n",
      " [ 0.01942906]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49817518]\n",
      " [0.50130294]\n",
      " [0.50270655]\n",
      " [0.50485711]]\n",
      "Error [[-0.49817518]\n",
      " [ 0.49869706]\n",
      " [ 0.49729345]\n",
      " [-0.50485711]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2335761  0.91297441]\n",
      " [0.8249822  1.33850348]\n",
      " [0.98194009 1.08434442]\n",
      " [1.5733462  1.50987348]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55812998 0.71360843]\n",
      " [0.6952929  0.79224373]\n",
      " [0.727493   0.74731524]\n",
      " [0.82826011 0.81904246]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0073415 ]\n",
      " [ 0.00520981]\n",
      " [ 0.01083625]\n",
      " [ 0.01946701]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49816463]\n",
      " [0.50130245]\n",
      " [0.50270904]\n",
      " [0.5048666 ]]\n",
      "Error [[-0.49816463]\n",
      " [ 0.49869755]\n",
      " [ 0.49729096]\n",
      " [-0.5048666 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2336038  0.91297509]\n",
      " [0.82510784 1.33849648]\n",
      " [0.98204527 1.08432493]\n",
      " [1.57354931 1.50984632]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55813681 0.71360857]\n",
      " [0.69531952 0.79224258]\n",
      " [0.72751385 0.74731156]\n",
      " [0.828289   0.81903843]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00738371]\n",
      " [ 0.00520786]\n",
      " [ 0.0108462 ]\n",
      " [ 0.01950497]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49815408]\n",
      " [0.50130196]\n",
      " [0.50271152]\n",
      " [0.50487609]]\n",
      "Error [[-0.49815408]\n",
      " [ 0.49869804]\n",
      " [ 0.49728848]\n",
      " [-0.50487609]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23363157 0.91297578]\n",
      " [0.82523382 1.33848948]\n",
      " [0.98215074 1.08430542]\n",
      " [1.57375299 1.50981912]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55814366 0.71360871]\n",
      " [0.6953462  0.79224143]\n",
      " [0.72753476 0.74730788]\n",
      " [0.82831797 0.8190344 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00742594]\n",
      " [ 0.00520592]\n",
      " [ 0.01085616]\n",
      " [ 0.01954296]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49814352]\n",
      " [0.50130148]\n",
      " [0.50271401]\n",
      " [0.50488558]]\n",
      "Error [[-0.49814352]\n",
      " [ 0.49869852]\n",
      " [ 0.49728599]\n",
      " [-0.50488558]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23365943 0.91297646]\n",
      " [0.82536015 1.33848247]\n",
      " [0.9822565  1.08428588]\n",
      " [1.57395722 1.5097919 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55815053 0.71360885]\n",
      " [0.69537297 0.79224027]\n",
      " [0.72755573 0.74730419]\n",
      " [0.82834701 0.81903036]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00746818]\n",
      " [ 0.00520399]\n",
      " [ 0.01086613]\n",
      " [ 0.01958097]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49813296]\n",
      " [0.50130099]\n",
      " [0.5027165 ]\n",
      " [0.50489509]]\n",
      "Error [[-0.49813296]\n",
      " [ 0.49869901]\n",
      " [ 0.4972835 ]\n",
      " [-0.50489509]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23368736 0.91297714]\n",
      " [0.82548683 1.33847546]\n",
      " [0.98236256 1.08426632]\n",
      " [1.57416203 1.50976464]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55815742 0.71360899]\n",
      " [0.6953998  0.79223912]\n",
      " [0.72757675 0.7473005 ]\n",
      " [0.82837613 0.81902632]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00751043]\n",
      " [ 0.00520207]\n",
      " [ 0.01087611]\n",
      " [ 0.01961899]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4981224 ]\n",
      " [0.50130051]\n",
      " [0.502719  ]\n",
      " [0.50490459]]\n",
      "Error [[-0.4981224 ]\n",
      " [ 0.49869949]\n",
      " [ 0.497281  ]\n",
      " [-0.50490459]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23371536 0.91297782]\n",
      " [0.82561385 1.33846843]\n",
      " [0.9824689  1.08424674]\n",
      " [1.57436739 1.50973735]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55816432 0.71360913]\n",
      " [0.6954267  0.79223796]\n",
      " [0.72759783 0.7472968 ]\n",
      " [0.82840532 0.81902228]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0075527 ]\n",
      " [ 0.00520016]\n",
      " [ 0.01088609]\n",
      " [ 0.01965704]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49811183]\n",
      " [0.50130004]\n",
      " [0.5027215 ]\n",
      " [0.5049141 ]]\n",
      "Error [[-0.49811183]\n",
      " [ 0.49869996]\n",
      " [ 0.4972785 ]\n",
      " [-0.5049141 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23374345 0.91297851]\n",
      " [0.82574123 1.3384614 ]\n",
      " [0.98257554 1.08422713]\n",
      " [1.57457332 1.50971002]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55817125 0.71360927]\n",
      " [0.69545368 0.79223681]\n",
      " [0.72761896 0.74729309]\n",
      " [0.82843459 0.81901823]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00759498]\n",
      " [ 0.00519826]\n",
      " [ 0.01089609]\n",
      " [ 0.0196951 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49810126]\n",
      " [0.50129956]\n",
      " [0.502724  ]\n",
      " [0.50492362]]\n",
      "Error [[-0.49810126]\n",
      " [ 0.49870044]\n",
      " [ 0.497276  ]\n",
      " [-0.50492362]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23377161 0.91297919]\n",
      " [0.82586895 1.33845436]\n",
      " [0.98268247 1.0842075 ]\n",
      " [1.57477981 1.50968267]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55817819 0.71360941]\n",
      " [0.69548073 0.79223565]\n",
      " [0.72764015 0.74728939]\n",
      " [0.82846394 0.81901417]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00763727]\n",
      " [ 0.00519637]\n",
      " [ 0.0109061 ]\n",
      " [ 0.01973318]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49809069]\n",
      " [0.50129909]\n",
      " [0.5027265 ]\n",
      " [0.50493314]]\n",
      "Error [[-0.49809069]\n",
      " [ 0.49870091]\n",
      " [ 0.4972735 ]\n",
      " [-0.50493314]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23379985 0.91297988]\n",
      " [0.82599702 1.33844732]\n",
      " [0.9827897  1.08418784]\n",
      " [1.57498687 1.50965528]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55818516 0.71360955]\n",
      " [0.69550786 0.79223449]\n",
      " [0.7276614  0.74728567]\n",
      " [0.82849336 0.81901011]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00767958]\n",
      " [ 0.00519449]\n",
      " [ 0.01091612]\n",
      " [ 0.01977129]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49808012]\n",
      " [0.50129862]\n",
      " [0.502729  ]\n",
      " [0.50494266]]\n",
      "Error [[-0.49808012]\n",
      " [ 0.49870138]\n",
      " [ 0.497271  ]\n",
      " [-0.50494266]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23382816 0.91298056]\n",
      " [0.82612543 1.33844027]\n",
      " [0.98289722 1.08416816]\n",
      " [1.57519449 1.50962786]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55819214 0.71360969]\n",
      " [0.69553505 0.79223333]\n",
      " [0.72768271 0.74728196]\n",
      " [0.82852286 0.81900605]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0077219 ]\n",
      " [ 0.00519263]\n",
      " [ 0.01092615]\n",
      " [ 0.01980941]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49806954]\n",
      " [0.50129815]\n",
      " [0.50273151]\n",
      " [0.50495219]]\n",
      "Error [[-0.49806954]\n",
      " [ 0.49870185]\n",
      " [ 0.49726849]\n",
      " [-0.50495219]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23385655 0.91298125]\n",
      " [0.8262542  1.33843321]\n",
      " [0.98300503 1.08414845]\n",
      " [1.57540267 1.50960041]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55819914 0.71360983]\n",
      " [0.69556232 0.79223216]\n",
      " [0.72770407 0.74727824]\n",
      " [0.82855244 0.81900198]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00776423]\n",
      " [ 0.00519077]\n",
      " [ 0.01093618]\n",
      " [ 0.01984755]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49805895]\n",
      " [0.50129769]\n",
      " [0.50273402]\n",
      " [0.50496173]]\n",
      "Error [[-0.49805895]\n",
      " [ 0.49870231]\n",
      " [ 0.49726598]\n",
      " [-0.50496173]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23388502 0.91298193]\n",
      " [0.82638331 1.33842614]\n",
      " [0.98311314 1.08412873]\n",
      " [1.57561143 1.50957293]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55820616 0.71360997]\n",
      " [0.69558966 0.792231  ]\n",
      " [0.72772549 0.74727451]\n",
      " [0.82858209 0.81899791]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00780657]\n",
      " [ 0.00518892]\n",
      " [ 0.01094623]\n",
      " [ 0.01988572]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49804837]\n",
      " [0.50129723]\n",
      " [0.50273653]\n",
      " [0.50497126]]\n",
      "Error [[-0.49804837]\n",
      " [ 0.49870277]\n",
      " [ 0.49726347]\n",
      " [-0.50497126]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23391357 0.91298262]\n",
      " [0.82651277 1.33841906]\n",
      " [0.98322153 1.08410897]\n",
      " [1.57582074 1.50954542]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5582132  0.71361011]\n",
      " [0.69561707 0.79222984]\n",
      " [0.72774697 0.74727078]\n",
      " [0.82861182 0.81899383]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00784893]\n",
      " [ 0.00518709]\n",
      " [ 0.01095628]\n",
      " [ 0.0199239 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49803778]\n",
      " [0.50129677]\n",
      " [0.50273904]\n",
      " [0.50498081]]\n",
      "Error [[-0.49803778]\n",
      " [ 0.49870323]\n",
      " [ 0.49726096]\n",
      " [-0.50498081]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23394219 0.91298331]\n",
      " [0.82664258 1.33841198]\n",
      " [0.98333023 1.0840892 ]\n",
      " [1.57603062 1.50951787]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55822026 0.71361025]\n",
      " [0.69564455 0.79222867]\n",
      " [0.72776851 0.74726705]\n",
      " [0.82864162 0.81898974]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0078913 ]\n",
      " [ 0.00518526]\n",
      " [ 0.01096635]\n",
      " [ 0.0199621 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49802718]\n",
      " [0.50129631]\n",
      " [0.50274156]\n",
      " [0.50499036]]\n",
      "Error [[-0.49802718]\n",
      " [ 0.49870369]\n",
      " [ 0.49725844]\n",
      " [-0.50499036]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23397089 0.91298399]\n",
      " [0.82677274 1.33840489]\n",
      " [0.98343921 1.0840694 ]\n",
      " [1.57624107 1.5094903 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55822734 0.71361039]\n",
      " [0.69567211 0.7922275 ]\n",
      " [0.7277901  0.74726331]\n",
      " [0.8286715  0.81898566]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00793369]\n",
      " [ 0.00518344]\n",
      " [ 0.01097643]\n",
      " [ 0.02000032]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49801659]\n",
      " [0.50129586]\n",
      " [0.50274408]\n",
      " [0.50499991]]\n",
      "Error [[-0.49801659]\n",
      " [ 0.49870414]\n",
      " [ 0.49725592]\n",
      " [-0.50499991]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23399966 0.91298468]\n",
      " [0.82690325 1.3383978 ]\n",
      " [0.98354849 1.08404957]\n",
      " [1.57645208 1.50946269]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55823444 0.71361053]\n",
      " [0.69569974 0.79222634]\n",
      " [0.72781175 0.74725956]\n",
      " [0.82870146 0.81898156]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00797609]\n",
      " [ 0.00518164]\n",
      " [ 0.01098651]\n",
      " [ 0.02003856]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49800599]\n",
      " [0.50129541]\n",
      " [0.5027466 ]\n",
      " [0.50500947]]\n",
      "Error [[-0.49800599]\n",
      " [ 0.49870459]\n",
      " [ 0.4972534 ]\n",
      " [-0.50500947]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23402852 0.91298537]\n",
      " [0.82703411 1.33839069]\n",
      " [0.98365807 1.08402972]\n",
      " [1.57666366 1.50943504]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55824155 0.71361067]\n",
      " [0.69572744 0.79222517]\n",
      " [0.72783345 0.74725581]\n",
      " [0.82873149 0.81897747]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0080185 ]\n",
      " [ 0.00517985]\n",
      " [ 0.01099661]\n",
      " [ 0.02007682]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49799539]\n",
      " [0.50129496]\n",
      " [0.50274912]\n",
      " [0.50501904]]\n",
      "Error [[-0.49799539]\n",
      " [ 0.49870504]\n",
      " [ 0.49725088]\n",
      " [-0.50501904]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23405745 0.91298606]\n",
      " [0.82716532 1.33838358]\n",
      " [0.98376794 1.08400985]\n",
      " [1.57687581 1.50940737]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55824869 0.71361081]\n",
      " [0.69575522 0.792224  ]\n",
      " [0.72785522 0.74725206]\n",
      " [0.8287616  0.81897336]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00806092]\n",
      " [ 0.00517806]\n",
      " [ 0.01100671]\n",
      " [ 0.02011511]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49798478]\n",
      " [0.50129451]\n",
      " [0.50275165]\n",
      " [0.50502861]]\n",
      "Error [[-0.49798478]\n",
      " [ 0.49870549]\n",
      " [ 0.49724835]\n",
      " [-0.50502861]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23408646 0.91298675]\n",
      " [0.82729687 1.33837646]\n",
      " [0.9838781  1.08398995]\n",
      " [1.57708852 1.50937967]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55825584 0.71361096]\n",
      " [0.69578307 0.79222282]\n",
      " [0.72787704 0.7472483 ]\n",
      " [0.82879179 0.81896926]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00810336]\n",
      " [ 0.00517629]\n",
      " [ 0.01101683]\n",
      " [ 0.02015341]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49797417]\n",
      " [0.50129407]\n",
      " [0.50275418]\n",
      " [0.50503818]]\n",
      "Error [[-0.49797417]\n",
      " [ 0.49870593]\n",
      " [ 0.49724582]\n",
      " [-0.50503818]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23411554 0.91298744]\n",
      " [0.82742878 1.33836934]\n",
      " [0.98398856 1.08397003]\n",
      " [1.5773018  1.50935193]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55826301 0.7136111 ]\n",
      " [0.69581098 0.79222165]\n",
      " [0.72789892 0.74724454]\n",
      " [0.82882205 0.81896514]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00814582]\n",
      " [ 0.00517452]\n",
      " [ 0.01102695]\n",
      " [ 0.02019173]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49796356]\n",
      " [0.50129363]\n",
      " [0.50275671]\n",
      " [0.50504776]]\n",
      "Error [[-0.49796356]\n",
      " [ 0.49870637]\n",
      " [ 0.49724329]\n",
      " [-0.50504776]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2341447  0.91298813]\n",
      " [0.82756104 1.33836221]\n",
      " [0.98409931 1.08395008]\n",
      " [1.57751565 1.50932416]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5582702  0.71361124]\n",
      " [0.69583898 0.79222048]\n",
      " [0.72792085 0.74724077]\n",
      " [0.82885239 0.81896103]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00818828]\n",
      " [ 0.00517277]\n",
      " [ 0.01103708]\n",
      " [ 0.02023007]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49795294]\n",
      " [0.50129319]\n",
      " [0.50275924]\n",
      " [0.50505735]]\n",
      "Error [[-0.49795294]\n",
      " [ 0.49870681]\n",
      " [ 0.49724076]\n",
      " [-0.50505735]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23417394 0.91298882]\n",
      " [0.82769365 1.33835507]\n",
      " [0.98421036 1.08393011]\n",
      " [1.57773007 1.50929636]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55827741 0.71361138]\n",
      " [0.69586704 0.7922193 ]\n",
      " [0.72794285 0.747237  ]\n",
      " [0.8288828  0.8189569 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00823077]\n",
      " [ 0.00517103]\n",
      " [ 0.01104723]\n",
      " [ 0.02026844]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49794232]\n",
      " [0.50129275]\n",
      " [0.50276178]\n",
      " [0.50506694]]\n",
      "Error [[-0.49794232]\n",
      " [ 0.49870725]\n",
      " [ 0.49723822]\n",
      " [-0.50506694]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23420326 0.91298951]\n",
      " [0.8278266  1.33834792]\n",
      " [0.98432171 1.08391012]\n",
      " [1.57794505 1.50926852]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55828464 0.71361152]\n",
      " [0.69589518 0.79221813]\n",
      " [0.7279649  0.74723322]\n",
      " [0.82891329 0.81895278]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00827326]\n",
      " [ 0.0051693 ]\n",
      " [ 0.01105738]\n",
      " [ 0.02030682]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4979317 ]\n",
      " [0.50129232]\n",
      " [0.50276432]\n",
      " [0.50507653]]\n",
      "Error [[-0.4979317 ]\n",
      " [ 0.49870768]\n",
      " [ 0.49723568]\n",
      " [-0.50507653]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23423265 0.91299021]\n",
      " [0.82795991 1.33834076]\n",
      " [0.98443334 1.0838901 ]\n",
      " [1.5781606  1.50924066]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55829189 0.71361166]\n",
      " [0.69592339 0.79221695]\n",
      " [0.727987   0.74722944]\n",
      " [0.82894386 0.81894865]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00831577]\n",
      " [ 0.00516758]\n",
      " [ 0.01106755]\n",
      " [ 0.02034522]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49792107]\n",
      " [0.50129189]\n",
      " [0.50276686]\n",
      " [0.50508613]]\n",
      "Error [[-0.49792107]\n",
      " [ 0.49870811]\n",
      " [ 0.49723314]\n",
      " [-0.50508613]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23426212 0.9129909 ]\n",
      " [0.82809357 1.3383336 ]\n",
      " [0.98454528 1.08387006]\n",
      " [1.57837673 1.50921276]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55829916 0.7136118 ]\n",
      " [0.69595167 0.79221577]\n",
      " [0.72800917 0.74722566]\n",
      " [0.8289745  0.81894451]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00835829]\n",
      " [ 0.00516587]\n",
      " [ 0.01107772]\n",
      " [ 0.02038365]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49791044]\n",
      " [0.50129146]\n",
      " [0.5027694 ]\n",
      " [0.50509574]]\n",
      "Error [[-0.49791044]\n",
      " [ 0.49870854]\n",
      " [ 0.4972306 ]\n",
      " [-0.50509574]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23429167 0.91299159]\n",
      " [0.82822758 1.33832643]\n",
      " [0.98465751 1.08384999]\n",
      " [1.57859342 1.50918483]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55830644 0.71361194]\n",
      " [0.69598003 0.79221459]\n",
      " [0.72803139 0.74722187]\n",
      " [0.82900522 0.81894037]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00840083]\n",
      " [ 0.00516417]\n",
      " [ 0.0110879 ]\n",
      " [ 0.02042209]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4978998 ]\n",
      " [0.50129104]\n",
      " [0.50277195]\n",
      " [0.50510535]]\n",
      "Error [[-0.4978998 ]\n",
      " [ 0.49870896]\n",
      " [ 0.49722805]\n",
      " [-0.50510535]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23432129 0.91299229]\n",
      " [0.82836194 1.33831926]\n",
      " [0.98477003 1.0838299 ]\n",
      " [1.57881068 1.50915687]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55831375 0.71361209]\n",
      " [0.69600846 0.79221341]\n",
      " [0.72805367 0.74721807]\n",
      " [0.82903601 0.81893622]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00844338]\n",
      " [ 0.00516248]\n",
      " [ 0.0110981 ]\n",
      " [ 0.02046055]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49788917]\n",
      " [0.50129062]\n",
      " [0.5027745 ]\n",
      " [0.50511496]]\n",
      "Error [[-0.49788917]\n",
      " [ 0.49870938]\n",
      " [ 0.4972255 ]\n",
      " [-0.50511496]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.234351   0.91299298]\n",
      " [0.82849665 1.33831207]\n",
      " [0.98488286 1.08380978]\n",
      " [1.57902851 1.50912887]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55832108 0.71361223]\n",
      " [0.69603696 0.79221223]\n",
      " [0.72807601 0.74721427]\n",
      " [0.82906689 0.81893207]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00848595]\n",
      " [ 0.0051608 ]\n",
      " [ 0.0111083 ]\n",
      " [ 0.02049904]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49787853]\n",
      " [0.5012902 ]\n",
      " [0.50277705]\n",
      " [0.50512458]]\n",
      "Error [[-0.49787853]\n",
      " [ 0.4987098 ]\n",
      " [ 0.49722295]\n",
      " [-0.50512458]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23438078 0.91299368]\n",
      " [0.82863171 1.33830488]\n",
      " [0.98499597 1.08378964]\n",
      " [1.57924691 1.50910085]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55832842 0.71361237]\n",
      " [0.69606553 0.79221104]\n",
      " [0.7280984  0.74721047]\n",
      " [0.82909784 0.81892791]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00852853]\n",
      " [ 0.00515914]\n",
      " [ 0.01111851]\n",
      " [ 0.02053755]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49786788]\n",
      " [0.50128978]\n",
      " [0.5027796 ]\n",
      " [0.50513421]]\n",
      "Error [[-0.49786788]\n",
      " [ 0.49871022]\n",
      " [ 0.4972204 ]\n",
      " [-0.50513421]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23441063 0.91299437]\n",
      " [0.82876712 1.33829768]\n",
      " [0.98510939 1.08376948]\n",
      " [1.57946588 1.50907279]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55833578 0.71361251]\n",
      " [0.69609418 0.79220986]\n",
      " [0.72812085 0.74720666]\n",
      " [0.82912886 0.81892375]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00857113]\n",
      " [ 0.00515748]\n",
      " [ 0.01112874]\n",
      " [ 0.02057607]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49785723]\n",
      " [0.50128937]\n",
      " [0.50278216]\n",
      " [0.50514384]]\n",
      "Error [[-0.49785723]\n",
      " [ 0.49871063]\n",
      " [ 0.49721784]\n",
      " [-0.50514384]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23444057 0.91299507]\n",
      " [0.82890289 1.33829048]\n",
      " [0.9852231  1.08374929]\n",
      " [1.57968542 1.5090447 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55834316 0.71361265]\n",
      " [0.6961229  0.79220867]\n",
      " [0.72814336 0.74720285]\n",
      " [0.82915996 0.81891959]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00861374]\n",
      " [ 0.00515584]\n",
      " [ 0.01113897]\n",
      " [ 0.02061462]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49784658]\n",
      " [0.50128896]\n",
      " [0.50278471]\n",
      " [0.50515347]]\n",
      "Error [[-0.49784658]\n",
      " [ 0.49871104]\n",
      " [ 0.49721529]\n",
      " [-0.50515347]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23447058 0.91299576]\n",
      " [0.82903901 1.33828326]\n",
      " [0.9853371  1.08372908]\n",
      " [1.57990553 1.50901658]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55835056 0.7136128 ]\n",
      " [0.69615169 0.79220748]\n",
      " [0.72816593 0.74719903]\n",
      " [0.82919114 0.81891542]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00865636]\n",
      " [ 0.0051542 ]\n",
      " [ 0.01114921]\n",
      " [ 0.02065319]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49783592]\n",
      " [0.50128855]\n",
      " [0.50278727]\n",
      " [0.50516311]]\n",
      "Error [[-0.49783592]\n",
      " [ 0.49871145]\n",
      " [ 0.49721273]\n",
      " [-0.50516311]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23450067 0.91299646]\n",
      " [0.82917547 1.33827604]\n",
      " [0.98545141 1.08370884]\n",
      " [1.58012621 1.50898842]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55835798 0.71361294]\n",
      " [0.69618056 0.79220629]\n",
      " [0.72818855 0.7471952 ]\n",
      " [0.82922239 0.81891124]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.008699  ]\n",
      " [ 0.00515258]\n",
      " [ 0.01115947]\n",
      " [ 0.02069178]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49782526]\n",
      " [0.50128814]\n",
      " [0.50278984]\n",
      " [0.50517276]]\n",
      "Error [[-0.49782526]\n",
      " [ 0.49871186]\n",
      " [ 0.49721016]\n",
      " [-0.50517276]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23453084 0.91299716]\n",
      " [0.8293123  1.33826882]\n",
      " [0.98556601 1.08368858]\n",
      " [1.58034747 1.50896024]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55836542 0.71361308]\n",
      " [0.6962095  0.7922051 ]\n",
      " [0.72821124 0.74719138]\n",
      " [0.82925372 0.81890706]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00874165]\n",
      " [ 0.00515096]\n",
      " [ 0.01116973]\n",
      " [ 0.02073039]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4978146 ]\n",
      " [0.50128774]\n",
      " [0.5027924 ]\n",
      " [0.50518241]]\n",
      "Error [[-0.4978146 ]\n",
      " [ 0.49871226]\n",
      " [ 0.4972076 ]\n",
      " [-0.50518241]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23456108 0.91299786]\n",
      " [0.82944947 1.33826158]\n",
      " [0.98568091 1.08366829]\n",
      " [1.58056929 1.50893202]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55837288 0.71361322]\n",
      " [0.69623851 0.79220391]\n",
      " [0.72823398 0.74718755]\n",
      " [0.82928513 0.81890288]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00878432]\n",
      " [ 0.00514936]\n",
      " [ 0.01118   ]\n",
      " [ 0.02076902]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49780393]\n",
      " [0.50128734]\n",
      " [0.50279497]\n",
      " [0.50519207]]\n",
      "Error [[-0.49780393]\n",
      " [ 0.49871266]\n",
      " [ 0.49720503]\n",
      " [-0.50519207]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2345914  0.91299856]\n",
      " [0.82958699 1.33825434]\n",
      " [0.9857961  1.08364798]\n",
      " [1.58079169 1.50890376]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55838036 0.71361337]\n",
      " [0.69626759 0.79220272]\n",
      " [0.72825677 0.74718371]\n",
      " [0.82931661 0.81889869]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00882701]\n",
      " [ 0.00514777]\n",
      " [ 0.01119029]\n",
      " [ 0.02080767]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49779326]\n",
      " [0.50128694]\n",
      " [0.50279754]\n",
      " [0.50520173]]\n",
      "Error [[-0.49779326]\n",
      " [ 0.49871306]\n",
      " [ 0.49720246]\n",
      " [-0.50520173]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2346218  0.91299925]\n",
      " [0.82972487 1.33824709]\n",
      " [0.98591159 1.08362765]\n",
      " [1.58101466 1.50887548]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55838785 0.71361351]\n",
      " [0.69629675 0.79220153]\n",
      " [0.72827963 0.74717987]\n",
      " [0.82934817 0.81889449]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0088697 ]\n",
      " [ 0.00514619]\n",
      " [ 0.01120058]\n",
      " [ 0.02084634]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49778259]\n",
      " [0.50128654]\n",
      " [0.50280012]\n",
      " [0.5052114 ]]\n",
      "Error [[-0.49778259]\n",
      " [ 0.49871346]\n",
      " [ 0.49719988]\n",
      " [-0.5052114 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23465228 0.91299995]\n",
      " [0.8298631  1.33823983]\n",
      " [0.98602738 1.08360729]\n",
      " [1.5812382  1.50884716]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55839537 0.71361365]\n",
      " [0.69632598 0.79220033]\n",
      " [0.72830254 0.74717602]\n",
      " [0.82937981 0.81889029]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00891242]\n",
      " [ 0.00514462]\n",
      " [ 0.01121088]\n",
      " [ 0.02088504]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49777191]\n",
      " [0.50128615]\n",
      " [0.50280269]\n",
      " [0.50522107]]\n",
      "Error [[-0.49777191]\n",
      " [ 0.49871385]\n",
      " [ 0.49719731]\n",
      " [-0.50522107]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23468284 0.91300065]\n",
      " [0.83000169 1.33823257]\n",
      " [0.98614347 1.0835869 ]\n",
      " [1.58146232 1.50881882]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5584029  0.7136138 ]\n",
      " [0.69635529 0.79219914]\n",
      " [0.72832551 0.74717217]\n",
      " [0.82941152 0.81888609]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00895515]\n",
      " [ 0.00514306]\n",
      " [ 0.0112212 ]\n",
      " [ 0.02092375]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49776123]\n",
      " [0.50128576]\n",
      " [0.50280527]\n",
      " [0.50523075]]\n",
      "Error [[-0.49776123]\n",
      " [ 0.49871424]\n",
      " [ 0.49719473]\n",
      " [-0.50523075]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23471347 0.91300136]\n",
      " [0.83014063 1.3382253 ]\n",
      " [0.98625985 1.08356649]\n",
      " [1.58168701 1.50879043]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55841046 0.71361394]\n",
      " [0.69638466 0.79219794]\n",
      " [0.72834854 0.74716832]\n",
      " [0.82944331 0.81888188]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00899789]\n",
      " [ 0.00514151]\n",
      " [ 0.01123152]\n",
      " [ 0.02096249]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49775054]\n",
      " [0.50128538]\n",
      " [0.50280785]\n",
      " [0.50524043]]\n",
      "Error [[-0.49775054]\n",
      " [ 0.49871462]\n",
      " [ 0.49719215]\n",
      " [-0.50524043]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23474418 0.91300206]\n",
      " [0.83027992 1.33821802]\n",
      " [0.98637654 1.08354606]\n",
      " [1.58191227 1.50876202]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55841803 0.71361408]\n",
      " [0.69641411 0.79219674]\n",
      " [0.72837163 0.74716446]\n",
      " [0.82947517 0.81887767]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00904065]\n",
      " [ 0.00513998]\n",
      " [ 0.01124186]\n",
      " [ 0.02100125]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49773985]\n",
      " [0.50128499]\n",
      " [0.50281043]\n",
      " [0.50525012]]\n",
      "Error [[-0.49773985]\n",
      " [ 0.49871501]\n",
      " [ 0.49718957]\n",
      " [-0.50525012]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23477497 0.91300276]\n",
      " [0.83041956 1.33821073]\n",
      " [0.98649352 1.0835256 ]\n",
      " [1.58213811 1.50873358]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55842562 0.71361423]\n",
      " [0.69644364 0.79219554]\n",
      " [0.72839477 0.74716059]\n",
      " [0.82950711 0.81887345]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00908342]\n",
      " [ 0.00513845]\n",
      " [ 0.0112522 ]\n",
      " [ 0.02104003]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49772916]\n",
      " [0.50128461]\n",
      " [0.50281302]\n",
      " [0.50525981]]\n",
      "Error [[-0.49772916]\n",
      " [ 0.49871539]\n",
      " [ 0.49718698]\n",
      " [-0.50525981]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23480583 0.91300346]\n",
      " [0.83055956 1.33820344]\n",
      " [0.9866108  1.08350512]\n",
      " [1.58236452 1.5087051 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55843323 0.71361437]\n",
      " [0.69647323 0.79219434]\n",
      " [0.72841797 0.74715672]\n",
      " [0.82953913 0.81886922]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00912621]\n",
      " [ 0.00513694]\n",
      " [ 0.01126255]\n",
      " [ 0.02107883]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49771846]\n",
      " [0.50128423]\n",
      " [0.50281561]\n",
      " [0.50526951]]\n",
      "Error [[-0.49771846]\n",
      " [ 0.49871577]\n",
      " [ 0.49718439]\n",
      " [-0.50526951]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23483678 0.91300416]\n",
      " [0.83069991 1.33819614]\n",
      " [0.98672838 1.08348461]\n",
      " [1.58259151 1.50867659]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55844086 0.71361451]\n",
      " [0.6965029  0.79219314]\n",
      " [0.72844123 0.74715285]\n",
      " [0.82957123 0.81886499]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00916902]\n",
      " [ 0.00513543]\n",
      " [ 0.01127292]\n",
      " [ 0.02111765]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49770776]\n",
      " [0.50128386]\n",
      " [0.5028182 ]\n",
      " [0.50527922]]\n",
      "Error [[-0.49770776]\n",
      " [ 0.49871614]\n",
      " [ 0.4971818 ]\n",
      " [-0.50527922]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2348678  0.91300487]\n",
      " [0.83084061 1.33818883]\n",
      " [0.98684626 1.08346408]\n",
      " [1.58281907 1.50864805]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55844851 0.71361466]\n",
      " [0.69653264 0.79219194]\n",
      " [0.72846455 0.74714897]\n",
      " [0.8296034  0.81886076]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00921184]\n",
      " [ 0.00513394]\n",
      " [ 0.01128329]\n",
      " [ 0.02115649]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49769706]\n",
      " [0.50128348]\n",
      " [0.50282079]\n",
      " [0.50528893]]\n",
      "Error [[-0.49769706]\n",
      " [ 0.49871652]\n",
      " [ 0.49717921]\n",
      " [-0.50528893]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2348989  0.91300557]\n",
      " [0.83098167 1.33818152]\n",
      " [0.98696443 1.08344353]\n",
      " [1.58304721 1.50861947]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55845618 0.7136148 ]\n",
      " [0.69656246 0.79219073]\n",
      " [0.72848792 0.74714509]\n",
      " [0.82963564 0.81885652]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00925467]\n",
      " [ 0.00513246]\n",
      " [ 0.01129368]\n",
      " [ 0.02119536]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49768635]\n",
      " [0.50128311]\n",
      " [0.50282339]\n",
      " [0.50529864]]\n",
      "Error [[-0.49768635]\n",
      " [ 0.49871689]\n",
      " [ 0.49717661]\n",
      " [-0.50529864]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23493007 0.91300628]\n",
      " [0.83112309 1.33817419]\n",
      " [0.98708291 1.08342295]\n",
      " [1.58327592 1.50859086]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55846387 0.71361495]\n",
      " [0.69659235 0.79218953]\n",
      " [0.72851136 0.7471412 ]\n",
      " [0.82966797 0.81885228]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00929753]\n",
      " [ 0.00513099]\n",
      " [ 0.01130407]\n",
      " [ 0.02123424]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49767564]\n",
      " [0.50128274]\n",
      " [0.50282599]\n",
      " [0.50530836]]\n",
      "Error [[-0.49767564]\n",
      " [ 0.49871726]\n",
      " [ 0.49717401]\n",
      " [-0.50530836]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23496133 0.91300698]\n",
      " [0.83126486 1.33816686]\n",
      " [0.98720168 1.08340234]\n",
      " [1.58350521 1.50856222]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55847158 0.71361509]\n",
      " [0.69662231 0.79218832]\n",
      " [0.72853485 0.7471373 ]\n",
      " [0.82970037 0.81884803]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00934039]\n",
      " [ 0.00512953]\n",
      " [ 0.01131448]\n",
      " [ 0.02127315]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49766492]\n",
      " [0.50128238]\n",
      " [0.50282859]\n",
      " [0.50531809]]\n",
      "Error [[-0.49766492]\n",
      " [ 0.49871762]\n",
      " [ 0.49717141]\n",
      " [-0.50531809]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23499266 0.91300769]\n",
      " [0.83140698 1.33815953]\n",
      " [0.98732075 1.08338171]\n",
      " [1.58373507 1.50853355]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5584793  0.71361523]\n",
      " [0.69665235 0.79218711]\n",
      " [0.7285584  0.74713341]\n",
      " [0.82973285 0.81884378]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00938328]\n",
      " [ 0.00512808]\n",
      " [ 0.0113249 ]\n",
      " [ 0.02131208]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4976542 ]\n",
      " [0.50128202]\n",
      " [0.50283119]\n",
      " [0.50532782]]\n",
      "Error [[-0.4976542 ]\n",
      " [ 0.49871798]\n",
      " [ 0.49716881]\n",
      " [-0.50532782]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23502407 0.91300839]\n",
      " [0.83154946 1.33815218]\n",
      " [0.98744013 1.08336106]\n",
      " [1.58396552 1.50850485]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55848705 0.71361538]\n",
      " [0.69668245 0.7921859 ]\n",
      " [0.728582   0.7471295 ]\n",
      " [0.8297654  0.81883952]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00942618]\n",
      " [ 0.00512664]\n",
      " [ 0.01133532]\n",
      " [ 0.02135103]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49764347]\n",
      " [0.50128166]\n",
      " [0.5028338 ]\n",
      " [0.50533756]]\n",
      "Error [[-0.49764347]\n",
      " [ 0.49871834]\n",
      " [ 0.4971662 ]\n",
      " [-0.50533756]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23505556 0.9130091 ]\n",
      " [0.83169229 1.33814483]\n",
      " [0.9875598  1.08334038]\n",
      " [1.58419653 1.50847611]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55849481 0.71361552]\n",
      " [0.69671264 0.79218469]\n",
      " [0.72860567 0.7471256 ]\n",
      " [0.82979803 0.81883526]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00946909]\n",
      " [ 0.00512521]\n",
      " [ 0.01134576]\n",
      " [ 0.02139001]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49763275]\n",
      " [0.5012813 ]\n",
      " [0.50283641]\n",
      " [0.5053473 ]]\n",
      "Error [[-0.49763275]\n",
      " [ 0.4987187 ]\n",
      " [ 0.49716359]\n",
      " [-0.5053473 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23508713 0.91300981]\n",
      " [0.83183548 1.33813747]\n",
      " [0.98767977 1.08331967]\n",
      " [1.58442813 1.50844734]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5585026  0.71361567]\n",
      " [0.69674289 0.79218348]\n",
      " [0.72862939 0.74712169]\n",
      " [0.82983074 0.81883099]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00951202]\n",
      " [ 0.0051238 ]\n",
      " [ 0.01135621]\n",
      " [ 0.021429  ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49762201]\n",
      " [0.50128095]\n",
      " [0.50283902]\n",
      " [0.50535705]]\n",
      "Error [[-0.49762201]\n",
      " [ 0.49871905]\n",
      " [ 0.49716098]\n",
      " [-0.50535705]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23511877 0.91301052]\n",
      " [0.83197902 1.33813011]\n",
      " [0.98780005 1.08329894]\n",
      " [1.5846603  1.50841854]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5585104  0.71361581]\n",
      " [0.69677322 0.79218227]\n",
      " [0.72865317 0.74711777]\n",
      " [0.82986352 0.81882672]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00955497]\n",
      " [ 0.00512239]\n",
      " [ 0.01136666]\n",
      " [ 0.02146802]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49761128]\n",
      " [0.5012806 ]\n",
      " [0.50284164]\n",
      " [0.5053668 ]]\n",
      "Error [[-0.49761128]\n",
      " [ 0.4987194 ]\n",
      " [ 0.49715836]\n",
      " [-0.5053668 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23515049 0.91301122]\n",
      " [0.83212292 1.33812273]\n",
      " [0.98792062 1.08327819]\n",
      " [1.58489305 1.5083897 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55851822 0.71361596]\n",
      " [0.69680362 0.79218106]\n",
      " [0.72867701 0.74711385]\n",
      " [0.82989638 0.81882244]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00959793]\n",
      " [ 0.005121  ]\n",
      " [ 0.01137713]\n",
      " [ 0.02150706]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49760054]\n",
      " [0.50128025]\n",
      " [0.50284425]\n",
      " [0.50537656]]\n",
      "Error [[-0.49760054]\n",
      " [ 0.49871975]\n",
      " [ 0.49715575]\n",
      " [-0.50537656]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23518229 0.91301193]\n",
      " [0.83226718 1.33811535]\n",
      " [0.9880415  1.08325741]\n",
      " [1.58512638 1.50836083]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55852606 0.7136161 ]\n",
      " [0.6968341  0.79217984]\n",
      " [0.72870091 0.74710992]\n",
      " [0.82992931 0.81881816]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00964091]\n",
      " [ 0.00511962]\n",
      " [ 0.01138761]\n",
      " [ 0.02154612]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49758979]\n",
      " [0.5012799 ]\n",
      " [0.50284687]\n",
      " [0.50538632]]\n",
      "Error [[-0.49758979]\n",
      " [ 0.4987201 ]\n",
      " [ 0.49715313]\n",
      " [-0.50538632]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23521417 0.91301264]\n",
      " [0.83241179 1.33810797]\n",
      " [0.98816267 1.08323661]\n",
      " [1.58536029 1.50833193]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55853392 0.71361625]\n",
      " [0.69686465 0.79217863]\n",
      " [0.72872486 0.74710599]\n",
      " [0.82996233 0.81881387]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00968391]\n",
      " [ 0.00511825]\n",
      " [ 0.0113981 ]\n",
      " [ 0.0215852 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49757904]\n",
      " [0.50127956]\n",
      " [0.50284949]\n",
      " [0.50539609]]\n",
      "Error [[-0.49757904]\n",
      " [ 0.49872044]\n",
      " [ 0.49715051]\n",
      " [-0.50539609]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23524613 0.91301335]\n",
      " [0.83255676 1.33810057]\n",
      " [0.98828414 1.08321578]\n",
      " [1.58559477 1.508303  ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5585418  0.71361639]\n",
      " [0.69689527 0.79217741]\n",
      " [0.72874888 0.74710206]\n",
      " [0.82999542 0.81880958]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00972692]\n",
      " [ 0.00511689]\n",
      " [ 0.0114086 ]\n",
      " [ 0.02162431]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49756829]\n",
      " [0.50127922]\n",
      " [0.50285212]\n",
      " [0.50540587]]\n",
      "Error [[-0.49756829]\n",
      " [ 0.49872078]\n",
      " [ 0.49714788]\n",
      " [-0.50540587]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23527816 0.91301406]\n",
      " [0.83270208 1.33809317]\n",
      " [0.98840592 1.08319493]\n",
      " [1.58582984 1.50827404]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5585497  0.71361654]\n",
      " [0.69692597 0.79217619]\n",
      " [0.72877295 0.74709812]\n",
      " [0.83002858 0.81880528]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00976995]\n",
      " [ 0.00511554]\n",
      " [ 0.01141911]\n",
      " [ 0.02166344]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49755753]\n",
      " [0.50127888]\n",
      " [0.50285475]\n",
      " [0.50541565]]\n",
      "Error [[-0.49755753]\n",
      " [ 0.49872112]\n",
      " [ 0.49714525]\n",
      " [-0.50541565]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23531028 0.91301478]\n",
      " [0.83284776 1.33808576]\n",
      " [0.988528   1.08317405]\n",
      " [1.58606548 1.50824504]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55855762 0.71361668]\n",
      " [0.69695674 0.79217497]\n",
      " [0.72879708 0.74709417]\n",
      " [0.83006182 0.81880098]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00981299]\n",
      " [ 0.0051142 ]\n",
      " [ 0.01142963]\n",
      " [ 0.02170259]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49754677]\n",
      " [0.50127855]\n",
      " [0.50285738]\n",
      " [0.50542543]]\n",
      "Error [[-0.49754677]\n",
      " [ 0.49872145]\n",
      " [ 0.49714262]\n",
      " [-0.50542543]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23534247 0.91301549]\n",
      " [0.8329938  1.33807834]\n",
      " [0.98865038 1.08315315]\n",
      " [1.58630171 1.50821601]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55856556 0.71361683]\n",
      " [0.69698758 0.79217375]\n",
      " [0.72882126 0.74709022]\n",
      " [0.83009514 0.81879667]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00985605]\n",
      " [ 0.00511287]\n",
      " [ 0.01144016]\n",
      " [ 0.02174176]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49753601]\n",
      " [0.50127822]\n",
      " [0.50286001]\n",
      " [0.50543523]]\n",
      "Error [[-0.49753601]\n",
      " [ 0.49872178]\n",
      " [ 0.49713999]\n",
      " [-0.50543523]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23537474 0.9130162 ]\n",
      " [0.83314019 1.33807092]\n",
      " [0.98877306 1.08313222]\n",
      " [1.58653851 1.50818694]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55857351 0.71361697]\n",
      " [0.6970185  0.79217253]\n",
      " [0.72884551 0.74708627]\n",
      " [0.83012854 0.81879236]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00989913]\n",
      " [ 0.00511156]\n",
      " [ 0.0114507 ]\n",
      " [ 0.02178095]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49752524]\n",
      " [0.50127789]\n",
      " [0.50286264]\n",
      " [0.50544502]]\n",
      "Error [[-0.49752524]\n",
      " [ 0.49872211]\n",
      " [ 0.49713736]\n",
      " [-0.50544502]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23540709 0.91301691]\n",
      " [0.83328695 1.33806349]\n",
      " [0.98889604 1.08311127]\n",
      " [1.5867759  1.50815785]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55858149 0.71361712]\n",
      " [0.69704949 0.7921713 ]\n",
      " [0.72886981 0.74708231]\n",
      " [0.83016201 0.81878804]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00994222]\n",
      " [ 0.00511026]\n",
      " [ 0.01146125]\n",
      " [ 0.02182017]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49751446]\n",
      " [0.50127756]\n",
      " [0.50286528]\n",
      " [0.50545483]]\n",
      "Error [[-0.49751446]\n",
      " [ 0.49872244]\n",
      " [ 0.49713472]\n",
      " [-0.50545483]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23543951 0.91301763]\n",
      " [0.83343405 1.33805605]\n",
      " [0.98901932 1.08309029]\n",
      " [1.58701387 1.50812872]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55858948 0.71361727]\n",
      " [0.69708055 0.79217008]\n",
      " [0.72889418 0.74707835]\n",
      " [0.83019556 0.81878372]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.00998533]\n",
      " [ 0.00510896]\n",
      " [ 0.01147181]\n",
      " [ 0.02185941]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49750369]\n",
      " [0.50127724]\n",
      " [0.50286792]\n",
      " [0.50546463]]\n",
      "Error [[-0.49750369]\n",
      " [ 0.49872276]\n",
      " [ 0.49713208]\n",
      " [-0.50546463]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23547202 0.91301834]\n",
      " [0.83358152 1.3380486 ]\n",
      " [0.98914291 1.08306929]\n",
      " [1.58725241 1.50809956]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5585975  0.71361741]\n",
      " [0.69711169 0.79216885]\n",
      " [0.7289186  0.74707438]\n",
      " [0.83022919 0.81877939]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01002846]\n",
      " [ 0.00510768]\n",
      " [ 0.01148238]\n",
      " [ 0.02189867]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49749291]\n",
      " [0.50127692]\n",
      " [0.50287056]\n",
      " [0.50547445]]\n",
      "Error [[-0.49749291]\n",
      " [ 0.49872308]\n",
      " [ 0.49712944]\n",
      " [-0.50547445]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2355046  0.91301905]\n",
      " [0.83372934 1.33804115]\n",
      " [0.9892668  1.08304827]\n",
      " [1.58749154 1.50807036]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55860553 0.71361756]\n",
      " [0.6971429  0.79216762]\n",
      " [0.72894308 0.74707041]\n",
      " [0.83026289 0.81877506]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01007161]\n",
      " [ 0.00510641]\n",
      " [ 0.01149297]\n",
      " [ 0.02193795]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49748212]\n",
      " [0.5012766 ]\n",
      " [0.50287321]\n",
      " [0.50548427]]\n",
      "Error [[-0.49748212]\n",
      " [ 0.4987234 ]\n",
      " [ 0.49712679]\n",
      " [-0.50548427]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23553726 0.91301977]\n",
      " [0.83387753 1.33803369]\n",
      " [0.98939099 1.08302722]\n",
      " [1.58773125 1.50804114]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55861359 0.7136177 ]\n",
      " [0.69717419 0.7921664 ]\n",
      " [0.72896761 0.74706643]\n",
      " [0.83029667 0.81877072]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01011477]\n",
      " [ 0.00510516]\n",
      " [ 0.01150356]\n",
      " [ 0.02197726]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49747133]\n",
      " [0.50127629]\n",
      " [0.50287586]\n",
      " [0.50549409]]\n",
      "Error [[-0.49747133]\n",
      " [ 0.49872371]\n",
      " [ 0.49712414]\n",
      " [-0.50549409]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23557    0.91302049]\n",
      " [0.83402606 1.33802622]\n",
      " [0.98951548 1.08300614]\n",
      " [1.58797155 1.50801188]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55862166 0.71361785]\n",
      " [0.69720555 0.79216517]\n",
      " [0.72899221 0.74706245]\n",
      " [0.83033052 0.81876638]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01015795]\n",
      " [ 0.00510391]\n",
      " [ 0.01151417]\n",
      " [ 0.02201659]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49746053]\n",
      " [0.50127597]\n",
      " [0.50287851]\n",
      " [0.50550393]]\n",
      "Error [[-0.49746053]\n",
      " [ 0.49872403]\n",
      " [ 0.49712149]\n",
      " [-0.50550393]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23560282 0.9130212 ]\n",
      " [0.83417496 1.33801875]\n",
      " [0.98964028 1.08298504]\n",
      " [1.58821242 1.50798258]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55862975 0.713618  ]\n",
      " [0.69723698 0.79216394]\n",
      " [0.72901686 0.74705846]\n",
      " [0.83036445 0.81876203]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01020114]\n",
      " [ 0.00510267]\n",
      " [ 0.01152478]\n",
      " [ 0.02205594]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49744974]\n",
      " [0.50127567]\n",
      " [0.50288116]\n",
      " [0.50551376]]\n",
      "Error [[-0.49744974]\n",
      " [ 0.49872433]\n",
      " [ 0.49711884]\n",
      " [-0.50551376]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23563571 0.91302192]\n",
      " [0.83432422 1.33801127]\n",
      " [0.98976537 1.08296391]\n",
      " [1.58845388 1.50795326]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55863786 0.71361814]\n",
      " [0.69726849 0.7921627 ]\n",
      " [0.72904158 0.74705447]\n",
      " [0.83039846 0.81875768]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01024436]\n",
      " [ 0.00510145]\n",
      " [ 0.01153541]\n",
      " [ 0.02209532]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49743893]\n",
      " [0.50127536]\n",
      " [0.50288382]\n",
      " [0.5055236 ]]\n",
      "Error [[-0.49743893]\n",
      " [ 0.49872464]\n",
      " [ 0.49711618]\n",
      " [-0.5055236 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23566869 0.91302264]\n",
      " [0.83447383 1.33800378]\n",
      " [0.98989078 1.08294276]\n",
      " [1.58869592 1.5079239 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55864599 0.71361829]\n",
      " [0.69730007 0.79216147]\n",
      " [0.72906635 0.74705047]\n",
      " [0.83043255 0.81875333]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01028759]\n",
      " [ 0.00510024]\n",
      " [ 0.01154604]\n",
      " [ 0.02213472]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49742813]\n",
      " [0.50127506]\n",
      " [0.50288648]\n",
      " [0.50553345]]\n",
      "Error [[-0.49742813]\n",
      " [ 0.49872494]\n",
      " [ 0.49711352]\n",
      " [-0.50553345]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23570174 0.91302335]\n",
      " [0.83462381 1.33799628]\n",
      " [0.99001648 1.08292158]\n",
      " [1.58893855 1.50789451]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55865414 0.71361844]\n",
      " [0.69733172 0.79216024]\n",
      " [0.72909118 0.74704647]\n",
      " [0.83046671 0.81874896]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01033083]\n",
      " [ 0.00509904]\n",
      " [ 0.01155669]\n",
      " [ 0.02217414]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49741731]\n",
      " [0.50127476]\n",
      " [0.50288914]\n",
      " [0.50554331]]\n",
      "Error [[-0.49741731]\n",
      " [ 0.49872524]\n",
      " [ 0.49711086]\n",
      " [-0.50554331]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23573487 0.91302407]\n",
      " [0.83477414 1.33798878]\n",
      " [0.99014249 1.08290038]\n",
      " [1.58918176 1.50786509]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55866231 0.71361858]\n",
      " [0.69736345 0.792159  ]\n",
      " [0.72911607 0.74704246]\n",
      " [0.83050095 0.8187446 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0103741 ]\n",
      " [ 0.00509785]\n",
      " [ 0.01156735]\n",
      " [ 0.02221358]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4974065 ]\n",
      " [0.50127446]\n",
      " [0.5028918 ]\n",
      " [0.50555317]]\n",
      "Error [[-0.4974065 ]\n",
      " [ 0.49872554]\n",
      " [ 0.4971082 ]\n",
      " [-0.50555317]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23576808 0.91302479]\n",
      " [0.83492483 1.33798127]\n",
      " [0.9902688  1.08287916]\n",
      " [1.58942555 1.50783563]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5586705  0.71361873]\n",
      " [0.69739525 0.79215777]\n",
      " [0.72914101 0.74703845]\n",
      " [0.83053527 0.81874023]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01041738]\n",
      " [ 0.00509667]\n",
      " [ 0.01157802]\n",
      " [ 0.02225305]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49739568]\n",
      " [0.50127416]\n",
      " [0.50289447]\n",
      " [0.50556303]]\n",
      "Error [[-0.49739568]\n",
      " [ 0.49872584]\n",
      " [ 0.49710553]\n",
      " [-0.50556303]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23580137 0.91302551]\n",
      " [0.83507588 1.33797375]\n",
      " [0.99039542 1.0828579 ]\n",
      " [1.58966993 1.50780614]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5586787  0.71361888]\n",
      " [0.69742713 0.79215653]\n",
      " [0.72916602 0.74703443]\n",
      " [0.83056966 0.81873585]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01046068]\n",
      " [ 0.0050955 ]\n",
      " [ 0.0115887 ]\n",
      " [ 0.02229254]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49738485]\n",
      " [0.50127387]\n",
      " [0.50289714]\n",
      " [0.5055729 ]]\n",
      "Error [[-0.49738485]\n",
      " [ 0.49872613]\n",
      " [ 0.49710286]\n",
      " [-0.5055729 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23583474 0.91302623]\n",
      " [0.83522729 1.33796622]\n",
      " [0.99052234 1.08283663]\n",
      " [1.58991489 1.50777662]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55868693 0.71361902]\n",
      " [0.69745908 0.79215529]\n",
      " [0.72919108 0.74703041]\n",
      " [0.83060413 0.81873147]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.010504  ]\n",
      " [ 0.00509435]\n",
      " [ 0.01159939]\n",
      " [ 0.02233205]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49737402]\n",
      " [0.50127358]\n",
      " [0.50289981]\n",
      " [0.50558278]]\n",
      "Error [[-0.49737402]\n",
      " [ 0.49872642]\n",
      " [ 0.49710019]\n",
      " [-0.50558278]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23586818 0.91302695]\n",
      " [0.83537906 1.33795869]\n",
      " [0.99064956 1.08281533]\n",
      " [1.59016044 1.50774706]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55869518 0.71361917]\n",
      " [0.6974911  0.79215405]\n",
      " [0.7292162  0.74702639]\n",
      " [0.83063867 0.81872708]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01054733]\n",
      " [ 0.0050932 ]\n",
      " [ 0.01161009]\n",
      " [ 0.02237159]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49736319]\n",
      " [0.5012733 ]\n",
      " [0.50290249]\n",
      " [0.50559266]]\n",
      "Error [[-0.49736319]\n",
      " [ 0.4987267 ]\n",
      " [ 0.49709751]\n",
      " [-0.50559266]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23590171 0.91302767]\n",
      " [0.83553119 1.33795115]\n",
      " [0.99077709 1.082794  ]\n",
      " [1.59040658 1.50771747]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55870344 0.71361932]\n",
      " [0.6975232  0.79215281]\n",
      " [0.72924138 0.74702236]\n",
      " [0.8306733  0.81872269]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01059069]\n",
      " [ 0.00509207]\n",
      " [ 0.0116208 ]\n",
      " [ 0.02241115]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49735235]\n",
      " [0.50127302]\n",
      " [0.50290517]\n",
      " [0.50560255]]\n",
      "Error [[-0.49735235]\n",
      " [ 0.49872698]\n",
      " [ 0.49709483]\n",
      " [-0.50560255]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23593531 0.9130284 ]\n",
      " [0.83568368 1.3379436 ]\n",
      " [0.99090492 1.08277265]\n",
      " [1.5906533  1.50768785]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55871173 0.71361947]\n",
      " [0.69755537 0.79215156]\n",
      " [0.72926662 0.74701832]\n",
      " [0.830708   0.81871829]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01063406]\n",
      " [ 0.00509095]\n",
      " [ 0.01163152]\n",
      " [ 0.02245073]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49734151]\n",
      " [0.50127274]\n",
      " [0.50290785]\n",
      " [0.50561245]]\n",
      "Error [[-0.49734151]\n",
      " [ 0.49872726]\n",
      " [ 0.49709215]\n",
      " [-0.50561245]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23596899 0.91302912]\n",
      " [0.83583653 1.33793605]\n",
      " [0.99103306 1.08275127]\n",
      " [1.5909006  1.5076582 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55872003 0.71361961]\n",
      " [0.69758762 0.79215032]\n",
      " [0.72929192 0.74701428]\n",
      " [0.83074277 0.81871389]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01067744]\n",
      " [ 0.00508984]\n",
      " [ 0.01164226]\n",
      " [ 0.02249034]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49733066]\n",
      " [0.50127246]\n",
      " [0.50291053]\n",
      " [0.50562235]]\n",
      "Error [[-0.49733066]\n",
      " [ 0.49872754]\n",
      " [ 0.49708947]\n",
      " [-0.50562235]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23600275 0.91302984]\n",
      " [0.83598975 1.33792848]\n",
      " [0.9911615  1.08272987]\n",
      " [1.5911485  1.50762851]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55872836 0.71361976]\n",
      " [0.69761994 0.79214908]\n",
      " [0.72931728 0.74701024]\n",
      " [0.83077763 0.81870949]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01072085]\n",
      " [ 0.00508875]\n",
      " [ 0.011653  ]\n",
      " [ 0.02252997]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49731981]\n",
      " [0.50127218]\n",
      " [0.50291322]\n",
      " [0.50563225]]\n",
      "Error [[-0.49731981]\n",
      " [ 0.49872782]\n",
      " [ 0.49708678]\n",
      " [-0.50563225]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23603659 0.91303057]\n",
      " [0.83614332 1.33792092]\n",
      " [0.99129025 1.08270844]\n",
      " [1.59139698 1.50759879]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5587367  0.71361991]\n",
      " [0.69765233 0.79214783]\n",
      " [0.7293427  0.74700619]\n",
      " [0.83081256 0.81870507]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01076427]\n",
      " [ 0.00508766]\n",
      " [ 0.01166376]\n",
      " [ 0.02256962]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49730896]\n",
      " [0.50127191]\n",
      " [0.50291591]\n",
      " [0.50564217]]\n",
      "Error [[-0.49730896]\n",
      " [ 0.49872809]\n",
      " [ 0.49708409]\n",
      " [-0.50564217]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23607051 0.91303129]\n",
      " [0.83629725 1.33791334]\n",
      " [0.9914193  1.08268699]\n",
      " [1.59164604 1.50756904]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55874506 0.71362006]\n",
      " [0.6976848  0.79214658]\n",
      " [0.72936817 0.74700213]\n",
      " [0.83084756 0.81870066]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01080772]\n",
      " [ 0.00508659]\n",
      " [ 0.01167452]\n",
      " [ 0.0226093 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4972981 ]\n",
      " [0.50127164]\n",
      " [0.5029186 ]\n",
      " [0.50565208]]\n",
      "Error [[-0.4972981 ]\n",
      " [ 0.49872836]\n",
      " [ 0.4970814 ]\n",
      " [-0.50565208]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23610451 0.91303201]\n",
      " [0.83645154 1.33790576]\n",
      " [0.99154866 1.08266551]\n",
      " [1.5918957  1.50753925]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55875344 0.71362021]\n",
      " [0.69771734 0.79214533]\n",
      " [0.7293937  0.74699807]\n",
      " [0.83088265 0.81869624]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01085118]\n",
      " [ 0.00508553]\n",
      " [ 0.0116853 ]\n",
      " [ 0.022649  ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49728723]\n",
      " [0.50127138]\n",
      " [0.50292129]\n",
      " [0.50566201]]\n",
      "Error [[-0.49728723]\n",
      " [ 0.49872862]\n",
      " [ 0.49707871]\n",
      " [-0.50566201]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23613858 0.91303274]\n",
      " [0.8366062  1.33789816]\n",
      " [0.99167833 1.08264401]\n",
      " [1.59214594 1.50750943]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55876185 0.71362035]\n",
      " [0.69774996 0.79214408]\n",
      " [0.7294193  0.74699401]\n",
      " [0.83091781 0.81869181]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01089466]\n",
      " [ 0.00508448]\n",
      " [ 0.01169609]\n",
      " [ 0.02268872]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49727636]\n",
      " [0.50127112]\n",
      " [0.50292399]\n",
      " [0.50567194]]\n",
      "Error [[-0.49727636]\n",
      " [ 0.49872888]\n",
      " [ 0.49707601]\n",
      " [-0.50567194]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23617274 0.91303347]\n",
      " [0.83676122 1.33789057]\n",
      " [0.9918083  1.08262248]\n",
      " [1.59239678 1.50747958]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55877027 0.7136205 ]\n",
      " [0.69778265 0.79214283]\n",
      " [0.72944495 0.74698994]\n",
      " [0.83095305 0.81868738]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01093815]\n",
      " [ 0.00508344]\n",
      " [ 0.01170689]\n",
      " [ 0.02272847]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49726549]\n",
      " [0.50127086]\n",
      " [0.50292669]\n",
      " [0.50568187]]\n",
      "Error [[-0.49726549]\n",
      " [ 0.49872914]\n",
      " [ 0.49707331]\n",
      " [-0.50568187]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23620697 0.91303419]\n",
      " [0.83691659 1.33788296]\n",
      " [0.99193857 1.08260092]\n",
      " [1.5926482  1.50744969]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55877871 0.71362065]\n",
      " [0.69781542 0.79214158]\n",
      " [0.72947066 0.74698587]\n",
      " [0.83098836 0.81868294]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01098167]\n",
      " [ 0.00508241]\n",
      " [ 0.0117177 ]\n",
      " [ 0.02276824]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49725461]\n",
      " [0.5012706 ]\n",
      " [0.50292939]\n",
      " [0.50569181]]\n",
      "Error [[-0.49725461]\n",
      " [ 0.4987294 ]\n",
      " [ 0.49707061]\n",
      " [-0.50569181]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23624128 0.91303492]\n",
      " [0.83707233 1.33787535]\n",
      " [0.99206916 1.08257934]\n",
      " [1.59290021 1.50741977]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55878717 0.7136208 ]\n",
      " [0.69784826 0.79214033]\n",
      " [0.72949643 0.74698179]\n",
      " [0.83102375 0.8186785 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0110252 ]\n",
      " [ 0.0050814 ]\n",
      " [ 0.01172852]\n",
      " [ 0.02280803]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49724373]\n",
      " [0.50127035]\n",
      " [0.5029321 ]\n",
      " [0.50570176]]\n",
      "Error [[-0.49724373]\n",
      " [ 0.49872965]\n",
      " [ 0.4970679 ]\n",
      " [-0.50570176]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23627567 0.91303565]\n",
      " [0.83722844 1.33786773]\n",
      " [0.99220004 1.08255774]\n",
      " [1.59315281 1.50738982]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55879564 0.71362095]\n",
      " [0.69788117 0.79213907]\n",
      " [0.72952225 0.74697771]\n",
      " [0.83105922 0.81867406]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01106875]\n",
      " [ 0.00508039]\n",
      " [ 0.01173935]\n",
      " [ 0.02284785]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49723284]\n",
      " [0.5012701 ]\n",
      " [0.5029348 ]\n",
      " [0.50571171]]\n",
      "Error [[-0.49723284]\n",
      " [ 0.4987299 ]\n",
      " [ 0.4970652 ]\n",
      " [-0.50571171]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23631014 0.91303638]\n",
      " [0.8373849  1.3378601 ]\n",
      " [0.99233124 1.08253611]\n",
      " [1.593406   1.50735983]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55880414 0.7136211 ]\n",
      " [0.69791416 0.79213782]\n",
      " [0.72954814 0.74697362]\n",
      " [0.83109476 0.8186696 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01111232]\n",
      " [ 0.0050794 ]\n",
      " [ 0.01175019]\n",
      " [ 0.02288769]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49722195]\n",
      " [0.50126985]\n",
      " [0.50293751]\n",
      " [0.50572167]]\n",
      "Error [[-0.49722195]\n",
      " [ 0.49873015]\n",
      " [ 0.49706249]\n",
      " [-0.50572167]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23634469 0.91303711]\n",
      " [0.83754173 1.33785247]\n",
      " [0.99246274 1.08251445]\n",
      " [1.59365978 1.50732982]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55881266 0.71362125]\n",
      " [0.69794722 0.79213656]\n",
      " [0.72957409 0.74696953]\n",
      " [0.83113039 0.81866515]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01115591]\n",
      " [ 0.00507842]\n",
      " [ 0.01176105]\n",
      " [ 0.02292756]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49721105]\n",
      " [0.5012696 ]\n",
      " [0.50294023]\n",
      " [0.50573164]]\n",
      "Error [[-0.49721105]\n",
      " [ 0.4987304 ]\n",
      " [ 0.49705977]\n",
      " [-0.50573164]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23637932 0.91303783]\n",
      " [0.83769892 1.33784483]\n",
      " [0.99259455 1.08249277]\n",
      " [1.59391415 1.50729976]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5588212  0.7136214 ]\n",
      " [0.69798036 0.7921353 ]\n",
      " [0.72960009 0.74696543]\n",
      " [0.83116608 0.81866069]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01119952]\n",
      " [ 0.00507745]\n",
      " [ 0.01177191]\n",
      " [ 0.02296745]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49720015]\n",
      " [0.50126936]\n",
      " [0.50294294]\n",
      " [0.50574161]]\n",
      "Error [[-0.49720015]\n",
      " [ 0.49873064]\n",
      " [ 0.49705706]\n",
      " [-0.50574161]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23641403 0.91303856]\n",
      " [0.83785647 1.33783718]\n",
      " [0.99272667 1.08247107]\n",
      " [1.59416911 1.50726968]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55882975 0.71362154]\n",
      " [0.69801357 0.79213404]\n",
      " [0.72962615 0.74696133]\n",
      " [0.83120186 0.81865622]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01124315]\n",
      " [ 0.0050765 ]\n",
      " [ 0.01178279]\n",
      " [ 0.02300737]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49718924]\n",
      " [0.50126912]\n",
      " [0.50294566]\n",
      " [0.50575159]]\n",
      "Error [[-0.49718924]\n",
      " [ 0.49873088]\n",
      " [ 0.49705434]\n",
      " [-0.50575159]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23644882 0.9130393 ]\n",
      " [0.83801439 1.33782952]\n",
      " [0.99285909 1.08244934]\n",
      " [1.59442466 1.50723956]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55883833 0.71362169]\n",
      " [0.69804686 0.79213278]\n",
      " [0.72965228 0.74695722]\n",
      " [0.83123771 0.81865175]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01128679]\n",
      " [ 0.00507555]\n",
      " [ 0.01179368]\n",
      " [ 0.0230473 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49717833]\n",
      " [0.50126889]\n",
      " [0.50294839]\n",
      " [0.50576157]]\n",
      "Error [[-0.49717833]\n",
      " [ 0.49873111]\n",
      " [ 0.49705161]\n",
      " [-0.50576157]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23648368 0.91304003]\n",
      " [0.83817267 1.33782186]\n",
      " [0.99299182 1.08242758]\n",
      " [1.59468081 1.50720941]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55884693 0.71362184]\n",
      " [0.69808022 0.79213152]\n",
      " [0.72967846 0.74695311]\n",
      " [0.83127364 0.81864727]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01133046]\n",
      " [ 0.00507462]\n",
      " [ 0.01180458]\n",
      " [ 0.02308727]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49716742]\n",
      " [0.50126865]\n",
      " [0.50295111]\n",
      " [0.50577156]]\n",
      "Error [[-0.49716742]\n",
      " [ 0.49873135]\n",
      " [ 0.49704889]\n",
      " [-0.50577156]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23651863 0.91304076]\n",
      " [0.83833131 1.33781419]\n",
      " [0.99312486 1.0824058 ]\n",
      " [1.59493755 1.50717923]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55885554 0.71362199]\n",
      " [0.69811365 0.79213026]\n",
      " [0.7297047  0.74694899]\n",
      " [0.83130965 0.81864279]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01137414]\n",
      " [ 0.0050737 ]\n",
      " [ 0.01181549]\n",
      " [ 0.02312725]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4971565 ]\n",
      " [0.50126842]\n",
      " [0.50295384]\n",
      " [0.50578156]]\n",
      "Error [[-0.4971565 ]\n",
      " [ 0.49873158]\n",
      " [ 0.49704616]\n",
      " [-0.50578156]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23655365 0.91304149]\n",
      " [0.83849031 1.33780651]\n",
      " [0.99325821 1.08238399]\n",
      " [1.59519488 1.50714901]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55886418 0.71362214]\n",
      " [0.69814716 0.79212899]\n",
      " [0.729731   0.74694487]\n",
      " [0.83134573 0.81863831]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01141784]\n",
      " [ 0.00507279]\n",
      " [ 0.01182641]\n",
      " [ 0.02316727]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49714557]\n",
      " [0.5012682 ]\n",
      " [0.50295657]\n",
      " [0.50579156]]\n",
      "Error [[-0.49714557]\n",
      " [ 0.4987318 ]\n",
      " [ 0.49704343]\n",
      " [-0.50579156]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23658875 0.91304222]\n",
      " [0.83864968 1.33779882]\n",
      " [0.99339187 1.08236216]\n",
      " [1.5954528  1.50711876]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55887283 0.71362229]\n",
      " [0.69818075 0.79212773]\n",
      " [0.72975736 0.74694074]\n",
      " [0.83138189 0.81863381]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01146156]\n",
      " [ 0.0050719 ]\n",
      " [ 0.01183734]\n",
      " [ 0.0232073 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49713464]\n",
      " [0.50126797]\n",
      " [0.5029593 ]\n",
      " [0.50580157]]\n",
      "Error [[-0.49713464]\n",
      " [ 0.49873203]\n",
      " [ 0.4970407 ]\n",
      " [-0.50580157]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23662393 0.91304296]\n",
      " [0.83880942 1.33779113]\n",
      " [0.99352583 1.0823403 ]\n",
      " [1.59571132 1.50708847]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5588815  0.71362244]\n",
      " [0.69821441 0.79212646]\n",
      " [0.72978378 0.74693661]\n",
      " [0.83141813 0.81862932]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0115053 ]\n",
      " [ 0.00507101]\n",
      " [ 0.01184828]\n",
      " [ 0.02324736]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49712371]\n",
      " [0.50126775]\n",
      " [0.50296204]\n",
      " [0.50581158]]\n",
      "Error [[-0.49712371]\n",
      " [ 0.49873225]\n",
      " [ 0.49703796]\n",
      " [-0.50581158]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23665919 0.91304369]\n",
      " [0.83896952 1.33778343]\n",
      " [0.9936601  1.08231841]\n",
      " [1.59597043 1.50705815]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5588902  0.71362259]\n",
      " [0.69824814 0.79212519]\n",
      " [0.72981025 0.74693247]\n",
      " [0.83145444 0.81862482]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01154906]\n",
      " [ 0.00507014]\n",
      " [ 0.01185924]\n",
      " [ 0.02328745]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49711277]\n",
      " [0.50126753]\n",
      " [0.50296477]\n",
      " [0.5058216 ]]\n",
      "Error [[-0.49711277]\n",
      " [ 0.49873247]\n",
      " [ 0.49703523]\n",
      " [-0.5058216 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23669454 0.91304443]\n",
      " [0.83912998 1.33777573]\n",
      " [0.99379468 1.0822965 ]\n",
      " [1.59623013 1.5070278 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55889891 0.71362274]\n",
      " [0.69828195 0.79212392]\n",
      " [0.72983679 0.74692833]\n",
      " [0.83149083 0.81862031]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01159284]\n",
      " [ 0.00506928]\n",
      " [ 0.0118702 ]\n",
      " [ 0.02332756]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49710182]\n",
      " [0.50126732]\n",
      " [0.50296752]\n",
      " [0.50583162]]\n",
      "Error [[-0.49710182]\n",
      " [ 0.49873268]\n",
      " [ 0.49703248]\n",
      " [-0.50583162]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23672996 0.91304516]\n",
      " [0.83929081 1.33776801]\n",
      " [0.99392957 1.08227457]\n",
      " [1.59649043 1.50699742]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55890764 0.71362289]\n",
      " [0.69831583 0.79212265]\n",
      " [0.72986339 0.74692418]\n",
      " [0.8315273  0.8186158 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01163664]\n",
      " [ 0.00506843]\n",
      " [ 0.01188118]\n",
      " [ 0.02336769]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49709087]\n",
      " [0.50126711]\n",
      " [0.50297026]\n",
      " [0.50584166]]\n",
      "Error [[-0.49709087]\n",
      " [ 0.49873289]\n",
      " [ 0.49702974]\n",
      " [-0.50584166]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23676545 0.9130459 ]\n",
      " [0.839452   1.33776029]\n",
      " [0.99406477 1.08225261]\n",
      " [1.59675132 1.506967  ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55891639 0.71362304]\n",
      " [0.69834979 0.79212138]\n",
      " [0.72989004 0.74692003]\n",
      " [0.83156385 0.81861128]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01168046]\n",
      " [ 0.0050676 ]\n",
      " [ 0.01189217]\n",
      " [ 0.02340785]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49707992]\n",
      " [0.5012669 ]\n",
      " [0.50297301]\n",
      " [0.50585169]]\n",
      "Error [[-0.49707992]\n",
      " [ 0.4987331 ]\n",
      " [ 0.49702699]\n",
      " [-0.50585169]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23680103 0.91304664]\n",
      " [0.83961356 1.33775256]\n",
      " [0.99420028 1.08223062]\n",
      " [1.59701281 1.50693655]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55892516 0.71362319]\n",
      " [0.69838382 0.79212011]\n",
      " [0.72991676 0.74691588]\n",
      " [0.83160047 0.81860676]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0117243 ]\n",
      " [ 0.00506677]\n",
      " [ 0.01190317]\n",
      " [ 0.02344803]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49706896]\n",
      " [0.50126669]\n",
      " [0.50297576]\n",
      " [0.50586174]]\n",
      "Error [[-0.49706896]\n",
      " [ 0.49873331]\n",
      " [ 0.49702424]\n",
      " [-0.50586174]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23683669 0.91304737]\n",
      " [0.83977548 1.33774483]\n",
      " [0.9943361  1.08220861]\n",
      " [1.59727489 1.50690606]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55893395 0.71362334]\n",
      " [0.69841793 0.79211883]\n",
      " [0.72994353 0.74691171]\n",
      " [0.83163717 0.81860223]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01176816]\n",
      " [ 0.00506596]\n",
      " [ 0.01191418]\n",
      " [ 0.02348824]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49705799]\n",
      " [0.50126649]\n",
      " [0.50297851]\n",
      " [0.50587179]]\n",
      "Error [[-0.49705799]\n",
      " [ 0.49873351]\n",
      " [ 0.49702149]\n",
      " [-0.50587179]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23687243 0.91304811]\n",
      " [0.83993777 1.33773708]\n",
      " [0.99447223 1.08218657]\n",
      " [1.59753757 1.50687554]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55894276 0.7136235 ]\n",
      " [0.69845211 0.79211756]\n",
      " [0.72997037 0.74690755]\n",
      " [0.83167395 0.8185977 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01181203]\n",
      " [ 0.00506516]\n",
      " [ 0.01192521]\n",
      " [ 0.02352847]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49704703]\n",
      " [0.50126629]\n",
      " [0.50298127]\n",
      " [0.50588185]]\n",
      "Error [[-0.49704703]\n",
      " [ 0.49873371]\n",
      " [ 0.49701873]\n",
      " [-0.50588185]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23690824 0.91304885]\n",
      " [0.84010043 1.33772933]\n",
      " [0.99460867 1.08216451]\n",
      " [1.59780085 1.50684499]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55895159 0.71362365]\n",
      " [0.69848637 0.79211628]\n",
      " [0.72999726 0.74690338]\n",
      " [0.8317108  0.81859316]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01185593]\n",
      " [ 0.00506438]\n",
      " [ 0.01193624]\n",
      " [ 0.02356873]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49703605]\n",
      " [0.50126609]\n",
      " [0.50298402]\n",
      " [0.50589191]]\n",
      "Error [[-0.49703605]\n",
      " [ 0.49873391]\n",
      " [ 0.49701598]\n",
      " [-0.50589191]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23694414 0.91304959]\n",
      " [0.84026345 1.33772158]\n",
      " [0.99474542 1.08214242]\n",
      " [1.59806472 1.50681441]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55896044 0.7136238 ]\n",
      " [0.6985207  0.79211501]\n",
      " [0.73002421 0.7468992 ]\n",
      " [0.83174773 0.81858862]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01189985]\n",
      " [ 0.0050636 ]\n",
      " [ 0.01194729]\n",
      " [ 0.02360901]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49702507]\n",
      " [0.5012659 ]\n",
      " [0.50298679]\n",
      " [0.50590198]]\n",
      "Error [[-0.49702507]\n",
      " [ 0.4987341 ]\n",
      " [ 0.49701321]\n",
      " [-0.50590198]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23698012 0.91305033]\n",
      " [0.84042683 1.33771381]\n",
      " [0.99488247 1.0821203 ]\n",
      " [1.59832919 1.50678379]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55896931 0.71362395]\n",
      " [0.6985551  0.79211373]\n",
      " [0.73005122 0.74689502]\n",
      " [0.83178474 0.81858408]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01194378]\n",
      " [ 0.00506284]\n",
      " [ 0.01195834]\n",
      " [ 0.02364932]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49701409]\n",
      " [0.50126571]\n",
      " [0.50298955]\n",
      " [0.50591205]]\n",
      "Error [[-0.49701409]\n",
      " [ 0.49873429]\n",
      " [ 0.49701045]\n",
      " [-0.50591205]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23701617 0.91305107]\n",
      " [0.84059059 1.33770604]\n",
      " [0.99501984 1.08209816]\n",
      " [1.59859426 1.50675313]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5589782  0.7136241 ]\n",
      " [0.69858959 0.79211245]\n",
      " [0.73007829 0.74689084]\n",
      " [0.83182182 0.81857952]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01198774]\n",
      " [ 0.00506209]\n",
      " [ 0.01196941]\n",
      " [ 0.02368965]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4970031 ]\n",
      " [0.50126552]\n",
      " [0.50299232]\n",
      " [0.50592214]]\n",
      "Error [[-0.4970031 ]\n",
      " [ 0.49873448]\n",
      " [ 0.49700768]\n",
      " [-0.50592214]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23705231 0.91305181]\n",
      " [0.8407547  1.33769826]\n",
      " [0.99515752 1.082076  ]\n",
      " [1.59885992 1.50672245]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55898711 0.71362425]\n",
      " [0.69862414 0.79211117]\n",
      " [0.73010543 0.74688665]\n",
      " [0.83185898 0.81857497]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01203172]\n",
      " [ 0.00506135]\n",
      " [ 0.01198049]\n",
      " [ 0.02373001]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49699211]\n",
      " [0.50126533]\n",
      " [0.50299509]\n",
      " [0.50593222]]\n",
      "Error [[-0.49699211]\n",
      " [ 0.49873467]\n",
      " [ 0.49700491]\n",
      " [-0.50593222]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23708852 0.91305255]\n",
      " [0.84091919 1.33769048]\n",
      " [0.99529551 1.0820538 ]\n",
      " [1.59912618 1.50669173]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55899604 0.7136244 ]\n",
      " [0.69865877 0.79210988]\n",
      " [0.73013262 0.74688245]\n",
      " [0.83189622 0.8185704 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01207571]\n",
      " [ 0.00506062]\n",
      " [ 0.01199158]\n",
      " [ 0.02377039]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49698111]\n",
      " [0.50126515]\n",
      " [0.50299786]\n",
      " [0.50594232]]\n",
      "Error [[-0.49698111]\n",
      " [ 0.49873485]\n",
      " [ 0.49700214]\n",
      " [-0.50594232]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23712481 0.91305329]\n",
      " [0.84108404 1.33768268]\n",
      " [0.99543382 1.08203159]\n",
      " [1.59939305 1.50666098]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55900498 0.71362455]\n",
      " [0.69869348 0.7921086 ]\n",
      " [0.73015987 0.74687825]\n",
      " [0.83193354 0.81856584]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01211973]\n",
      " [ 0.00505991]\n",
      " [ 0.01200269]\n",
      " [ 0.0238108 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4969701 ]\n",
      " [0.50126497]\n",
      " [0.50300064]\n",
      " [0.50595242]]\n",
      "Error [[-0.4969701 ]\n",
      " [ 0.49873503]\n",
      " [ 0.49699936]\n",
      " [-0.50595242]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23716119 0.91305404]\n",
      " [0.84124926 1.33767488]\n",
      " [0.99557243 1.08200934]\n",
      " [1.59966051 1.50663019]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55901395 0.71362471]\n",
      " [0.69872826 0.79210732]\n",
      " [0.73018718 0.74687404]\n",
      " [0.83197093 0.81856126]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01216377]\n",
      " [ 0.00505921]\n",
      " [ 0.0120138 ]\n",
      " [ 0.02385123]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4969591 ]\n",
      " [0.5012648 ]\n",
      " [0.50300341]\n",
      " [0.50596253]]\n",
      "Error [[-0.4969591 ]\n",
      " [ 0.4987352 ]\n",
      " [ 0.49699659]\n",
      " [-0.50596253]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23719764 0.91305478]\n",
      " [0.84141485 1.33766707]\n",
      " [0.99571135 1.08198707]\n",
      " [1.59992857 1.50659937]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55902294 0.71362486]\n",
      " [0.69876312 0.79210603]\n",
      " [0.73021454 0.74686983]\n",
      " [0.8320084  0.81855669]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01220782]\n",
      " [ 0.00505852]\n",
      " [ 0.01202493]\n",
      " [ 0.02389169]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49694808]\n",
      " [0.50126463]\n",
      " [0.5030062 ]\n",
      " [0.50597264]]\n",
      "Error [[-0.49694808]\n",
      " [ 0.49873537]\n",
      " [ 0.4969938 ]\n",
      " [-0.50597264]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23723417 0.91305552]\n",
      " [0.84158081 1.33765926]\n",
      " [0.99585059 1.08196478]\n",
      " [1.60019723 1.50656851]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55903194 0.71362501]\n",
      " [0.69879805 0.79210474]\n",
      " [0.73024197 0.74686562]\n",
      " [0.83204595 0.8185521 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0122519 ]\n",
      " [ 0.00505784]\n",
      " [ 0.01203607]\n",
      " [ 0.02393217]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49693706]\n",
      " [0.50126446]\n",
      " [0.50300898]\n",
      " [0.50598276]]\n",
      "Error [[-0.49693706]\n",
      " [ 0.49873554]\n",
      " [ 0.49699102]\n",
      " [-0.50598276]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23727079 0.91305627]\n",
      " [0.84174713 1.33765144]\n",
      " [0.99599014 1.08194246]\n",
      " [1.60046649 1.50653763]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55904097 0.71362516]\n",
      " [0.69883305 0.79210346]\n",
      " [0.73026946 0.7468614 ]\n",
      " [0.83208357 0.81854752]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.012296  ]\n",
      " [ 0.00505717]\n",
      " [ 0.01204722]\n",
      " [ 0.02397268]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49692604]\n",
      " [0.50126429]\n",
      " [0.50301177]\n",
      " [0.50599288]]\n",
      "Error [[-0.49692604]\n",
      " [ 0.49873571]\n",
      " [ 0.49698823]\n",
      " [-0.50599288]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23730748 0.91305701]\n",
      " [0.84191382 1.33764361]\n",
      " [0.99613    1.08192011]\n",
      " [1.60073635 1.5065067 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55905001 0.71362531]\n",
      " [0.69886814 0.79210217]\n",
      " [0.73029701 0.74685717]\n",
      " [0.83212127 0.81854292]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01234012]\n",
      " [ 0.00505652]\n",
      " [ 0.01205838]\n",
      " [ 0.02401322]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49691501]\n",
      " [0.50126413]\n",
      " [0.50301456]\n",
      " [0.50600302]]\n",
      "Error [[-0.49691501]\n",
      " [ 0.49873587]\n",
      " [ 0.49698544]\n",
      " [-0.50600302]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23734425 0.91305776]\n",
      " [0.84208088 1.33763577]\n",
      " [0.99627017 1.08189774]\n",
      " [1.60100681 1.50647575]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55905908 0.71362547]\n",
      " [0.69890329 0.79210088]\n",
      " [0.73032462 0.74685294]\n",
      " [0.83215905 0.81853833]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01238426]\n",
      " [ 0.00505588]\n",
      " [ 0.01206955]\n",
      " [ 0.02405378]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49690397]\n",
      " [0.50126397]\n",
      " [0.50301735]\n",
      " [0.50601315]]\n",
      "Error [[-0.49690397]\n",
      " [ 0.49873603]\n",
      " [ 0.49698265]\n",
      " [-0.50601315]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2373811  0.91305851]\n",
      " [0.84224831 1.33762793]\n",
      " [0.99641066 1.08187534]\n",
      " [1.60127787 1.50644476]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55906816 0.71362562]\n",
      " [0.69893852 0.79209958]\n",
      " [0.73035229 0.74684871]\n",
      " [0.83219691 0.81853372]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01242842]\n",
      " [ 0.00505525]\n",
      " [ 0.01208073]\n",
      " [ 0.02409436]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49689294]\n",
      " [0.50126381]\n",
      " [0.50302015]\n",
      " [0.5060233 ]]\n",
      "Error [[-0.49689294]\n",
      " [ 0.49873619]\n",
      " [ 0.49697985]\n",
      " [-0.5060233 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23741803 0.91305925]\n",
      " [0.84241611 1.33762008]\n",
      " [0.99655146 1.08185291]\n",
      " [1.60154953 1.50641374]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55907727 0.71362577]\n",
      " [0.69897383 0.79209829]\n",
      " [0.73038001 0.74684447]\n",
      " [0.83223484 0.81852911]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0124726 ]\n",
      " [ 0.00505464]\n",
      " [ 0.01209193]\n",
      " [ 0.02413498]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49688189]\n",
      " [0.50126366]\n",
      " [0.50302295]\n",
      " [0.50603345]]\n",
      "Error [[-0.49688189]\n",
      " [ 0.49873634]\n",
      " [ 0.49697705]\n",
      " [-0.50603345]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23745504 0.91306   ]\n",
      " [0.84258427 1.33761222]\n",
      " [0.99669257 1.08183046]\n",
      " [1.6018218  1.50638268]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55908639 0.71362593]\n",
      " [0.69900921 0.792097  ]\n",
      " [0.7304078  0.74684023]\n",
      " [0.83227285 0.8185245 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0125168 ]\n",
      " [ 0.00505404]\n",
      " [ 0.01210314]\n",
      " [ 0.02417561]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49687084]\n",
      " [0.50126351]\n",
      " [0.50302575]\n",
      " [0.50604361]]\n",
      "Error [[-0.49687084]\n",
      " [ 0.49873649]\n",
      " [ 0.49697425]\n",
      " [-0.50604361]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23749213 0.91306075]\n",
      " [0.84275281 1.33760435]\n",
      " [0.99683399 1.08180799]\n",
      " [1.60209467 1.50635159]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55909553 0.71362608]\n",
      " [0.69904467 0.7920957 ]\n",
      " [0.73043565 0.74683598]\n",
      " [0.83231094 0.81851988]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01256102]\n",
      " [ 0.00505345]\n",
      " [ 0.01211436]\n",
      " [ 0.02421628]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49685979]\n",
      " [0.50126336]\n",
      " [0.50302855]\n",
      " [0.50605377]]\n",
      "Error [[-0.49685979]\n",
      " [ 0.49873664]\n",
      " [ 0.49697145]\n",
      " [-0.50605377]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23752931 0.9130615 ]\n",
      " [0.84292171 1.33759648]\n",
      " [0.99697573 1.08178548]\n",
      " [1.60236814 1.50632047]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5591047  0.71362623]\n",
      " [0.69908021 0.79209441]\n",
      " [0.73046356 0.74683172]\n",
      " [0.83234911 0.81851526]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01260527]\n",
      " [ 0.00505287]\n",
      " [ 0.01212559]\n",
      " [ 0.02425696]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49684872]\n",
      " [0.50126321]\n",
      " [0.50303136]\n",
      " [0.50606394]]\n",
      "Error [[-0.49684872]\n",
      " [ 0.49873679]\n",
      " [ 0.49696864]\n",
      " [-0.50606394]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23756656 0.91306225]\n",
      " [0.84309099 1.3375886 ]\n",
      " [0.99711778 1.08176296]\n",
      " [1.60264222 1.50628931]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55911388 0.71362638]\n",
      " [0.69911581 0.79209311]\n",
      " [0.73049152 0.74682746]\n",
      " [0.83238735 0.81851063]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01264953]\n",
      " [ 0.0050523 ]\n",
      " [ 0.01213683]\n",
      " [ 0.02429768]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49683766]\n",
      " [0.50126307]\n",
      " [0.50303417]\n",
      " [0.50607412]]\n",
      "Error [[-0.49683766]\n",
      " [ 0.49873693]\n",
      " [ 0.49696583]\n",
      " [-0.50607412]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23760389 0.913063  ]\n",
      " [0.84326063 1.33758071]\n",
      " [0.99726015 1.0817404 ]\n",
      " [1.60291689 1.50625812]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55912308 0.71362654]\n",
      " [0.6991515  0.79209181]\n",
      " [0.73051955 0.7468232 ]\n",
      " [0.83242567 0.818506  ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01269382]\n",
      " [ 0.00505175]\n",
      " [ 0.01214809]\n",
      " [ 0.02433842]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49682659]\n",
      " [0.50126293]\n",
      " [0.50303698]\n",
      " [0.5060843 ]]\n",
      "Error [[-0.49682659]\n",
      " [ 0.49873707]\n",
      " [ 0.49696302]\n",
      " [-0.5060843 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2376413  0.91306375]\n",
      " [0.84343064 1.33757282]\n",
      " [0.99740283 1.08171782]\n",
      " [1.60319218 1.50622689]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5591323  0.71362669]\n",
      " [0.69918726 0.79209051]\n",
      " [0.73054764 0.74681893]\n",
      " [0.83246406 0.81850136]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01273813]\n",
      " [ 0.00505121]\n",
      " [ 0.01215935]\n",
      " [ 0.02437919]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49681551]\n",
      " [0.5012628 ]\n",
      " [0.5030398 ]\n",
      " [0.50609449]]\n",
      "Error [[-0.49681551]\n",
      " [ 0.4987372 ]\n",
      " [ 0.4969602 ]\n",
      " [-0.50609449]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23767879 0.9130645 ]\n",
      " [0.84360103 1.33756492]\n",
      " [0.99754582 1.08169521]\n",
      " [1.60346806 1.50619563]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55914154 0.71362684]\n",
      " [0.69922309 0.79208921]\n",
      " [0.73057578 0.74681465]\n",
      " [0.83250254 0.81849672]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01278245]\n",
      " [ 0.00505068]\n",
      " [ 0.01217063]\n",
      " [ 0.02441998]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49680443]\n",
      " [0.50126267]\n",
      " [0.50304262]\n",
      " [0.50610469]]\n",
      "Error [[-0.49680443]\n",
      " [ 0.49873733]\n",
      " [ 0.49695738]\n",
      " [-0.50610469]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23771636 0.91306525]\n",
      " [0.84377178 1.33755701]\n",
      " [0.99768913 1.08167258]\n",
      " [1.60374456 1.50616434]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55915081 0.713627  ]\n",
      " [0.699259   0.79208791]\n",
      " [0.73060399 0.74681037]\n",
      " [0.83254109 0.81849207]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0128268 ]\n",
      " [ 0.00505017]\n",
      " [ 0.01218192]\n",
      " [ 0.0244608 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49679334]\n",
      " [0.50126254]\n",
      " [0.50304544]\n",
      " [0.50611489]]\n",
      "Error [[-0.49679334]\n",
      " [ 0.49873746]\n",
      " [ 0.49695456]\n",
      " [-0.50611489]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23775401 0.913066  ]\n",
      " [0.84394291 1.33754909]\n",
      " [0.99783276 1.08164992]\n",
      " [1.60402165 1.50613301]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55916009 0.71362715]\n",
      " [0.69929499 0.7920866 ]\n",
      " [0.73063226 0.74680609]\n",
      " [0.83257972 0.81848741]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01287118]\n",
      " [ 0.00504967]\n",
      " [ 0.01219323]\n",
      " [ 0.02450164]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49678225]\n",
      " [0.50126241]\n",
      " [0.50304827]\n",
      " [0.5061251 ]]\n",
      "Error [[-0.49678225]\n",
      " [ 0.49873759]\n",
      " [ 0.49695173]\n",
      " [-0.5061251 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23779174 0.91306676]\n",
      " [0.8441144  1.33754117]\n",
      " [0.99797669 1.08162724]\n",
      " [1.60429936 1.50610165]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55916939 0.71362731]\n",
      " [0.69933105 0.7920853 ]\n",
      " [0.73066059 0.7468018 ]\n",
      " [0.83261842 0.81848275]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01291557]\n",
      " [ 0.00504918]\n",
      " [ 0.01220454]\n",
      " [ 0.02454251]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49677115]\n",
      " [0.50126229]\n",
      " [0.5030511 ]\n",
      " [0.50613532]]\n",
      "Error [[-0.49677115]\n",
      " [ 0.49873771]\n",
      " [ 0.4969489 ]\n",
      " [-0.50613532]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23782955 0.91306751]\n",
      " [0.84428627 1.33753324]\n",
      " [0.99812095 1.08160453]\n",
      " [1.60457767 1.50607025]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55917871 0.71362746]\n",
      " [0.69936719 0.79208399]\n",
      " [0.73068897 0.74679751]\n",
      " [0.83265721 0.81847809]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01295998]\n",
      " [ 0.0050487 ]\n",
      " [ 0.01221587]\n",
      " [ 0.02458341]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49676005]\n",
      " [0.50126217]\n",
      " [0.50305393]\n",
      " [0.50614554]]\n",
      "Error [[-0.49676005]\n",
      " [ 0.49873783]\n",
      " [ 0.49694607]\n",
      " [-0.50614554]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23786744 0.91306827]\n",
      " [0.84445851 1.3375253 ]\n",
      " [0.99826552 1.08158179]\n",
      " [1.60485658 1.50603882]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55918805 0.71362761]\n",
      " [0.6994034  0.79208268]\n",
      " [0.73071742 0.74679321]\n",
      " [0.83269607 0.81847342]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01300442]\n",
      " [ 0.00504823]\n",
      " [ 0.01222721]\n",
      " [ 0.02462433]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49674894]\n",
      " [0.50126206]\n",
      " [0.50305676]\n",
      " [0.50615577]]\n",
      "Error [[-0.49674894]\n",
      " [ 0.49873794]\n",
      " [ 0.49694324]\n",
      " [-0.50615577]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23790541 0.91306902]\n",
      " [0.84463112 1.33751736]\n",
      " [0.9984104  1.08155903]\n",
      " [1.6051361  1.50600736]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55919741 0.71362777]\n",
      " [0.69943969 0.79208138]\n",
      " [0.73074593 0.7467889 ]\n",
      " [0.832735   0.81846874]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01304888]\n",
      " [ 0.00504778]\n",
      " [ 0.01223856]\n",
      " [ 0.02466528]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49673783]\n",
      " [0.50126194]\n",
      " [0.5030596 ]\n",
      " [0.50616601]]\n",
      "Error [[-0.49673783]\n",
      " [ 0.49873806]\n",
      " [ 0.4969404 ]\n",
      " [-0.50616601]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23794346 0.91306978]\n",
      " [0.8448041  1.33750941]\n",
      " [0.9985556  1.08153624]\n",
      " [1.60541623 1.50597586]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55920679 0.71362792]\n",
      " [0.69947605 0.79208007]\n",
      " [0.7307745  0.74678459]\n",
      " [0.83277402 0.81846406]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01309336]\n",
      " [ 0.00504734]\n",
      " [ 0.01224992]\n",
      " [ 0.02470626]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49672671]\n",
      " [0.50126183]\n",
      " [0.50306244]\n",
      " [0.50617625]]\n",
      "Error [[-0.49672671]\n",
      " [ 0.49873817]\n",
      " [ 0.49693756]\n",
      " [-0.50617625]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2379816  0.91307053]\n",
      " [0.84497745 1.33750145]\n",
      " [0.99870111 1.08151342]\n",
      " [1.60569697 1.50594433]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55921619 0.71362808]\n",
      " [0.69951249 0.79207875]\n",
      " [0.73080313 0.74678028]\n",
      " [0.83281311 0.81845938]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01313786]\n",
      " [ 0.00504692]\n",
      " [ 0.01226129]\n",
      " [ 0.02474726]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49671558]\n",
      " [0.50126173]\n",
      " [0.50306528]\n",
      " [0.5061865 ]]\n",
      "Error [[-0.49671558]\n",
      " [ 0.49873827]\n",
      " [ 0.49693472]\n",
      " [-0.5061865 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23801981 0.91307129]\n",
      " [0.84515118 1.33749348]\n",
      " [0.99884695 1.08149058]\n",
      " [1.60597832 1.50591277]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5592256  0.71362823]\n",
      " [0.699549   0.79207744]\n",
      " [0.73083181 0.74677596]\n",
      " [0.83285228 0.81845469]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01318238]\n",
      " [ 0.00504651]\n",
      " [ 0.01227268]\n",
      " [ 0.02478829]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49670445]\n",
      " [0.50126162]\n",
      " [0.50306813]\n",
      " [0.50619676]]\n",
      "Error [[-0.49670445]\n",
      " [ 0.49873838]\n",
      " [ 0.49693187]\n",
      " [-0.50619676]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2380581  0.91307205]\n",
      " [0.84532528 1.33748551]\n",
      " [0.99899309 1.08146771]\n",
      " [1.60626027 1.50588117]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55923504 0.71362839]\n",
      " [0.69958559 0.79207613]\n",
      " [0.73086056 0.74677163]\n",
      " [0.83289153 0.81844999]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01322693]\n",
      " [ 0.0050461 ]\n",
      " [ 0.01228408]\n",
      " [ 0.02482935]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49669332]\n",
      " [0.50126152]\n",
      " [0.50307098]\n",
      " [0.50620702]]\n",
      "Error [[-0.49669332]\n",
      " [ 0.49873848]\n",
      " [ 0.49692902]\n",
      " [-0.50620702]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23809647 0.91307281]\n",
      " [0.84549975 1.33747753]\n",
      " [0.99913956 1.08144482]\n",
      " [1.60654284 1.50584953]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5592445  0.71362854]\n",
      " [0.69962226 0.79207482]\n",
      " [0.73088937 0.7467673 ]\n",
      " [0.83293085 0.81844529]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01327149]\n",
      " [ 0.00504572]\n",
      " [ 0.01229549]\n",
      " [ 0.02487043]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49668218]\n",
      " [0.50126143]\n",
      " [0.50307383]\n",
      " [0.50621729]]\n",
      "Error [[-0.49668218]\n",
      " [ 0.49873857]\n",
      " [ 0.49692617]\n",
      " [-0.50621729]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23813492 0.91307357]\n",
      " [0.84567459 1.33746954]\n",
      " [0.99928634 1.08142189]\n",
      " [1.60682601 1.50581787]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55925398 0.7136287 ]\n",
      " [0.699659   0.7920735 ]\n",
      " [0.73091824 0.74676297]\n",
      " [0.83297025 0.81844059]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01331608]\n",
      " [ 0.00504534]\n",
      " [ 0.01230691]\n",
      " [ 0.02491154]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49667103]\n",
      " [0.50126133]\n",
      " [0.50307669]\n",
      " [0.50622756]]\n",
      "Error [[-0.49667103]\n",
      " [ 0.49873867]\n",
      " [ 0.49692331]\n",
      " [-0.50622756]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23817346 0.91307433]\n",
      " [0.84584981 1.33746154]\n",
      " [0.99943344 1.08139895]\n",
      " [1.60710979 1.50578616]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55926348 0.71362885]\n",
      " [0.69969582 0.79207218]\n",
      " [0.73094717 0.74675863]\n",
      " [0.83300973 0.81843588]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01336069]\n",
      " [ 0.00504498]\n",
      " [ 0.01231835]\n",
      " [ 0.02495268]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49665988]\n",
      " [0.50126124]\n",
      " [0.50307955]\n",
      " [0.50623785]]\n",
      "Error [[-0.49665988]\n",
      " [ 0.49873876]\n",
      " [ 0.49692045]\n",
      " [-0.50623785]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23821207 0.91307509]\n",
      " [0.8460254  1.33745354]\n",
      " [0.99958086 1.08137597]\n",
      " [1.60739418 1.50575443]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.559273   0.71362901]\n",
      " [0.69973272 0.79207087]\n",
      " [0.73097616 0.74675429]\n",
      " [0.83304929 0.81843116]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01340533]\n",
      " [ 0.00504463]\n",
      " [ 0.01232979]\n",
      " [ 0.02499384]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49664872]\n",
      " [0.50126116]\n",
      " [0.50308241]\n",
      " [0.50624814]]\n",
      "Error [[-0.49664872]\n",
      " [ 0.49873884]\n",
      " [ 0.49691759]\n",
      " [-0.50624814]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23825076 0.91307585]\n",
      " [0.84620136 1.33744553]\n",
      " [0.99972859 1.08135297]\n",
      " [1.60767919 1.50572266]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55928253 0.71362916]\n",
      " [0.69976969 0.79206955]\n",
      " [0.73100521 0.74674994]\n",
      " [0.83308892 0.81842644]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01344998]\n",
      " [ 0.0050443 ]\n",
      " [ 0.01234125]\n",
      " [ 0.02503503]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49663755]\n",
      " [0.50126107]\n",
      " [0.50308527]\n",
      " [0.50625843]]\n",
      "Error [[-0.49663755]\n",
      " [ 0.49873893]\n",
      " [ 0.49691473]\n",
      " [-0.50625843]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23828954 0.91307661]\n",
      " [0.8463777  1.33743752]\n",
      " [0.99987664 1.08132995]\n",
      " [1.6079648  1.50569085]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55929209 0.71362932]\n",
      " [0.69980673 0.79206823]\n",
      " [0.73103432 0.74674558]\n",
      " [0.83312863 0.81842171]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01349466]\n",
      " [ 0.00504397]\n",
      " [ 0.01235272]\n",
      " [ 0.02507625]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49662639]\n",
      " [0.50126099]\n",
      " [0.50308814]\n",
      " [0.50626873]]\n",
      "Error [[-0.49662639]\n",
      " [ 0.49873901]\n",
      " [ 0.49691186]\n",
      " [-0.50626873]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23832839 0.91307737]\n",
      " [0.84655441 1.33742949]\n",
      " [1.00002501 1.0813069 ]\n",
      " [1.60825103 1.50565901]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55930167 0.71362948]\n",
      " [0.69984385 0.7920669 ]\n",
      " [0.7310635  0.74674122]\n",
      " [0.83316842 0.81841698]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01353936]\n",
      " [ 0.00504366]\n",
      " [ 0.01236421]\n",
      " [ 0.0251175 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49661521]\n",
      " [0.50126091]\n",
      " [0.50309101]\n",
      " [0.50627904]]\n",
      "Error [[-0.49661521]\n",
      " [ 0.49873909]\n",
      " [ 0.49690899]\n",
      " [-0.50627904]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23836733 0.91307814]\n",
      " [0.8467315  1.33742146]\n",
      " [1.0001737  1.08128382]\n",
      " [1.60853787 1.50562714]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55931126 0.71362963]\n",
      " [0.69988105 0.79206558]\n",
      " [0.73109273 0.74673686]\n",
      " [0.83320829 0.81841225]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01358409]\n",
      " [ 0.00504337]\n",
      " [ 0.0123757 ]\n",
      " [ 0.02515877]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49660403]\n",
      " [0.50126084]\n",
      " [0.50309389]\n",
      " [0.50628936]]\n",
      "Error [[-0.49660403]\n",
      " [ 0.49873916]\n",
      " [ 0.49690611]\n",
      " [-0.50628936]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23840634 0.9130789 ]\n",
      " [0.84690896 1.33741342]\n",
      " [1.0003227  1.08126071]\n",
      " [1.60882532 1.50559523]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55932088 0.71362979]\n",
      " [0.69991832 0.79206426]\n",
      " [0.73112202 0.74673249]\n",
      " [0.83324823 0.8184075 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01362884]\n",
      " [ 0.00504308]\n",
      " [ 0.01238721]\n",
      " [ 0.02520007]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49659284]\n",
      " [0.50126077]\n",
      " [0.50309676]\n",
      " [0.50629968]]\n",
      "Error [[-0.49659284]\n",
      " [ 0.49873923]\n",
      " [ 0.49690324]\n",
      " [-0.50629968]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23844544 0.91307966]\n",
      " [0.84708679 1.33740538]\n",
      " [1.00047203 1.08123758]\n",
      " [1.60911338 1.50556329]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55933052 0.71362994]\n",
      " [0.69995567 0.79206293]\n",
      " [0.73115137 0.74672811]\n",
      " [0.83328825 0.81840276]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0136736 ]\n",
      " [ 0.00504281]\n",
      " [ 0.01239873]\n",
      " [ 0.02524139]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49658165]\n",
      " [0.5012607 ]\n",
      " [0.50309964]\n",
      " [0.50631001]]\n",
      "Error [[-0.49658165]\n",
      " [ 0.4987393 ]\n",
      " [ 0.49690036]\n",
      " [-0.50631001]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23848462 0.91308043]\n",
      " [0.847265   1.33739733]\n",
      " [1.00062167 1.08121442]\n",
      " [1.60940206 1.50553132]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55934017 0.7136301 ]\n",
      " [0.6999931  0.79206161]\n",
      " [0.73118079 0.74672373]\n",
      " [0.83332835 0.818398  ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0137184 ]\n",
      " [ 0.00504255]\n",
      " [ 0.01241026]\n",
      " [ 0.02528275]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49657045]\n",
      " [0.50126064]\n",
      " [0.50310253]\n",
      " [0.50632035]]\n",
      "Error [[-0.49657045]\n",
      " [ 0.49873936]\n",
      " [ 0.49689747]\n",
      " [-0.50632035]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23852387 0.9130812 ]\n",
      " [0.84744359 1.33738927]\n",
      " [1.00077163 1.08119124]\n",
      " [1.60969135 1.50549931]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55934985 0.71363026]\n",
      " [0.7000306  0.79206028]\n",
      " [0.73121026 0.74671935]\n",
      " [0.83336853 0.81839325]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01376321]\n",
      " [ 0.00504231]\n",
      " [ 0.01242181]\n",
      " [ 0.02532413]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49655925]\n",
      " [0.50126057]\n",
      " [0.50310541]\n",
      " [0.50633069]]\n",
      "Error [[-0.49655925]\n",
      " [ 0.49873943]\n",
      " [ 0.49689459]\n",
      " [-0.50633069]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23856321 0.91308196]\n",
      " [0.84762255 1.3373812 ]\n",
      " [1.00092191 1.08116802]\n",
      " [1.60998125 1.50546726]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55935954 0.71363041]\n",
      " [0.70006818 0.79205895]\n",
      " [0.7312398  0.74671496]\n",
      " [0.83340878 0.81838848]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01380805]\n",
      " [ 0.00504208]\n",
      " [ 0.01243337]\n",
      " [ 0.02536554]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49654804]\n",
      " [0.50126052]\n",
      " [0.5031083 ]\n",
      " [0.50634104]]\n",
      "Error [[-0.49654804]\n",
      " [ 0.49873948]\n",
      " [ 0.4968917 ]\n",
      " [-0.50634104]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23860263 0.91308273]\n",
      " [0.84780189 1.33737313]\n",
      " [1.00107251 1.08114479]\n",
      " [1.61027177 1.50543518]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55936926 0.71363057]\n",
      " [0.70010583 0.79205762]\n",
      " [0.7312694  0.74671056]\n",
      " [0.83344911 0.81838372]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01385291]\n",
      " [ 0.00504186]\n",
      " [ 0.01244494]\n",
      " [ 0.02540697]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49653683]\n",
      " [0.50126046]\n",
      " [0.50311119]\n",
      " [0.5063514 ]]\n",
      "Error [[-0.49653683]\n",
      " [ 0.49873954]\n",
      " [ 0.49688881]\n",
      " [-0.5063514 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23864213 0.9130835 ]\n",
      " [0.8479816  1.33736505]\n",
      " [1.00122343 1.08112152]\n",
      " [1.6105629  1.50540307]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.559379   0.71363073]\n",
      " [0.70014357 0.79205629]\n",
      " [0.73129905 0.74670616]\n",
      " [0.83348952 0.81837894]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0138978 ]\n",
      " [ 0.00504165]\n",
      " [ 0.01245652]\n",
      " [ 0.02544843]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49652561]\n",
      " [0.50126041]\n",
      " [0.50311409]\n",
      " [0.50636177]]\n",
      "Error [[-0.49652561]\n",
      " [ 0.49873959]\n",
      " [ 0.49688591]\n",
      " [-0.50636177]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23868171 0.91308426]\n",
      " [0.84816168 1.33735696]\n",
      " [1.00137467 1.08109823]\n",
      " [1.61085465 1.50537092]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55938875 0.71363088]\n",
      " [0.70018137 0.79205496]\n",
      " [0.73132877 0.74670176]\n",
      " [0.83353001 0.81837416]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0139427 ]\n",
      " [ 0.00504146]\n",
      " [ 0.01246811]\n",
      " [ 0.02548993]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49651438]\n",
      " [0.50126036]\n",
      " [0.50311699]\n",
      " [0.50637214]]\n",
      "Error [[-0.49651438]\n",
      " [ 0.49873964]\n",
      " [ 0.49688301]\n",
      " [-0.50637214]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23872137 0.91308503]\n",
      " [0.84834215 1.33734886]\n",
      " [1.00152623 1.08107491]\n",
      " [1.61114701 1.50533874]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55939853 0.71363104]\n",
      " [0.70021925 0.79205362]\n",
      " [0.73135855 0.74669735]\n",
      " [0.83357057 0.81836938]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01398763]\n",
      " [ 0.00504128]\n",
      " [ 0.01247972]\n",
      " [ 0.02553144]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49650315]\n",
      " [0.50126032]\n",
      " [0.50311989]\n",
      " [0.50638251]]\n",
      "Error [[-0.49650315]\n",
      " [ 0.49873968]\n",
      " [ 0.49688011]\n",
      " [-0.50638251]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23876111 0.9130858 ]\n",
      " [0.84852299 1.33734076]\n",
      " [1.00167811 1.08105157]\n",
      " [1.61143999 1.50530652]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55940832 0.7136312 ]\n",
      " [0.70025721 0.79205229]\n",
      " [0.73138839 0.74669293]\n",
      " [0.83361121 0.81836459]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01403259]\n",
      " [ 0.00504112]\n",
      " [ 0.01249134]\n",
      " [ 0.02557299]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49649191]\n",
      " [0.50126028]\n",
      " [0.50312279]\n",
      " [0.5063929 ]]\n",
      "Error [[-0.49649191]\n",
      " [ 0.49873972]\n",
      " [ 0.49687721]\n",
      " [-0.5063929 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23880093 0.91308657]\n",
      " [0.84870421 1.33733265]\n",
      " [1.00183031 1.0810282 ]\n",
      " [1.61173359 1.50527427]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55941814 0.71363136]\n",
      " [0.70029525 0.79205095]\n",
      " [0.73141829 0.74668851]\n",
      " [0.83365193 0.8183598 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01407757]\n",
      " [ 0.00504096]\n",
      " [ 0.01250297]\n",
      " [ 0.02561456]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49648067]\n",
      " [0.50126024]\n",
      " [0.5031257 ]\n",
      " [0.50640329]]\n",
      "Error [[-0.49648067]\n",
      " [ 0.49873976]\n",
      " [ 0.4968743 ]\n",
      " [-0.50640329]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23884083 0.91308734]\n",
      " [0.8488858  1.33732453]\n",
      " [1.00198284 1.0810048 ]\n",
      " [1.61202781 1.50524199]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55942797 0.71363151]\n",
      " [0.70033336 0.79204962]\n",
      " [0.73144825 0.74668409]\n",
      " [0.83369273 0.818355  ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01412257]\n",
      " [ 0.00504082]\n",
      " [ 0.01251462]\n",
      " [ 0.02565617]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49646942]\n",
      " [0.5012602 ]\n",
      " [0.50312861]\n",
      " [0.50641369]]\n",
      "Error [[-0.49646942]\n",
      " [ 0.4987398 ]\n",
      " [ 0.49687139]\n",
      " [-0.50641369]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23888082 0.91308812]\n",
      " [0.84906777 1.33731641]\n",
      " [1.00213568 1.08098137]\n",
      " [1.61232264 1.50520967]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55943783 0.71363167]\n",
      " [0.70037155 0.79204828]\n",
      " [0.73147827 0.74667965]\n",
      " [0.8337336  0.81835019]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01416759]\n",
      " [ 0.0050407 ]\n",
      " [ 0.01252628]\n",
      " [ 0.0256978 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49645816]\n",
      " [0.50126017]\n",
      " [0.50313153]\n",
      " [0.5064241 ]]\n",
      "Error [[-0.49645816]\n",
      " [ 0.49873983]\n",
      " [ 0.49686847]\n",
      " [-0.5064241 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23892088 0.91308889]\n",
      " [0.84925012 1.33730828]\n",
      " [1.00228884 1.08095792]\n",
      " [1.61261809 1.50517731]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5594477  0.71363183]\n",
      " [0.70040982 0.79204694]\n",
      " [0.73150835 0.74667522]\n",
      " [0.83377456 0.81834538]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01421264]\n",
      " [ 0.00504058]\n",
      " [ 0.01253795]\n",
      " [ 0.02573945]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4964469 ]\n",
      " [0.50126014]\n",
      " [0.50313445]\n",
      " [0.50643451]]\n",
      "Error [[-0.4964469 ]\n",
      " [ 0.49873986]\n",
      " [ 0.49686555]\n",
      " [-0.50643451]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23896103 0.91308966]\n",
      " [0.84943285 1.33730014]\n",
      " [1.00244233 1.08093445]\n",
      " [1.61291415 1.50514492]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55945759 0.71363199]\n",
      " [0.70044816 0.7920456 ]\n",
      " [0.7315385  0.74667078]\n",
      " [0.83381559 0.81834057]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01425771]\n",
      " [ 0.00504049]\n",
      " [ 0.01254963]\n",
      " [ 0.02578114]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49643563]\n",
      " [0.50126012]\n",
      " [0.50313737]\n",
      " [0.50644493]]\n",
      "Error [[-0.49643563]\n",
      " [ 0.49873988]\n",
      " [ 0.49686263]\n",
      " [-0.50644493]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23900125 0.91309044]\n",
      " [0.84961596 1.337292  ]\n",
      " [1.00259614 1.08091094]\n",
      " [1.61321084 1.5051125 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55946751 0.71363215]\n",
      " [0.70048657 0.79204426]\n",
      " [0.7315687  0.74666633]\n",
      " [0.83385669 0.81833575]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01430281]\n",
      " [ 0.0050404 ]\n",
      " [ 0.01256132]\n",
      " [ 0.02582285]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49642436]\n",
      " [0.5012601 ]\n",
      " [0.50314029]\n",
      " [0.50645535]]\n",
      "Error [[-0.49642436]\n",
      " [ 0.4987399 ]\n",
      " [ 0.49685971]\n",
      " [-0.50645535]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23904156 0.91309121]\n",
      " [0.84979944 1.33728384]\n",
      " [1.00275027 1.08088741]\n",
      " [1.61350815 1.50508004]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55947744 0.7136323 ]\n",
      " [0.70052507 0.79204292]\n",
      " [0.73159897 0.74666188]\n",
      " [0.83389788 0.81833092]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01434793]\n",
      " [ 0.00504033]\n",
      " [ 0.01257303]\n",
      " [ 0.02586459]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49641308]\n",
      " [0.50126008]\n",
      " [0.50314322]\n",
      " [0.50646579]]\n",
      "Error [[-0.49641308]\n",
      " [ 0.49873992]\n",
      " [ 0.49685678]\n",
      " [-0.50646579]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23908195 0.91309199]\n",
      " [0.8499833  1.33727568]\n",
      " [1.00290472 1.08086385]\n",
      " [1.61380607 1.50504755]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5594874  0.71363246]\n",
      " [0.70056364 0.79204157]\n",
      " [0.7316293  0.74665742]\n",
      " [0.83393914 0.81832609]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01439307]\n",
      " [ 0.00504027]\n",
      " [ 0.01258475]\n",
      " [ 0.02590636]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49640179]\n",
      " [0.50126006]\n",
      " [0.50314615]\n",
      " [0.50647623]]\n",
      "Error [[-0.49640179]\n",
      " [ 0.49873994]\n",
      " [ 0.49685385]\n",
      " [-0.50647623]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23912241 0.91309276]\n",
      " [0.85016754 1.33726752]\n",
      " [1.00305949 1.08084027]\n",
      " [1.61410462 1.50501502]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55949737 0.71363262]\n",
      " [0.70060229 0.79204023]\n",
      " [0.73165969 0.74665296]\n",
      " [0.83398048 0.81832126]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01443824]\n",
      " [ 0.00504022]\n",
      " [ 0.01259648]\n",
      " [ 0.02594816]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4963905 ]\n",
      " [0.50126005]\n",
      " [0.50314908]\n",
      " [0.50648668]]\n",
      "Error [[-0.4963905 ]\n",
      " [ 0.49873995]\n",
      " [ 0.49685092]\n",
      " [-0.50648668]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23916296 0.91309354]\n",
      " [0.85035216 1.33725934]\n",
      " [1.00321459 1.08081665]\n",
      " [1.61440378 1.50498246]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55950736 0.71363278]\n",
      " [0.70064101 0.79203888]\n",
      " [0.73169014 0.7466485 ]\n",
      " [0.8340219  0.81831642]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01448343]\n",
      " [ 0.00504019]\n",
      " [ 0.01260823]\n",
      " [ 0.02598999]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49637921]\n",
      " [0.50126004]\n",
      " [0.50315202]\n",
      " [0.50649713]]\n",
      "Error [[-0.49637921]\n",
      " [ 0.49873996]\n",
      " [ 0.49684798]\n",
      " [-0.50649713]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2392036  0.91309431]\n",
      " [0.85053716 1.33725116]\n",
      " [1.00337001 1.08079302]\n",
      " [1.61470357 1.50494986]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55951738 0.71363294]\n",
      " [0.70067981 0.79203753]\n",
      " [0.73172065 0.74664402]\n",
      " [0.83406339 0.81831157]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01452865]\n",
      " [ 0.00504017]\n",
      " [ 0.01261999]\n",
      " [ 0.02603184]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4963679 ]\n",
      " [0.50126004]\n",
      " [0.50315496]\n",
      " [0.50650759]]\n",
      "Error [[-0.4963679 ]\n",
      " [ 0.49873996]\n",
      " [ 0.49684504]\n",
      " [-0.50650759]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23924431 0.91309509]\n",
      " [0.85072254 1.33724297]\n",
      " [1.00352575 1.08076935]\n",
      " [1.61500398 1.50491723]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55952741 0.7136331 ]\n",
      " [0.70071869 0.79203618]\n",
      " [0.73175122 0.74663955]\n",
      " [0.83410496 0.81830672]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01457389]\n",
      " [ 0.00504016]\n",
      " [ 0.01263176]\n",
      " [ 0.02607373]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49635659]\n",
      " [0.50126004]\n",
      " [0.5031579 ]\n",
      " [0.50651806]]\n",
      "Error [[-0.49635659]\n",
      " [ 0.49873996]\n",
      " [ 0.4968421 ]\n",
      " [-0.50651806]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2392851  0.91309587]\n",
      " [0.85090829 1.33723478]\n",
      " [1.00368181 1.08074566]\n",
      " [1.61530501 1.50488457]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55953747 0.71363326]\n",
      " [0.70075764 0.79203483]\n",
      " [0.73178185 0.74663507]\n",
      " [0.83414661 0.81830186]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01461915]\n",
      " [ 0.00504017]\n",
      " [ 0.01264355]\n",
      " [ 0.02611564]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49634528]\n",
      " [0.50126004]\n",
      " [0.50316084]\n",
      " [0.50652854]]\n",
      "Error [[-0.49634528]\n",
      " [ 0.49873996]\n",
      " [ 0.49683916]\n",
      " [-0.50652854]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23932597 0.91309665]\n",
      " [0.85109443 1.33722658]\n",
      " [1.0038382  1.08072194]\n",
      " [1.61560666 1.50485186]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55954754 0.71363342]\n",
      " [0.70079667 0.79203348]\n",
      " [0.73181255 0.74663058]\n",
      " [0.83418834 0.818297  ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01466444]\n",
      " [ 0.00504019]\n",
      " [ 0.01265534]\n",
      " [ 0.02615758]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49633395]\n",
      " [0.50126005]\n",
      " [0.50316379]\n",
      " [0.50653902]]\n",
      "Error [[-0.49633395]\n",
      " [ 0.49873995]\n",
      " [ 0.49683621]\n",
      " [-0.50653902]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23936693 0.91309743]\n",
      " [0.85128095 1.33721837]\n",
      " [1.00399492 1.08069819]\n",
      " [1.61590893 1.50481913]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55955763 0.71363357]\n",
      " [0.70083578 0.79203213]\n",
      " [0.7318433  0.74662609]\n",
      " [0.83423015 0.81829213]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01470976]\n",
      " [ 0.00504023]\n",
      " [ 0.01266715]\n",
      " [ 0.02619955]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49632263]\n",
      " [0.50126005]\n",
      " [0.50316675]\n",
      " [0.50654951]]\n",
      "Error [[-0.49632263]\n",
      " [ 0.49873995]\n",
      " [ 0.49683325]\n",
      " [-0.50654951]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23940797 0.91309821]\n",
      " [0.85146784 1.33721015]\n",
      " [1.00415195 1.08067442]\n",
      " [1.61621183 1.50478636]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55956775 0.71363373]\n",
      " [0.70087497 0.79203078]\n",
      " [0.73187412 0.74662159]\n",
      " [0.83427203 0.81828726]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0147551 ]\n",
      " [ 0.00504028]\n",
      " [ 0.01267898]\n",
      " [ 0.02624155]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49631129]\n",
      " [0.50126007]\n",
      " [0.5031697 ]\n",
      " [0.50656001]]\n",
      "Error [[-0.49631129]\n",
      " [ 0.49873993]\n",
      " [ 0.4968303 ]\n",
      " [-0.50656001]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23944908 0.91309899]\n",
      " [0.85165512 1.33720193]\n",
      " [1.00430932 1.08065062]\n",
      " [1.61651535 1.50475355]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55957788 0.71363389]\n",
      " [0.70091423 0.79202942]\n",
      " [0.731905   0.74661709]\n",
      " [0.83431399 0.81828238]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01480046]\n",
      " [ 0.00504034]\n",
      " [ 0.01269081]\n",
      " [ 0.02628357]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49629995]\n",
      " [0.50126008]\n",
      " [0.50317266]\n",
      " [0.50657051]]\n",
      "Error [[-0.49629995]\n",
      " [ 0.49873992]\n",
      " [ 0.49682734]\n",
      " [-0.50657051]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23949028 0.91309977]\n",
      " [0.85184278 1.3371937 ]\n",
      " [1.004467   1.08062679]\n",
      " [1.6168195  1.50472071]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55958803 0.71363405]\n",
      " [0.70095356 0.79202807]\n",
      " [0.73193594 0.74661258]\n",
      " [0.83435603 0.8182775 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01484585]\n",
      " [ 0.00504042]\n",
      " [ 0.01270266]\n",
      " [ 0.02632563]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49628861]\n",
      " [0.5012601 ]\n",
      " [0.50317562]\n",
      " [0.50658103]]\n",
      "Error [[-0.49628861]\n",
      " [ 0.4987399 ]\n",
      " [ 0.49682438]\n",
      " [-0.50658103]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23953156 0.91310056]\n",
      " [0.85203082 1.33718546]\n",
      " [1.00462501 1.08060294]\n",
      " [1.61712427 1.50468784]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55959821 0.71363421]\n",
      " [0.70099298 0.79202671]\n",
      " [0.73196694 0.74660807]\n",
      " [0.83439815 0.81827261]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01489126]\n",
      " [ 0.00504051]\n",
      " [ 0.01271452]\n",
      " [ 0.02636771]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49627725]\n",
      " [0.50126012]\n",
      " [0.50317859]\n",
      " [0.50659155]]\n",
      "Error [[-0.49627725]\n",
      " [ 0.49873988]\n",
      " [ 0.49682141]\n",
      " [-0.50659155]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23957292 0.91310134]\n",
      " [0.85221924 1.33717721]\n",
      " [1.00478335 1.08057906]\n",
      " [1.61742967 1.50465493]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5596084  0.71363437]\n",
      " [0.70103247 0.79202535]\n",
      " [0.731998   0.74660355]\n",
      " [0.83444034 0.81826772]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0149367 ]\n",
      " [ 0.00504061]\n",
      " [ 0.0127264 ]\n",
      " [ 0.02640983]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4962659 ]\n",
      " [0.50126015]\n",
      " [0.50318156]\n",
      " [0.50660207]]\n",
      "Error [[-0.4962659 ]\n",
      " [ 0.49873985]\n",
      " [ 0.49681844]\n",
      " [-0.50660207]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23961436 0.91310212]\n",
      " [0.85240804 1.33716896]\n",
      " [1.00494201 1.08055515]\n",
      " [1.61773569 1.50462198]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55961861 0.71363453]\n",
      " [0.70107204 0.79202399]\n",
      " [0.73202913 0.74659903]\n",
      " [0.83448262 0.81826282]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01498216]\n",
      " [ 0.00504073]\n",
      " [ 0.01273828]\n",
      " [ 0.02645197]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49625453]\n",
      " [0.50126018]\n",
      " [0.50318453]\n",
      " [0.50661261]]\n",
      "Error [[-0.49625453]\n",
      " [ 0.49873982]\n",
      " [ 0.49681547]\n",
      " [-0.50661261]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23965589 0.91310291]\n",
      " [0.85259723 1.3371607 ]\n",
      " [1.00510099 1.08053121]\n",
      " [1.61804233 1.504589  ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55962885 0.71363469]\n",
      " [0.70111169 0.79202263]\n",
      " [0.73206031 0.7465945 ]\n",
      " [0.83452497 0.81825791]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01502765]\n",
      " [ 0.00504086]\n",
      " [ 0.01275018]\n",
      " [ 0.02649414]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49624316]\n",
      " [0.50126021]\n",
      " [0.5031875 ]\n",
      " [0.50662315]]\n",
      "Error [[-0.49624316]\n",
      " [ 0.49873979]\n",
      " [ 0.4968125 ]\n",
      " [-0.50662315]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23969749 0.91310369]\n",
      " [0.8527868  1.33715243]\n",
      " [1.00526031 1.08050725]\n",
      " [1.61834961 1.50455599]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5596391  0.71363485]\n",
      " [0.70115141 0.79202127]\n",
      " [0.73209156 0.74658996]\n",
      " [0.83456739 0.818253  ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01507316]\n",
      " [ 0.005041  ]\n",
      " [ 0.0127621 ]\n",
      " [ 0.02653634]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49623178]\n",
      " [0.50126025]\n",
      " [0.50319048]\n",
      " [0.5066337 ]]\n",
      "Error [[-0.49623178]\n",
      " [ 0.49873975]\n",
      " [ 0.49680952]\n",
      " [-0.5066337 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23973918 0.91310448]\n",
      " [0.85297674 1.33714416]\n",
      " [1.00541994 1.08048326]\n",
      " [1.61865751 1.50452294]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55964937 0.71363502]\n",
      " [0.70119121 0.79201991]\n",
      " [0.73212287 0.74658543]\n",
      " [0.8346099  0.81824809]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0151187 ]\n",
      " [ 0.00504116]\n",
      " [ 0.01277403]\n",
      " [ 0.02657857]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4962204 ]\n",
      " [0.50126029]\n",
      " [0.50319346]\n",
      " [0.50664425]]\n",
      "Error [[-0.4962204 ]\n",
      " [ 0.49873971]\n",
      " [ 0.49680654]\n",
      " [-0.50664425]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23978095 0.91310527]\n",
      " [0.85316708 1.33713588]\n",
      " [1.00557991 1.08045924]\n",
      " [1.61896603 1.50448986]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55965967 0.71363518]\n",
      " [0.70123109 0.79201854]\n",
      " [0.73215424 0.74658088]\n",
      " [0.83465248 0.81824317]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01516426]\n",
      " [ 0.00504134]\n",
      " [ 0.01278597]\n",
      " [ 0.02662083]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49620901]\n",
      " [0.50126033]\n",
      " [0.50319645]\n",
      " [0.50665481]]\n",
      "Error [[-0.49620901]\n",
      " [ 0.49873967]\n",
      " [ 0.49680355]\n",
      " [-0.50665481]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2398228  0.91310606]\n",
      " [0.85335779 1.33712759]\n",
      " [1.0057402  1.0804352 ]\n",
      " [1.61927519 1.50445674]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55966998 0.71363534]\n",
      " [0.70127104 0.79201718]\n",
      " [0.73218567 0.74657633]\n",
      " [0.83469515 0.81823824]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01520985]\n",
      " [ 0.00504152]\n",
      " [ 0.01279792]\n",
      " [ 0.02666311]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49619761]\n",
      " [0.50126038]\n",
      " [0.50319944]\n",
      " [0.50666538]]\n",
      "Error [[-0.49619761]\n",
      " [ 0.49873962]\n",
      " [ 0.49680056]\n",
      " [-0.50666538]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23986473 0.91310684]\n",
      " [0.85354889 1.3371193 ]\n",
      " [1.00590081 1.08041113]\n",
      " [1.61958497 1.50442358]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55968031 0.7136355 ]\n",
      " [0.70131107 0.79201581]\n",
      " [0.73221717 0.74657178]\n",
      " [0.83473788 0.81823331]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01525546]\n",
      " [ 0.00504172]\n",
      " [ 0.01280988]\n",
      " [ 0.02670543]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49618621]\n",
      " [0.50126043]\n",
      " [0.50320243]\n",
      " [0.50667596]]\n",
      "Error [[-0.49618621]\n",
      " [ 0.49873957]\n",
      " [ 0.49679757]\n",
      " [-0.50667596]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23990674 0.91310763]\n",
      " [0.85374037 1.33711099]\n",
      " [1.00606176 1.08038703]\n",
      " [1.61989538 1.50439039]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55969067 0.71363566]\n",
      " [0.70135118 0.79201444]\n",
      " [0.73224872 0.74656722]\n",
      " [0.8347807  0.81822837]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0153011 ]\n",
      " [ 0.00504194]\n",
      " [ 0.01282186]\n",
      " [ 0.02674778]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4961748 ]\n",
      " [0.50126048]\n",
      " [0.50320542]\n",
      " [0.50668655]]\n",
      "Error [[-0.4961748 ]\n",
      " [ 0.49873952]\n",
      " [ 0.49679458]\n",
      " [-0.50668655]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23994883 0.91310842]\n",
      " [0.85393223 1.33710269]\n",
      " [1.00622303 1.08036291]\n",
      " [1.62020643 1.50435717]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55970104 0.71363582]\n",
      " [0.70139137 0.79201308]\n",
      " [0.73228034 0.74656265]\n",
      " [0.8348236  0.81822343]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01534676]\n",
      " [ 0.00504216]\n",
      " [ 0.01283386]\n",
      " [ 0.02679015]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49616338]\n",
      " [0.50126054]\n",
      " [0.50320842]\n",
      " [0.50669714]]\n",
      "Error [[-0.49616338]\n",
      " [ 0.49873946]\n",
      " [ 0.49679158]\n",
      " [-0.50669714]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.23999101 0.91310921]\n",
      " [0.85412448 1.33709437]\n",
      " [1.00638462 1.08033875]\n",
      " [1.6205181  1.50432391]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55971143 0.71363598]\n",
      " [0.70143163 0.79201171]\n",
      " [0.73231202 0.74655808]\n",
      " [0.83486657 0.81821849]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01539245]\n",
      " [ 0.00504241]\n",
      " [ 0.01284586]\n",
      " [ 0.02683256]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49615196]\n",
      " [0.5012606 ]\n",
      " [0.50321142]\n",
      " [0.50670774]]\n",
      "Error [[-0.49615196]\n",
      " [ 0.4987394 ]\n",
      " [ 0.49678858]\n",
      " [-0.50670774]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24003326 0.91311   ]\n",
      " [0.85431711 1.33708605]\n",
      " [1.00654655 1.08031457]\n",
      " [1.6208304  1.50429061]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55972185 0.71363614]\n",
      " [0.70147197 0.79201033]\n",
      " [0.73234376 0.74655351]\n",
      " [0.83490962 0.81821353]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01543817]\n",
      " [ 0.00504266]\n",
      " [ 0.01285788]\n",
      " [ 0.02687499]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49614053]\n",
      " [0.50126066]\n",
      " [0.50321443]\n",
      " [0.50671834]]\n",
      "Error [[-0.49614053]\n",
      " [ 0.49873934]\n",
      " [ 0.49678557]\n",
      " [-0.50671834]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2400756  0.9131108 ]\n",
      " [0.85451013 1.33707772]\n",
      " [1.0067088  1.08029037]\n",
      " [1.62114333 1.50425728]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55973228 0.71363631]\n",
      " [0.70151239 0.79200896]\n",
      " [0.73237556 0.74654893]\n",
      " [0.83495275 0.81820858]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01548391]\n",
      " [ 0.00504293]\n",
      " [ 0.01286991]\n",
      " [ 0.02691746]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4961291 ]\n",
      " [0.50126073]\n",
      " [0.50321743]\n",
      " [0.50672896]]\n",
      "Error [[-0.4961291 ]\n",
      " [ 0.49873927]\n",
      " [ 0.49678257]\n",
      " [-0.50672896]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24011802 0.91311159]\n",
      " [0.85470353 1.33706938]\n",
      " [1.00687138 1.08026613]\n",
      " [1.62145689 1.50422392]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55974273 0.71363647]\n",
      " [0.70155288 0.79200759]\n",
      " [0.73240743 0.74654434]\n",
      " [0.83499595 0.81820361]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01552968]\n",
      " [ 0.00504321]\n",
      " [ 0.01288196]\n",
      " [ 0.02695995]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49611766]\n",
      " [0.5012608 ]\n",
      " [0.50322045]\n",
      " [0.50673958]]\n",
      "Error [[-0.49611766]\n",
      " [ 0.4987392 ]\n",
      " [ 0.49677955]\n",
      " [-0.50673958]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24016052 0.91311238]\n",
      " [0.85489731 1.33706103]\n",
      " [1.00703429 1.08024187]\n",
      " [1.62177108 1.50419052]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55975321 0.71363663]\n",
      " [0.70159346 0.79200621]\n",
      " [0.73243935 0.74653975]\n",
      " [0.83503924 0.81819865]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01557547]\n",
      " [ 0.00504351]\n",
      " [ 0.01289402]\n",
      " [ 0.02700248]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49610621]\n",
      " [0.50126088]\n",
      " [0.50322346]\n",
      " [0.50675021]]\n",
      "Error [[-0.49610621]\n",
      " [ 0.49873912]\n",
      " [ 0.49677654]\n",
      " [-0.50675021]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24020311 0.91311318]\n",
      " [0.85509148 1.33705268]\n",
      " [1.00719753 1.08021758]\n",
      " [1.62208591 1.50415708]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5597637  0.71363679]\n",
      " [0.70163411 0.79200484]\n",
      " [0.73247134 0.74653516]\n",
      " [0.8350826  0.81819367]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01562129]\n",
      " [ 0.00504382]\n",
      " [ 0.01290609]\n",
      " [ 0.02704503]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49609476]\n",
      " [0.50126095]\n",
      " [0.50322648]\n",
      " [0.50676085]]\n",
      "Error [[-0.49609476]\n",
      " [ 0.49873905]\n",
      " [ 0.49677352]\n",
      " [-0.50676085]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24024577 0.91311397]\n",
      " [0.85528604 1.33704432]\n",
      " [1.0073611  1.08019326]\n",
      " [1.62240137 1.50412361]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55977421 0.71363695]\n",
      " [0.70167483 0.79200346]\n",
      " [0.73250339 0.74653055]\n",
      " [0.83512604 0.81818869]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01566714]\n",
      " [ 0.00504415]\n",
      " [ 0.01291818]\n",
      " [ 0.02708762]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4960833 ]\n",
      " [0.50126104]\n",
      " [0.5032295 ]\n",
      " [0.50677149]]\n",
      "Error [[-0.4960833 ]\n",
      " [ 0.49873896]\n",
      " [ 0.4967705 ]\n",
      " [-0.50677149]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24028852 0.91311477]\n",
      " [0.85548098 1.33703596]\n",
      " [1.00752499 1.08016892]\n",
      " [1.62271746 1.50409011]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55978475 0.71363712]\n",
      " [0.70171564 0.79200208]\n",
      " [0.73253551 0.74652595]\n",
      " [0.83516956 0.81818371]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01571301]\n",
      " [ 0.00504449]\n",
      " [ 0.01293028]\n",
      " [ 0.02713023]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49607183]\n",
      " [0.50126112]\n",
      " [0.50323252]\n",
      " [0.50678214]]\n",
      "Error [[-0.49607183]\n",
      " [ 0.49873888]\n",
      " [ 0.49676748]\n",
      " [-0.50678214]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24033135 0.91311556]\n",
      " [0.85567631 1.33702758]\n",
      " [1.00768922 1.08014455]\n",
      " [1.62303418 1.50405657]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5597953  0.71363728]\n",
      " [0.70175652 0.7920007 ]\n",
      " [0.73256768 0.74652134]\n",
      " [0.83521316 0.81817872]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01575891]\n",
      " [ 0.00504485]\n",
      " [ 0.01294239]\n",
      " [ 0.02717288]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49606035]\n",
      " [0.50126121]\n",
      " [0.50323555]\n",
      " [0.5067928 ]]\n",
      "Error [[-0.49606035]\n",
      " [ 0.49873879]\n",
      " [ 0.49676445]\n",
      " [-0.5067928 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24037425 0.91311636]\n",
      " [0.85587202 1.3370192 ]\n",
      " [1.00785377 1.08012015]\n",
      " [1.62335154 1.50402299]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55980588 0.71363744]\n",
      " [0.70179748 0.79199932]\n",
      " [0.73259992 0.74651672]\n",
      " [0.83525683 0.81817372]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01580483]\n",
      " [ 0.00504521]\n",
      " [ 0.01295451]\n",
      " [ 0.02721555]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49604887]\n",
      " [0.5012613 ]\n",
      " [0.50323858]\n",
      " [0.50680347]]\n",
      "Error [[-0.49604887]\n",
      " [ 0.4987387 ]\n",
      " [ 0.49676142]\n",
      " [-0.50680347]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24041725 0.91311716]\n",
      " [0.85606812 1.33701082]\n",
      " [1.00801866 1.08009572]\n",
      " [1.62366953 1.50398938]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55981647 0.71363761]\n",
      " [0.70183852 0.79199794]\n",
      " [0.73263222 0.7465121 ]\n",
      " [0.83530058 0.81816872]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01585079]\n",
      " [ 0.0050456 ]\n",
      " [ 0.01296665]\n",
      " [ 0.02725825]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49603739]\n",
      " [0.5012614 ]\n",
      " [0.50324162]\n",
      " [0.50681414]]\n",
      "Error [[-0.49603739]\n",
      " [ 0.4987386 ]\n",
      " [ 0.49675838]\n",
      " [-0.50681414]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24046032 0.91311796]\n",
      " [0.8562646  1.33700242]\n",
      " [1.00818387 1.08007127]\n",
      " [1.62398816 1.50395573]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55982708 0.71363777]\n",
      " [0.70187963 0.79199656]\n",
      " [0.73266458 0.74650747]\n",
      " [0.83534441 0.81816372]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01589676]\n",
      " [ 0.00504599]\n",
      " [ 0.01297881]\n",
      " [ 0.02730099]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49602589]\n",
      " [0.5012615 ]\n",
      " [0.50324466]\n",
      " [0.50682482]]\n",
      "Error [[-0.49602589]\n",
      " [ 0.4987385 ]\n",
      " [ 0.49675534]\n",
      " [-0.50682482]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24050347 0.91311876]\n",
      " [0.85646147 1.33699402]\n",
      " [1.00834942 1.08004679]\n",
      " [1.62430742 1.50392205]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55983772 0.71363793]\n",
      " [0.70192083 0.79199517]\n",
      " [0.732697   0.74650284]\n",
      " [0.83538832 0.81815871]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01594277]\n",
      " [ 0.00504641]\n",
      " [ 0.01299097]\n",
      " [ 0.02734375]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49601439]\n",
      " [0.5012616 ]\n",
      " [0.5032477 ]\n",
      " [0.50683551]]\n",
      "Error [[-0.49601439]\n",
      " [ 0.4987384 ]\n",
      " [ 0.4967523 ]\n",
      " [-0.50683551]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24054671 0.91311956]\n",
      " [0.85665873 1.33698561]\n",
      " [1.00851529 1.08002228]\n",
      " [1.62462731 1.50388833]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55984837 0.7136381 ]\n",
      " [0.7019621  0.79199379]\n",
      " [0.73272949 0.7464982 ]\n",
      " [0.8354323  0.81815369]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0159888 ]\n",
      " [ 0.00504683]\n",
      " [ 0.01300315]\n",
      " [ 0.02738655]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49600289]\n",
      " [0.5012617 ]\n",
      " [0.50325074]\n",
      " [0.50684621]]\n",
      "Error [[-0.49600289]\n",
      " [ 0.4987383 ]\n",
      " [ 0.49674926]\n",
      " [-0.50684621]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24059003 0.91312036]\n",
      " [0.85685638 1.3369772 ]\n",
      " [1.0086815  1.07999774]\n",
      " [1.62494785 1.50385458]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55985905 0.71363826]\n",
      " [0.70200344 0.7919924 ]\n",
      " [0.73276204 0.74649356]\n",
      " [0.83547637 0.81814867]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01603486]\n",
      " [ 0.00504727]\n",
      " [ 0.01301535]\n",
      " [ 0.02742937]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49599137]\n",
      " [0.50126181]\n",
      " [0.50325379]\n",
      " [0.50685691]]\n",
      "Error [[-0.49599137]\n",
      " [ 0.49873819]\n",
      " [ 0.49674621]\n",
      " [-0.50685691]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24063343 0.91312116]\n",
      " [0.85705441 1.33696878]\n",
      " [1.00884804 1.07997317]\n",
      " [1.62526902 1.50382079]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55986974 0.71363842]\n",
      " [0.70204487 0.79199102]\n",
      " [0.73279465 0.74648891]\n",
      " [0.83552051 0.81814364]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01608094]\n",
      " [ 0.00504772]\n",
      " [ 0.01302755]\n",
      " [ 0.02747223]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49597985]\n",
      " [0.50126193]\n",
      " [0.50325684]\n",
      " [0.50686763]]\n",
      "Error [[-0.49597985]\n",
      " [ 0.49873807]\n",
      " [ 0.49674316]\n",
      " [-0.50686763]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24067691 0.91312196]\n",
      " [0.85725284 1.33696035]\n",
      " [1.0090149  1.07994858]\n",
      " [1.62559083 1.50378697]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55988046 0.71363859]\n",
      " [0.70208637 0.79198963]\n",
      " [0.73282732 0.74648425]\n",
      " [0.83556473 0.81813861]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01612705]\n",
      " [ 0.00504819]\n",
      " [ 0.01303977]\n",
      " [ 0.02751512]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49596832]\n",
      " [0.50126205]\n",
      " [0.5032599 ]\n",
      " [0.50687835]]\n",
      "Error [[-0.49596832]\n",
      " [ 0.49873795]\n",
      " [ 0.4967401 ]\n",
      " [-0.50687835]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24072048 0.91312276]\n",
      " [0.85745165 1.33695191]\n",
      " [1.0091821  1.07992396]\n",
      " [1.62591327 1.50375311]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55989119 0.71363875]\n",
      " [0.70212796 0.79198824]\n",
      " [0.73286005 0.74647959]\n",
      " [0.83560903 0.81813357]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01617319]\n",
      " [ 0.00504868]\n",
      " [ 0.01305201]\n",
      " [ 0.02755803]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49595679]\n",
      " [0.50126217]\n",
      " [0.50326296]\n",
      " [0.50688907]]\n",
      "Error [[-0.49595679]\n",
      " [ 0.49873783]\n",
      " [ 0.49673704]\n",
      " [-0.50688907]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24076412 0.91312357]\n",
      " [0.85765084 1.33694347]\n",
      " [1.00934963 1.07989932]\n",
      " [1.62623635 1.50371921]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55990195 0.71363892]\n",
      " [0.70216961 0.79198685]\n",
      " [0.73289285 0.74647493]\n",
      " [0.8356534  0.81812853]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01621936]\n",
      " [ 0.00504917]\n",
      " [ 0.01306426]\n",
      " [ 0.02760098]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49594525]\n",
      " [0.50126229]\n",
      " [0.50326602]\n",
      " [0.50689981]]\n",
      "Error [[-0.49594525]\n",
      " [ 0.49873771]\n",
      " [ 0.49673398]\n",
      " [-0.50689981]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24080785 0.91312437]\n",
      " [0.85785043 1.33693501]\n",
      " [1.0095175  1.07987464]\n",
      " [1.62656007 1.50368528]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55991272 0.71363908]\n",
      " [0.70221135 0.79198545]\n",
      " [0.73292571 0.74647026]\n",
      " [0.83569786 0.81812348]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01626555]\n",
      " [ 0.00504968]\n",
      " [ 0.01307652]\n",
      " [ 0.02764396]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4959337 ]\n",
      " [0.50126242]\n",
      " [0.50326908]\n",
      " [0.50691055]]\n",
      "Error [[-0.4959337 ]\n",
      " [ 0.49873758]\n",
      " [ 0.49673092]\n",
      " [-0.50691055]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24085166 0.91312518]\n",
      " [0.85805041 1.33692656]\n",
      " [1.00968569 1.07984994]\n",
      " [1.62688443 1.50365132]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55992352 0.71363924]\n",
      " [0.70225317 0.79198406]\n",
      " [0.73295863 0.74646558]\n",
      " [0.83574239 0.81811843]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01631177]\n",
      " [ 0.00505021]\n",
      " [ 0.0130888 ]\n",
      " [ 0.02768697]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49592215]\n",
      " [0.50126255]\n",
      " [0.50327215]\n",
      " [0.5069213 ]]\n",
      "Error [[-0.49592215]\n",
      " [ 0.49873745]\n",
      " [ 0.49672785]\n",
      " [-0.5069213 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24089556 0.91312598]\n",
      " [0.85825077 1.33691809]\n",
      " [1.00985422 1.07982521]\n",
      " [1.62720943 1.50361732]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55993433 0.71363941]\n",
      " [0.70229506 0.79198267]\n",
      " [0.73299162 0.7464609 ]\n",
      " [0.835787   0.81811337]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01635802]\n",
      " [ 0.00505075]\n",
      " [ 0.01310108]\n",
      " [ 0.02773001]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49591059]\n",
      " [0.50126269]\n",
      " [0.50327522]\n",
      " [0.50693206]]\n",
      "Error [[-0.49591059]\n",
      " [ 0.49873731]\n",
      " [ 0.49672478]\n",
      " [-0.50693206]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24093953 0.91312679]\n",
      " [0.85845152 1.33690962]\n",
      " [1.01002308 1.07980045]\n",
      " [1.62753507 1.50358328]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55994517 0.71363957]\n",
      " [0.70233703 0.79198127]\n",
      " [0.73302467 0.74645622]\n",
      " [0.83583169 0.8181083 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01640429]\n",
      " [ 0.00505131]\n",
      " [ 0.01311339]\n",
      " [ 0.02777308]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49589902]\n",
      " [0.50126282]\n",
      " [0.5032783 ]\n",
      " [0.50694282]]\n",
      "Error [[-0.49589902]\n",
      " [ 0.49873718]\n",
      " [ 0.4967217 ]\n",
      " [-0.50694282]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24098359 0.9131276 ]\n",
      " [0.85865267 1.33690114]\n",
      " [1.01019227 1.07977566]\n",
      " [1.62786135 1.50354921]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55995602 0.71363974]\n",
      " [0.70237908 0.79197987]\n",
      " [0.73305778 0.74645153]\n",
      " [0.83587646 0.81810323]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01645059]\n",
      " [ 0.00505188]\n",
      " [ 0.01312571]\n",
      " [ 0.02781618]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49588744]\n",
      " [0.50126297]\n",
      " [0.50328138]\n",
      " [0.5069536 ]]\n",
      "Error [[-0.49588744]\n",
      " [ 0.49873703]\n",
      " [ 0.49671862]\n",
      " [-0.5069536 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24102773 0.9131284 ]\n",
      " [0.8588542  1.33689265]\n",
      " [1.0103618  1.07975085]\n",
      " [1.62818828 1.5035151 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5599669  0.7136399 ]\n",
      " [0.70242121 0.79197848]\n",
      " [0.73309095 0.74644683]\n",
      " [0.8359213  0.81809816]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01649692]\n",
      " [ 0.00505246]\n",
      " [ 0.01313804]\n",
      " [ 0.02785932]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49587586]\n",
      " [0.50126311]\n",
      " [0.50328446]\n",
      " [0.50696438]]\n",
      "Error [[-0.49587586]\n",
      " [ 0.49873689]\n",
      " [ 0.49671554]\n",
      " [-0.50696438]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24107195 0.91312921]\n",
      " [0.85905612 1.33688416]\n",
      " [1.01053166 1.07972601]\n",
      " [1.62851584 1.50348096]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5599778  0.71364007]\n",
      " [0.70246341 0.79197708]\n",
      " [0.73312418 0.74644213]\n",
      " [0.83596622 0.81809307]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01654328]\n",
      " [ 0.00505306]\n",
      " [ 0.01315038]\n",
      " [ 0.02790248]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49586427]\n",
      " [0.50126326]\n",
      " [0.50328755]\n",
      " [0.50697517]]\n",
      "Error [[-0.49586427]\n",
      " [ 0.49873674]\n",
      " [ 0.49671245]\n",
      " [-0.50697517]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24111625 0.91313002]\n",
      " [0.85925844 1.33687566]\n",
      " [1.01070185 1.07970114]\n",
      " [1.62884404 1.50344678]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55998871 0.71364023]\n",
      " [0.7025057  0.79197568]\n",
      " [0.73315748 0.74643742]\n",
      " [0.83601122 0.81808799]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01658966]\n",
      " [ 0.00505367]\n",
      " [ 0.01316274]\n",
      " [ 0.02794568]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49585268]\n",
      " [0.50126342]\n",
      " [0.50329064]\n",
      " [0.50698596]]\n",
      "Error [[-0.49585268]\n",
      " [ 0.49873658]\n",
      " [ 0.49670936]\n",
      " [-0.50698596]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24116063 0.91313083]\n",
      " [0.85946114 1.33686715]\n",
      " [1.01087238 1.07967624]\n",
      " [1.62917289 1.50341256]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.55999965 0.7136404 ]\n",
      " [0.70254806 0.79197427]\n",
      " [0.73319084 0.74643271]\n",
      " [0.8360563  0.8180829 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01663608]\n",
      " [ 0.0050543 ]\n",
      " [ 0.01317511]\n",
      " [ 0.0279889 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49584108]\n",
      " [0.50126357]\n",
      " [0.50329373]\n",
      " [0.50699677]]\n",
      "Error [[-0.49584108]\n",
      " [ 0.49873643]\n",
      " [ 0.49670627]\n",
      " [-0.50699677]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2412051  0.91313164]\n",
      " [0.85966424 1.33685864]\n",
      " [1.01104325 1.07965132]\n",
      " [1.62950238 1.50337831]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56001061 0.71364057]\n",
      " [0.7025905  0.79197287]\n",
      " [0.73322426 0.74642799]\n",
      " [0.83610146 0.8180778 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01668252]\n",
      " [ 0.00505494]\n",
      " [ 0.0131875 ]\n",
      " [ 0.02803216]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49582947]\n",
      " [0.50126373]\n",
      " [0.50329683]\n",
      " [0.50700758]]\n",
      "Error [[-0.49582947]\n",
      " [ 0.49873627]\n",
      " [ 0.49670317]\n",
      " [-0.50700758]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24124965 0.91313246]\n",
      " [0.85986772 1.33685012]\n",
      " [1.01121444 1.07962637]\n",
      " [1.62983251 1.50334403]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56002158 0.71364073]\n",
      " [0.70263302 0.79197147]\n",
      " [0.73325775 0.74642327]\n",
      " [0.83614669 0.8180727 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01672898]\n",
      " [ 0.0050556 ]\n",
      " [ 0.0131999 ]\n",
      " [ 0.02807545]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49581785]\n",
      " [0.5012639 ]\n",
      " [0.50329993]\n",
      " [0.5070184 ]]\n",
      "Error [[-0.49581785]\n",
      " [ 0.4987361 ]\n",
      " [ 0.49670007]\n",
      " [-0.5070184 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24129428 0.91313327]\n",
      " [0.8600716  1.33684159]\n",
      " [1.01138597 1.07960138]\n",
      " [1.63016329 1.50330971]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56003258 0.7136409 ]\n",
      " [0.70267561 0.79197006]\n",
      " [0.7332913  0.74641854]\n",
      " [0.83619201 0.81806759]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01677548]\n",
      " [ 0.00505627]\n",
      " [ 0.01321231]\n",
      " [ 0.02811877]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49580623]\n",
      " [0.50126407]\n",
      " [0.50330303]\n",
      " [0.50702923]]\n",
      "Error [[-0.49580623]\n",
      " [ 0.49873593]\n",
      " [ 0.49669697]\n",
      " [-0.50702923]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.241339   0.91313408]\n",
      " [0.86027587 1.33683306]\n",
      " [1.01155784 1.07957638]\n",
      " [1.63049471 1.50327535]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5600436  0.71364106]\n",
      " [0.70271829 0.79196866]\n",
      " [0.73332491 0.74641381]\n",
      " [0.8362374  0.81806247]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01682201]\n",
      " [ 0.00505696]\n",
      " [ 0.01322474]\n",
      " [ 0.02816212]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4957946 ]\n",
      " [0.50126424]\n",
      " [0.50330614]\n",
      " [0.50704007]]\n",
      "Error [[-0.4957946 ]\n",
      " [ 0.49873576]\n",
      " [ 0.49669386]\n",
      " [-0.50704007]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24138379 0.9131349 ]\n",
      " [0.86048053 1.33682451]\n",
      " [1.01173004 1.07955134]\n",
      " [1.63082678 1.50324096]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56005464 0.71364123]\n",
      " [0.70276104 0.79196725]\n",
      " [0.73335858 0.74640907]\n",
      " [0.83628287 0.81805736]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01686856]\n",
      " [ 0.00505766]\n",
      " [ 0.01323719]\n",
      " [ 0.02820551]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49578296]\n",
      " [0.50126441]\n",
      " [0.50330925]\n",
      " [0.50705091]]\n",
      "Error [[-0.49578296]\n",
      " [ 0.49873559]\n",
      " [ 0.49669075]\n",
      " [-0.50705091]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24142867 0.91313571]\n",
      " [0.86068559 1.33681596]\n",
      " [1.01190258 1.07952627]\n",
      " [1.63115949 1.50320653]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56006569 0.7136414 ]\n",
      " [0.70280387 0.79196584]\n",
      " [0.73339232 0.74640432]\n",
      " [0.83632842 0.81805223]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01691514]\n",
      " [ 0.00505838]\n",
      " [ 0.01324964]\n",
      " [ 0.02824892]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49577132]\n",
      " [0.50126459]\n",
      " [0.50331236]\n",
      " [0.50706176]]\n",
      "Error [[-0.49577132]\n",
      " [ 0.49873541]\n",
      " [ 0.49668764]\n",
      " [-0.50706176]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24147363 0.91313653]\n",
      " [0.86089103 1.33680741]\n",
      " [1.01207545 1.07950118]\n",
      " [1.63149285 1.50317206]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56007677 0.71364156]\n",
      " [0.70284678 0.79196443]\n",
      " [0.73342612 0.74639958]\n",
      " [0.83637404 0.8180471 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01696175]\n",
      " [ 0.00505911]\n",
      " [ 0.01326211]\n",
      " [ 0.02829237]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49575966]\n",
      " [0.50126477]\n",
      " [0.50331548]\n",
      " [0.50707262]]\n",
      "Error [[-0.49575966]\n",
      " [ 0.49873523]\n",
      " [ 0.49668452]\n",
      " [-0.50707262]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24151868 0.91313734]\n",
      " [0.86109687 1.33679884]\n",
      " [1.01224866 1.07947606]\n",
      " [1.63182686 1.50313756]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56008787 0.71364173]\n",
      " [0.70288977 0.79196302]\n",
      " [0.73345999 0.74639482]\n",
      " [0.83641975 0.81804197]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01700839]\n",
      " [ 0.00505986]\n",
      " [ 0.0132746 ]\n",
      " [ 0.02833585]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49574801]\n",
      " [0.50126496]\n",
      " [0.5033186 ]\n",
      " [0.50708349]]\n",
      "Error [[-0.49574801]\n",
      " [ 0.49873504]\n",
      " [ 0.4966814 ]\n",
      " [-0.50708349]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2415638  0.91313816]\n",
      " [0.8613031  1.33679027]\n",
      " [1.01242221 1.07945091]\n",
      " [1.63216151 1.50310303]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56009899 0.7136419 ]\n",
      " [0.70293284 0.79196161]\n",
      " [0.73349391 0.74639006]\n",
      " [0.83646553 0.81803683]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01705505]\n",
      " [ 0.00506062]\n",
      " [ 0.0132871 ]\n",
      " [ 0.02837936]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49573634]\n",
      " [0.50126515]\n",
      " [0.50332173]\n",
      " [0.50709436]]\n",
      "Error [[-0.49573634]\n",
      " [ 0.49873485]\n",
      " [ 0.49667827]\n",
      " [-0.50709436]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24160901 0.91313898]\n",
      " [0.86150973 1.3367817 ]\n",
      " [1.01259609 1.07942574]\n",
      " [1.63249681 1.50306845]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56011013 0.71364207]\n",
      " [0.70297598 0.79196019]\n",
      " [0.7335279  0.74638529]\n",
      " [0.83651139 0.81803168]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01710175]\n",
      " [ 0.00506139]\n",
      " [ 0.01329961]\n",
      " [ 0.0284229 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49572467]\n",
      " [0.50126535]\n",
      " [0.50332485]\n",
      " [0.50710525]]\n",
      "Error [[-0.49572467]\n",
      " [ 0.49873465]\n",
      " [ 0.49667515]\n",
      " [-0.50710525]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2416543  0.9131398 ]\n",
      " [0.86171675 1.33677311]\n",
      " [1.01277031 1.07940053]\n",
      " [1.63283275 1.50303384]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56012129 0.71364223]\n",
      " [0.70301921 0.79195878]\n",
      " [0.73356195 0.74638052]\n",
      " [0.83655733 0.81802653]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01714847]\n",
      " [ 0.00506218]\n",
      " [ 0.01331214]\n",
      " [ 0.02846647]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49571299]\n",
      " [0.50126554]\n",
      " [0.50332799]\n",
      " [0.50711614]]\n",
      "Error [[-0.49571299]\n",
      " [ 0.49873446]\n",
      " [ 0.49667201]\n",
      " [-0.50711614]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24169968 0.91314062]\n",
      " [0.86192416 1.33676452]\n",
      " [1.01294486 1.0793753 ]\n",
      " [1.63316935 1.5029992 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56013246 0.7136424 ]\n",
      " [0.70306251 0.79195736]\n",
      " [0.73359607 0.74637575]\n",
      " [0.83660335 0.81802137]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01719522]\n",
      " [ 0.00506299]\n",
      " [ 0.01332468]\n",
      " [ 0.02851008]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4957013 ]\n",
      " [0.50126575]\n",
      " [0.50333112]\n",
      " [0.50712704]]\n",
      "Error [[-0.4957013 ]\n",
      " [ 0.49873425]\n",
      " [ 0.49666888]\n",
      " [-0.50712704]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24174513 0.91314144]\n",
      " [0.86213197 1.33675592]\n",
      " [1.01311976 1.07935004]\n",
      " [1.63350659 1.50296452]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56014366 0.71364257]\n",
      " [0.70310589 0.79195595]\n",
      " [0.73363025 0.74637096]\n",
      " [0.83664944 0.81801621]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.017242  ]\n",
      " [ 0.00506381]\n",
      " [ 0.01333724]\n",
      " [ 0.02855372]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49568961]\n",
      " [0.50126595]\n",
      " [0.50333426]\n",
      " [0.50713794]]\n",
      "Error [[-0.49568961]\n",
      " [ 0.49873405]\n",
      " [ 0.49666574]\n",
      " [-0.50713794]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24179067 0.91314226]\n",
      " [0.86234017 1.33674732]\n",
      " [1.01329499 1.07932475]\n",
      " [1.63384449 1.5029298 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56015488 0.71364274]\n",
      " [0.70314935 0.79195453]\n",
      " [0.73366449 0.74636618]\n",
      " [0.83669561 0.81801104]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01728881]\n",
      " [ 0.00506465]\n",
      " [ 0.01334981]\n",
      " [ 0.02859739]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4956779 ]\n",
      " [0.50126616]\n",
      " [0.5033374 ]\n",
      " [0.50714886]]\n",
      "Error [[-0.4956779 ]\n",
      " [ 0.49873384]\n",
      " [ 0.4966626 ]\n",
      " [-0.50714886]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24183629 0.91314308]\n",
      " [0.86254876 1.33673871]\n",
      " [1.01347056 1.07929943]\n",
      " [1.63418303 1.50289505]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56016612 0.7136429 ]\n",
      " [0.70319289 0.79195311]\n",
      " [0.73369879 0.74636138]\n",
      " [0.83674187 0.81800587]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01733565]\n",
      " [ 0.0050655 ]\n",
      " [ 0.01336239]\n",
      " [ 0.02864109]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4956662 ]\n",
      " [0.50126637]\n",
      " [0.50334055]\n",
      " [0.50715978]]\n",
      "Error [[-0.4956662 ]\n",
      " [ 0.49873363]\n",
      " [ 0.49665945]\n",
      " [-0.50715978]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24188199 0.91314391]\n",
      " [0.86275775 1.33673009]\n",
      " [1.01364646 1.07927408]\n",
      " [1.63452222 1.50286026]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56017738 0.71364307]\n",
      " [0.70323651 0.79195169]\n",
      " [0.73373316 0.74635659]\n",
      " [0.8367882  0.81800069]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01738252]\n",
      " [ 0.00506637]\n",
      " [ 0.01337499]\n",
      " [ 0.02868483]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49565448]\n",
      " [0.50126659]\n",
      " [0.5033437 ]\n",
      " [0.50717072]]\n",
      "Error [[-0.49565448]\n",
      " [ 0.49873341]\n",
      " [ 0.4966563 ]\n",
      " [-0.50717072]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24192778 0.91314473]\n",
      " [0.86296714 1.33672146]\n",
      " [1.01382271 1.07924871]\n",
      " [1.63486207 1.50282544]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56018867 0.71364324]\n",
      " [0.7032802  0.79195027]\n",
      " [0.73376759 0.74635178]\n",
      " [0.83683461 0.8179955 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01742942]\n",
      " [ 0.00506725]\n",
      " [ 0.01338761]\n",
      " [ 0.02872859]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49564276]\n",
      " [0.50126681]\n",
      " [0.50334685]\n",
      " [0.50718165]]\n",
      "Error [[-0.49564276]\n",
      " [ 0.49873319]\n",
      " [ 0.49665315]\n",
      " [-0.50718165]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24197365 0.91314555]\n",
      " [0.86317692 1.33671283]\n",
      " [1.01399929 1.07922331]\n",
      " [1.63520256 1.50279058]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56019997 0.71364341]\n",
      " [0.70332398 0.79194885]\n",
      " [0.73380209 0.74634697]\n",
      " [0.83688109 0.81799031]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01747635]\n",
      " [ 0.00506814]\n",
      " [ 0.01340024]\n",
      " [ 0.02877239]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49563102]\n",
      " [0.50126703]\n",
      " [0.50335001]\n",
      " [0.5071926 ]]\n",
      "Error [[-0.49563102]\n",
      " [ 0.49873297]\n",
      " [ 0.49664999]\n",
      " [-0.5071926 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2420196  0.91314638]\n",
      " [0.8633871  1.33670419]\n",
      " [1.01417621 1.07919788]\n",
      " [1.63554371 1.50275568]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56021129 0.71364358]\n",
      " [0.70336783 0.79194742]\n",
      " [0.73383665 0.74634216]\n",
      " [0.83692766 0.81798512]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0175233 ]\n",
      " [ 0.00506905]\n",
      " [ 0.01341288]\n",
      " [ 0.02881623]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49561929]\n",
      " [0.50126726]\n",
      " [0.50335317]\n",
      " [0.50720356]]\n",
      "Error [[-0.49561929]\n",
      " [ 0.49873274]\n",
      " [ 0.49664683]\n",
      " [-0.50720356]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24206563 0.91314721]\n",
      " [0.86359767 1.33669554]\n",
      " [1.01435348 1.07917242]\n",
      " [1.63588551 1.50272075]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56022263 0.71364375]\n",
      " [0.70341176 0.791946  ]\n",
      " [0.73387127 0.74633734]\n",
      " [0.8369743  0.81797992]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01757029]\n",
      " [ 0.00506998]\n",
      " [ 0.01342554]\n",
      " [ 0.02886009]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49560754]\n",
      " [0.50126749]\n",
      " [0.50335633]\n",
      " [0.50721452]]\n",
      "Error [[-0.49560754]\n",
      " [ 0.49873251]\n",
      " [ 0.49664367]\n",
      " [-0.50721452]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24211175 0.91314803]\n",
      " [0.86380864 1.33668688]\n",
      " [1.01453108 1.07914693]\n",
      " [1.63622797 1.50268578]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56023399 0.71364392]\n",
      " [0.70345577 0.79194457]\n",
      " [0.73390595 0.74633251]\n",
      " [0.83702102 0.81797471]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0176173 ]\n",
      " [ 0.00507092]\n",
      " [ 0.01343821]\n",
      " [ 0.02890399]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49559579]\n",
      " [0.50126773]\n",
      " [0.5033595 ]\n",
      " [0.50722549]]\n",
      "Error [[-0.49559579]\n",
      " [ 0.49873227]\n",
      " [ 0.4966405 ]\n",
      " [-0.50722549]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24215795 0.91314886]\n",
      " [0.86402001 1.33667822]\n",
      " [1.01470902 1.07912141]\n",
      " [1.63657107 1.50265078]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56024537 0.71364408]\n",
      " [0.70349986 0.79194315]\n",
      " [0.7339407  0.74632768]\n",
      " [0.83706782 0.8179695 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01766435]\n",
      " [ 0.00507188]\n",
      " [ 0.0134509 ]\n",
      " [ 0.02894792]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49558403]\n",
      " [0.50126797]\n",
      " [0.50336267]\n",
      " [0.50723647]]\n",
      "Error [[-0.49558403]\n",
      " [ 0.49873203]\n",
      " [ 0.49663733]\n",
      " [-0.50723647]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24220423 0.91314969]\n",
      " [0.86423177 1.33666956]\n",
      " [1.0148873  1.07909587]\n",
      " [1.63691484 1.50261574]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56025678 0.71364425]\n",
      " [0.70354403 0.79194172]\n",
      " [0.73397551 0.74632285]\n",
      " [0.8371147  0.81796428]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01771142]\n",
      " [ 0.00507285]\n",
      " [ 0.0134636 ]\n",
      " [ 0.02899188]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49557226]\n",
      " [0.50126821]\n",
      " [0.50336585]\n",
      " [0.50724746]]\n",
      "Error [[-0.49557226]\n",
      " [ 0.49873179]\n",
      " [ 0.49663415]\n",
      " [-0.50724746]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2422506  0.91315052]\n",
      " [0.86444393 1.33666088]\n",
      " [1.01506592 1.0790703 ]\n",
      " [1.63725925 1.50258066]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5602682  0.71364442]\n",
      " [0.70358828 0.79194029]\n",
      " [0.73401039 0.74631801]\n",
      " [0.83716166 0.81795906]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01775852]\n",
      " [ 0.00507384]\n",
      " [ 0.01347631]\n",
      " [ 0.02903588]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49556049]\n",
      " [0.50126846]\n",
      " [0.50336903]\n",
      " [0.50725846]]\n",
      "Error [[-0.49556049]\n",
      " [ 0.49873154]\n",
      " [ 0.49663097]\n",
      " [-0.50725846]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24229704 0.91315135]\n",
      " [0.86465648 1.3366522 ]\n",
      " [1.01524488 1.0790447 ]\n",
      " [1.63760432 1.50254555]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56027964 0.71364459]\n",
      " [0.70363261 0.79193886]\n",
      " [0.73404533 0.74631316]\n",
      " [0.83720869 0.81795383]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01780566]\n",
      " [ 0.00507484]\n",
      " [ 0.01348904]\n",
      " [ 0.0290799 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4955487 ]\n",
      " [0.50126871]\n",
      " [0.50337221]\n",
      " [0.50726946]]\n",
      "Error [[-0.4955487 ]\n",
      " [ 0.49873129]\n",
      " [ 0.49662779]\n",
      " [-0.50726946]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24234357 0.91315218]\n",
      " [0.86486944 1.33664351]\n",
      " [1.01542418 1.07901907]\n",
      " [1.63795005 1.5025104 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5602911  0.71364476]\n",
      " [0.70367701 0.79193743]\n",
      " [0.73408033 0.74630831]\n",
      " [0.83725581 0.81794859]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01785282]\n",
      " [ 0.00507586]\n",
      " [ 0.01350179]\n",
      " [ 0.02912397]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49553691]\n",
      " [0.50126896]\n",
      " [0.5033754 ]\n",
      " [0.50728048]]\n",
      "Error [[-0.49553691]\n",
      " [ 0.49873104]\n",
      " [ 0.4966246 ]\n",
      " [-0.50728048]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24239019 0.91315301]\n",
      " [0.86508279 1.33663481]\n",
      " [1.01560383 1.07899341]\n",
      " [1.63829643 1.50247521]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56030259 0.71364493]\n",
      " [0.7037215  0.79193599]\n",
      " [0.73411539 0.74630345]\n",
      " [0.837303   0.81794336]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01790001]\n",
      " [ 0.0050769 ]\n",
      " [ 0.01351455]\n",
      " [ 0.02916806]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49552512]\n",
      " [0.50126922]\n",
      " [0.50337859]\n",
      " [0.5072915 ]]\n",
      "Error [[-0.49552512]\n",
      " [ 0.49873078]\n",
      " [ 0.49662141]\n",
      " [-0.5072915 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24243688 0.91315384]\n",
      " [0.86529654 1.33662611]\n",
      " [1.01578381 1.07896772]\n",
      " [1.63864347 1.50243999]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56031409 0.7136451 ]\n",
      " [0.70376606 0.79193456]\n",
      " [0.73415052 0.74629858]\n",
      " [0.83735027 0.81793811]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01794724]\n",
      " [ 0.00507795]\n",
      " [ 0.01352732]\n",
      " [ 0.02921219]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49551331]\n",
      " [0.50126948]\n",
      " [0.50338178]\n",
      " [0.50730253]]\n",
      "Error [[-0.49551331]\n",
      " [ 0.49873052]\n",
      " [ 0.49661822]\n",
      " [-0.50730253]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24248366 0.91315468]\n",
      " [0.86551069 1.3366174 ]\n",
      " [1.01596414 1.07894201]\n",
      " [1.63899117 1.50240473]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56032562 0.71364527]\n",
      " [0.70381071 0.79193312]\n",
      " [0.73418572 0.74629372]\n",
      " [0.83739762 0.81793286]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01799449]\n",
      " [ 0.00507901]\n",
      " [ 0.01354011]\n",
      " [ 0.02925635]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4955015 ]\n",
      " [0.50126975]\n",
      " [0.50338498]\n",
      " [0.50731356]]\n",
      "Error [[-0.4955015 ]\n",
      " [ 0.49873025]\n",
      " [ 0.49661502]\n",
      " [-0.50731356]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24253052 0.91315551]\n",
      " [0.86572524 1.33660868]\n",
      " [1.01614481 1.07891626]\n",
      " [1.63933952 1.50236944]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56033716 0.71364544]\n",
      " [0.70385543 0.79193169]\n",
      " [0.73422097 0.74628884]\n",
      " [0.83744505 0.8179276 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01804177]\n",
      " [ 0.00508009]\n",
      " [ 0.01355291]\n",
      " [ 0.02930054]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49548968]\n",
      " [0.50127002]\n",
      " [0.50338818]\n",
      " [0.50732461]]\n",
      "Error [[-0.49548968]\n",
      " [ 0.49872998]\n",
      " [ 0.49661182]\n",
      " [-0.50732461]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24257747 0.91315635]\n",
      " [0.86594018 1.33659996]\n",
      " [1.01632582 1.07889049]\n",
      " [1.63968853 1.50233411]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56034873 0.71364561]\n",
      " [0.70390023 0.79193025]\n",
      " [0.7342563  0.74628396]\n",
      " [0.83749255 0.81792234]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01808909]\n",
      " [ 0.00508119]\n",
      " [ 0.01356573]\n",
      " [ 0.02934477]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49547785]\n",
      " [0.50127029]\n",
      " [0.50339138]\n",
      " [0.50733567]]\n",
      "Error [[-0.49547785]\n",
      " [ 0.49872971]\n",
      " [ 0.49660862]\n",
      " [-0.50733567]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24262449 0.91315718]\n",
      " [0.86615553 1.33659123]\n",
      " [1.01650717 1.07886469]\n",
      " [1.6400382  1.50229874]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56036031 0.71364579]\n",
      " [0.70394511 0.79192881]\n",
      " [0.73429168 0.74627908]\n",
      " [0.83754014 0.81791707]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01813643]\n",
      " [ 0.0050823 ]\n",
      " [ 0.01357857]\n",
      " [ 0.02938903]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49546602]\n",
      " [0.50127057]\n",
      " [0.50339459]\n",
      " [0.50734673]]\n",
      "Error [[-0.49546602]\n",
      " [ 0.49872943]\n",
      " [ 0.49660541]\n",
      " [-0.50734673]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2426716  0.91315802]\n",
      " [0.86637127 1.33658249]\n",
      " [1.01668887 1.07883886]\n",
      " [1.64038853 1.50226334]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56037192 0.71364596]\n",
      " [0.70399008 0.79192737]\n",
      " [0.73432713 0.74627419]\n",
      " [0.8375878  0.8179118 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01818381]\n",
      " [ 0.00508343]\n",
      " [ 0.01359141]\n",
      " [ 0.02943332]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49545417]\n",
      " [0.50127085]\n",
      " [0.5033978 ]\n",
      " [0.5073578 ]]\n",
      "Error [[-0.49545417]\n",
      " [ 0.49872915]\n",
      " [ 0.4966022 ]\n",
      " [-0.5073578 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2427188  0.91315886]\n",
      " [0.86658742 1.33657375]\n",
      " [1.0168709  1.078813  ]\n",
      " [1.64073952 1.5022279 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56038355 0.71364613]\n",
      " [0.70403512 0.79192593]\n",
      " [0.73436264 0.74626929]\n",
      " [0.83763554 0.81790652]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01823121]\n",
      " [ 0.00508457]\n",
      " [ 0.01360428]\n",
      " [ 0.02947765]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49544232]\n",
      " [0.50127114]\n",
      " [0.50340102]\n",
      " [0.50736888]]\n",
      "Error [[-0.49544232]\n",
      " [ 0.49872886]\n",
      " [ 0.49659898]\n",
      " [-0.50736888]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24276607 0.91315969]\n",
      " [0.86680396 1.33656499]\n",
      " [1.01705328 1.07878712]\n",
      " [1.64109117 1.50219242]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56039519 0.7136463 ]\n",
      " [0.70408023 0.79192449]\n",
      " [0.73439822 0.74626439]\n",
      " [0.83768336 0.81790124]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01827865]\n",
      " [ 0.00508573]\n",
      " [ 0.01361716]\n",
      " [ 0.02952201]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49543047]\n",
      " [0.50127143]\n",
      " [0.50340424]\n",
      " [0.50737997]]\n",
      "Error [[-0.49543047]\n",
      " [ 0.49872857]\n",
      " [ 0.49659576]\n",
      " [-0.50737997]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24281343 0.91316053]\n",
      " [0.86702091 1.33655624]\n",
      " [1.01723601 1.0787612 ]\n",
      " [1.64144349 1.50215691]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56040686 0.71364647]\n",
      " [0.70412543 0.79192305]\n",
      " [0.73443386 0.74625948]\n",
      " [0.83773126 0.81789595]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01832612]\n",
      " [ 0.0050869 ]\n",
      " [ 0.01363005]\n",
      " [ 0.0295664 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4954186 ]\n",
      " [0.50127172]\n",
      " [0.50340746]\n",
      " [0.50739106]]\n",
      "Error [[-0.4954186 ]\n",
      " [ 0.49872828]\n",
      " [ 0.49659254]\n",
      " [-0.50739106]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24286088 0.91316137]\n",
      " [0.86723826 1.33654747]\n",
      " [1.01741908 1.07873526]\n",
      " [1.64179646 1.50212136]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56041855 0.71364664]\n",
      " [0.70417071 0.7919216 ]\n",
      " [0.73446956 0.74625457]\n",
      " [0.83777923 0.81789066]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01837361]\n",
      " [ 0.00508809]\n",
      " [ 0.01364296]\n",
      " [ 0.02961083]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49540673]\n",
      " [0.50127202]\n",
      " [0.50341069]\n",
      " [0.50740217]]\n",
      "Error [[-0.49540673]\n",
      " [ 0.49872798]\n",
      " [ 0.49658931]\n",
      " [-0.50740217]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggrigation in hidden layer\n",
      "[[0.2429084  0.91316221]\n",
      " [0.867456   1.3365387 ]\n",
      " [1.01760249 1.07870929]\n",
      " [1.64215009 1.50208577]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56043025 0.71364681]\n",
      " [0.70421607 0.79192016]\n",
      " [0.73450533 0.74624965]\n",
      " [0.83782729 0.81788536]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01842114]\n",
      " [ 0.00508929]\n",
      " [ 0.01365588]\n",
      " [ 0.02965529]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49539484]\n",
      " [0.50127232]\n",
      " [0.50341392]\n",
      " [0.50741328]]\n",
      "Error [[-0.49539484]\n",
      " [ 0.49872768]\n",
      " [ 0.49658608]\n",
      " [-0.50741328]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24295601 0.91316306]\n",
      " [0.86767415 1.33652992]\n",
      " [1.01778625 1.07868328]\n",
      " [1.64250439 1.50205015]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56044198 0.71364699]\n",
      " [0.70426151 0.79191871]\n",
      " [0.73454116 0.74624473]\n",
      " [0.83787542 0.81788005]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0184687 ]\n",
      " [ 0.00509052]\n",
      " [ 0.01366882]\n",
      " [ 0.02969978]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49538296]\n",
      " [0.50127263]\n",
      " [0.50341715]\n",
      " [0.5074244 ]]\n",
      "Error [[-0.49538296]\n",
      " [ 0.49872737]\n",
      " [ 0.49658285]\n",
      " [-0.5074244 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2430037  0.9131639 ]\n",
      " [0.8678927  1.33652113]\n",
      " [1.01797035 1.07865725]\n",
      " [1.64285935 1.50201449]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56045373 0.71364716]\n",
      " [0.70430702 0.79191726]\n",
      " [0.73457706 0.7462398 ]\n",
      " [0.83792363 0.81787474]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01851629]\n",
      " [ 0.00509175]\n",
      " [ 0.01368177]\n",
      " [ 0.02974431]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49537106]\n",
      " [0.50127294]\n",
      " [0.50342039]\n",
      " [0.50743553]]\n",
      "Error [[-0.49537106]\n",
      " [ 0.49872706]\n",
      " [ 0.49657961]\n",
      " [-0.50743553]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24305148 0.91316474]\n",
      " [0.86811165 1.33651234]\n",
      " [1.0181548  1.0786312 ]\n",
      " [1.64321497 1.50197879]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5604655  0.71364733]\n",
      " [0.70435262 0.79191581]\n",
      " [0.73461302 0.74623486]\n",
      " [0.83797192 0.81786942]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01856391]\n",
      " [ 0.005093  ]\n",
      " [ 0.01369474]\n",
      " [ 0.02978887]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49535915]\n",
      " [0.50127325]\n",
      " [0.50342363]\n",
      " [0.50744667]]\n",
      "Error [[-0.49535915]\n",
      " [ 0.49872675]\n",
      " [ 0.49657637]\n",
      " [-0.50744667]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24309934 0.91316559]\n",
      " [0.86833101 1.33650354]\n",
      " [1.01833959 1.07860511]\n",
      " [1.64357126 1.50194306]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56047729 0.7136475 ]\n",
      " [0.7043983  0.79191436]\n",
      " [0.73464905 0.74622992]\n",
      " [0.83802029 0.8178641 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01861157]\n",
      " [ 0.00509427]\n",
      " [ 0.01370772]\n",
      " [ 0.02983347]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49534724]\n",
      " [0.50127357]\n",
      " [0.50342688]\n",
      " [0.50745781]]\n",
      "Error [[-0.49534724]\n",
      " [ 0.49872643]\n",
      " [ 0.49657312]\n",
      " [-0.50745781]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24314728 0.91316643]\n",
      " [0.86855076 1.33649473]\n",
      " [1.01852472 1.07857899]\n",
      " [1.64392821 1.50190729]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5604891  0.71364768]\n",
      " [0.70444405 0.79191291]\n",
      " [0.73468513 0.74622498]\n",
      " [0.83806874 0.81785877]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01865925]\n",
      " [ 0.00509556]\n",
      " [ 0.01372072]\n",
      " [ 0.0298781 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49533532]\n",
      " [0.50127389]\n",
      " [0.50343013]\n",
      " [0.50746897]]\n",
      "Error [[-0.49533532]\n",
      " [ 0.49872611]\n",
      " [ 0.49656987]\n",
      " [-0.50746897]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2431953  0.91316728]\n",
      " [0.86877092 1.33648592]\n",
      " [1.01871021 1.07855285]\n",
      " [1.64428583 1.50187149]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56050093 0.71364785]\n",
      " [0.70448989 0.79191146]\n",
      " [0.73472129 0.74622003]\n",
      " [0.83811727 0.81785344]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01870697]\n",
      " [ 0.00509686]\n",
      " [ 0.01373374]\n",
      " [ 0.02992277]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49532339]\n",
      " [0.50127421]\n",
      " [0.50343338]\n",
      " [0.50748013]]\n",
      "Error [[-0.49532339]\n",
      " [ 0.49872579]\n",
      " [ 0.49656662]\n",
      " [-0.50748013]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24324341 0.91316812]\n",
      " [0.86899148 1.3364771 ]\n",
      " [1.01889604 1.07852667]\n",
      " [1.64464411 1.50183565]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56051278 0.71364802]\n",
      " [0.7045358  0.79191   ]\n",
      " [0.7347575  0.74621507]\n",
      " [0.83816587 0.8178481 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01875471]\n",
      " [ 0.00509817]\n",
      " [ 0.01374677]\n",
      " [ 0.02996746]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49531146]\n",
      " [0.50127454]\n",
      " [0.50343664]\n",
      " [0.50749131]]\n",
      "Error [[-0.49531146]\n",
      " [ 0.49872546]\n",
      " [ 0.49656336]\n",
      " [-0.50749131]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2432916  0.91316897]\n",
      " [0.86921245 1.33646827]\n",
      " [1.01908221 1.07850047]\n",
      " [1.64500306 1.50179977]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56052465 0.71364819]\n",
      " [0.7045818  0.79190855]\n",
      " [0.73479379 0.74621011]\n",
      " [0.83821456 0.81784275]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01880249]\n",
      " [ 0.00509951]\n",
      " [ 0.01375981]\n",
      " [ 0.0300122 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49529952]\n",
      " [0.50127487]\n",
      " [0.5034399 ]\n",
      " [0.50750249]]\n",
      "Error [[-0.49529952]\n",
      " [ 0.49872513]\n",
      " [ 0.4965601 ]\n",
      " [-0.50750249]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24333987 0.91316982]\n",
      " [0.86943382 1.33645944]\n",
      " [1.01926873 1.07847423]\n",
      " [1.64536267 1.50176385]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56053654 0.71364837]\n",
      " [0.70462787 0.79190709]\n",
      " [0.73483013 0.74620514]\n",
      " [0.83826332 0.8178374 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0188503 ]\n",
      " [ 0.00510085]\n",
      " [ 0.01377287]\n",
      " [ 0.03005696]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49528756]\n",
      " [0.50127521]\n",
      " [0.50344316]\n",
      " [0.50751368]]\n",
      "Error [[-0.49528756]\n",
      " [ 0.49872479]\n",
      " [ 0.49655684]\n",
      " [-0.50751368]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24338823 0.91317067]\n",
      " [0.86965559 1.33645059]\n",
      " [1.0194556  1.07844797]\n",
      " [1.64572296 1.5017279 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56054846 0.71364854]\n",
      " [0.70467403 0.79190564]\n",
      " [0.73486654 0.74620016]\n",
      " [0.83831216 0.81783204]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01889815]\n",
      " [ 0.00510222]\n",
      " [ 0.01378595]\n",
      " [ 0.03010177]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4952756 ]\n",
      " [0.50127555]\n",
      " [0.50344643]\n",
      " [0.50752487]]\n",
      "Error [[-0.4952756 ]\n",
      " [ 0.49872445]\n",
      " [ 0.49655357]\n",
      " [-0.50752487]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24343667 0.91317152]\n",
      " [0.86987776 1.33644175]\n",
      " [1.01964281 1.07842168]\n",
      " [1.64608391 1.50169191]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56056039 0.71364871]\n",
      " [0.70472026 0.79190418]\n",
      " [0.73490302 0.74619519]\n",
      " [0.83836108 0.81782668]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01894602]\n",
      " [ 0.0051036 ]\n",
      " [ 0.01379904]\n",
      " [ 0.0301466 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49526364]\n",
      " [0.5012759 ]\n",
      " [0.5034497 ]\n",
      " [0.50753608]]\n",
      "Error [[-0.49526364]\n",
      " [ 0.4987241 ]\n",
      " [ 0.4965503 ]\n",
      " [-0.50753608]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2434852  0.91317237]\n",
      " [0.87010034 1.33643289]\n",
      " [1.01983038 1.07839536]\n",
      " [1.64644553 1.50165588]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56057234 0.71364889]\n",
      " [0.70476658 0.79190272]\n",
      " [0.73493956 0.7461902 ]\n",
      " [0.83841007 0.81782132]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01899393]\n",
      " [ 0.00510499]\n",
      " [ 0.01381214]\n",
      " [ 0.03019147]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49525166]\n",
      " [0.50127625]\n",
      " [0.50345298]\n",
      " [0.50754729]]\n",
      "Error [[-0.49525166]\n",
      " [ 0.49872375]\n",
      " [ 0.49654702]\n",
      " [-0.50754729]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2435338  0.91317322]\n",
      " [0.87032333 1.33642403]\n",
      " [1.02001829 1.07836901]\n",
      " [1.64680781 1.50161982]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56058431 0.71364906]\n",
      " [0.70481297 0.79190126]\n",
      " [0.73497616 0.74618521]\n",
      " [0.83845915 0.81781594]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01904186]\n",
      " [ 0.00510641]\n",
      " [ 0.01382526]\n",
      " [ 0.03023638]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49523968]\n",
      " [0.5012766 ]\n",
      " [0.50345626]\n",
      " [0.50755852]]\n",
      "Error [[-0.49523968]\n",
      " [ 0.4987234 ]\n",
      " [ 0.49654374]\n",
      " [-0.50755852]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24358249 0.91317407]\n",
      " [0.87054672 1.33641516]\n",
      " [1.02020655 1.07834264]\n",
      " [1.64717077 1.50158372]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56059631 0.71364924]\n",
      " [0.70485945 0.7918998 ]\n",
      " [0.73501283 0.74618021]\n",
      " [0.83850831 0.81781056]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01908983]\n",
      " [ 0.00510783]\n",
      " [ 0.0138384 ]\n",
      " [ 0.03028132]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49522769]\n",
      " [0.50127696]\n",
      " [0.50345954]\n",
      " [0.50756975]]\n",
      "Error [[-0.49522769]\n",
      " [ 0.49872304]\n",
      " [ 0.49654046]\n",
      " [-0.50756975]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24363127 0.91317493]\n",
      " [0.87077052 1.33640628]\n",
      " [1.02039515 1.07831623]\n",
      " [1.6475344  1.50154759]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56060832 0.71364941]\n",
      " [0.704906   0.79189833]\n",
      " [0.73504956 0.74617521]\n",
      " [0.83855754 0.81780518]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01913784]\n",
      " [ 0.00510928]\n",
      " [ 0.01385155]\n",
      " [ 0.03032629]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49521569]\n",
      " [0.50127732]\n",
      " [0.50346283]\n",
      " [0.50758099]]\n",
      "Error [[-0.49521569]\n",
      " [ 0.49872268]\n",
      " [ 0.49653717]\n",
      " [-0.50758099]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24368013 0.91317578]\n",
      " [0.87099472 1.3363974 ]\n",
      " [1.02058411 1.07828979]\n",
      " [1.6478987  1.50151141]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56062036 0.71364959]\n",
      " [0.70495264 0.79189687]\n",
      " [0.73508636 0.74617021]\n",
      " [0.83860685 0.81779979]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01918587]\n",
      " [ 0.00511074]\n",
      " [ 0.01386472]\n",
      " [ 0.0303713 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49520368]\n",
      " [0.50127768]\n",
      " [0.50346612]\n",
      " [0.50759224]]\n",
      "Error [[-0.49520368]\n",
      " [ 0.49872232]\n",
      " [ 0.49653388]\n",
      " [-0.50759224]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24372907 0.91317664]\n",
      " [0.87121932 1.33638851]\n",
      " [1.02077341 1.07826333]\n",
      " [1.64826366 1.5014752 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56063241 0.71364976]\n",
      " [0.70499935 0.79189541]\n",
      " [0.73512322 0.74616519]\n",
      " [0.83865624 0.81779439]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01923394]\n",
      " [ 0.00511222]\n",
      " [ 0.0138779 ]\n",
      " [ 0.03041634]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49519166]\n",
      " [0.50127805]\n",
      " [0.50346942]\n",
      " [0.5076035 ]]\n",
      "Error [[-0.49519166]\n",
      " [ 0.49872195]\n",
      " [ 0.49653058]\n",
      " [-0.5076035 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24377809 0.91317749]\n",
      " [0.87144433 1.33637962]\n",
      " [1.02096306 1.07823684]\n",
      " [1.64862931 1.50143896]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56064449 0.71364994]\n",
      " [0.70504615 0.79189394]\n",
      " [0.73516015 0.74616018]\n",
      " [0.83870571 0.81778899]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01928204]\n",
      " [ 0.00511371]\n",
      " [ 0.0138911 ]\n",
      " [ 0.03046142]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49517964]\n",
      " [0.50127842]\n",
      " [0.50347272]\n",
      " [0.50761477]]\n",
      "Error [[-0.49517964]\n",
      " [ 0.49872158]\n",
      " [ 0.49652728]\n",
      " [-0.50761477]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2438272  0.91317835]\n",
      " [0.87166975 1.33637071]\n",
      " [1.02115306 1.07821031]\n",
      " [1.64899562 1.50140267]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56065659 0.71365011]\n",
      " [0.70509302 0.79189247]\n",
      " [0.73519714 0.74615515]\n",
      " [0.83875526 0.81778359]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01933017]\n",
      " [ 0.00511522]\n",
      " [ 0.01390432]\n",
      " [ 0.03050654]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49516761]\n",
      " [0.5012788 ]\n",
      " [0.50347602]\n",
      " [0.50762604]]\n",
      "Error [[-0.49516761]\n",
      " [ 0.4987212 ]\n",
      " [ 0.49652398]\n",
      " [-0.50762604]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24387639 0.91317921]\n",
      " [0.87189558 1.3363618 ]\n",
      " [1.02134341 1.07818376]\n",
      " [1.6493626  1.50136635]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5606687  0.71365029]\n",
      " [0.70513998 0.791891  ]\n",
      " [0.7352342  0.74615012]\n",
      " [0.83880489 0.81777817]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01937833]\n",
      " [ 0.00511674]\n",
      " [ 0.01391755]\n",
      " [ 0.03055169]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49515557]\n",
      " [0.50127918]\n",
      " [0.50347933]\n",
      " [0.50763733]]\n",
      "Error [[-0.49515557]\n",
      " [ 0.49872082]\n",
      " [ 0.49652067]\n",
      " [-0.50763733]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24392566 0.91318007]\n",
      " [0.87212181 1.33635288]\n",
      " [1.02153412 1.07815718]\n",
      " [1.64973026 1.50132999]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56068084 0.71365046]\n",
      " [0.70518701 0.79188953]\n",
      " [0.73527132 0.74614509]\n",
      " [0.83885459 0.81777276]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01942653]\n",
      " [ 0.00511829]\n",
      " [ 0.01393079]\n",
      " [ 0.03059687]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49514352]\n",
      " [0.50127957]\n",
      " [0.50348264]\n",
      " [0.50764862]]\n",
      "Error [[-0.49514352]\n",
      " [ 0.49872043]\n",
      " [ 0.49651736]\n",
      " [-0.50764862]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24397502 0.91318093]\n",
      " [0.87234845 1.33634396]\n",
      " [1.02172517 1.07813057]\n",
      " [1.65009859 1.5012936 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.560693   0.71365064]\n",
      " [0.70523413 0.79188806]\n",
      " [0.7353085  0.74614005]\n",
      " [0.83890438 0.81776733]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01947476]\n",
      " [ 0.00511984]\n",
      " [ 0.01394405]\n",
      " [ 0.03064209]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49513146]\n",
      " [0.50127996]\n",
      " [0.50348596]\n",
      " [0.50765992]]\n",
      "Error [[-0.49513146]\n",
      " [ 0.49872004]\n",
      " [ 0.49651404]\n",
      " [-0.50765992]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24402447 0.91318179]\n",
      " [0.8725755  1.33633503]\n",
      " [1.02191657 1.07810393]\n",
      " [1.6504676  1.50125717]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56070518 0.71365081]\n",
      " [0.70528132 0.79188659]\n",
      " [0.73534576 0.746135  ]\n",
      " [0.83895424 0.8177619 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01952302]\n",
      " [ 0.00512142]\n",
      " [ 0.01395733]\n",
      " [ 0.03068734]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4951194 ]\n",
      " [0.50128035]\n",
      " [0.50348928]\n",
      " [0.50767123]]\n",
      "Error [[-0.4951194 ]\n",
      " [ 0.49871965]\n",
      " [ 0.49651072]\n",
      " [-0.50767123]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24407399 0.91318265]\n",
      " [0.87280295 1.33632609]\n",
      " [1.02210832 1.07807726]\n",
      " [1.65083728 1.5012207 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56071737 0.71365099]\n",
      " [0.7053286  0.79188512]\n",
      " [0.73538307 0.74612995]\n",
      " [0.83900418 0.81775647]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01957132]\n",
      " [ 0.00512301]\n",
      " [ 0.01397063]\n",
      " [ 0.03073263]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49510733]\n",
      " [0.50128075]\n",
      " [0.5034926 ]\n",
      " [0.50768255]]\n",
      "Error [[-0.49510733]\n",
      " [ 0.49871925]\n",
      " [ 0.4965074 ]\n",
      " [-0.50768255]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2441236  0.91318351]\n",
      " [0.87303082 1.33631715]\n",
      " [1.02230042 1.07805056]\n",
      " [1.65120764 1.50118419]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56072959 0.71365117]\n",
      " [0.70537596 0.79188365]\n",
      " [0.73542045 0.74612489]\n",
      " [0.8390542  0.81775103]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01961965]\n",
      " [ 0.00512462]\n",
      " [ 0.01398393]\n",
      " [ 0.03077796]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49509525]\n",
      " [0.50128115]\n",
      " [0.50349593]\n",
      " [0.50769388]]\n",
      "Error [[-0.49509525]\n",
      " [ 0.49871885]\n",
      " [ 0.49650407]\n",
      " [-0.50769388]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24417329 0.91318438]\n",
      " [0.87325909 1.3363082 ]\n",
      " [1.02249288 1.07802383]\n",
      " [1.65157867 1.50114765]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56074183 0.71365134]\n",
      " [0.70542339 0.79188217]\n",
      " [0.7354579  0.74611983]\n",
      " [0.8391043  0.81774558]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01966801]\n",
      " [ 0.00512624]\n",
      " [ 0.01399726]\n",
      " [ 0.03082332]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49508316]\n",
      " [0.50128156]\n",
      " [0.50349926]\n",
      " [0.50770522]]\n",
      "Error [[-0.49508316]\n",
      " [ 0.49871844]\n",
      " [ 0.49650074]\n",
      " [-0.50770522]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24422307 0.91318524]\n",
      " [0.87348777 1.33629924]\n",
      " [1.02268569 1.07799707]\n",
      " [1.65195039 1.50111107]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56075409 0.71365152]\n",
      " [0.70547091 0.79188069]\n",
      " [0.73549541 0.74611476]\n",
      " [0.83915448 0.81774013]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0197164 ]\n",
      " [ 0.00512788]\n",
      " [ 0.0140106 ]\n",
      " [ 0.03086871]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49507106]\n",
      " [0.50128197]\n",
      " [0.50350259]\n",
      " [0.50771657]]\n",
      "Error [[-0.49507106]\n",
      " [ 0.49871803]\n",
      " [ 0.49649741]\n",
      " [-0.50771657]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24427293 0.91318611]\n",
      " [0.87371686 1.33629027]\n",
      " [1.02287884 1.07797028]\n",
      " [1.65232277 1.50107445]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56076638 0.7136517 ]\n",
      " [0.70551851 0.79187922]\n",
      " [0.73553298 0.74610969]\n",
      " [0.83920473 0.81773467]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01976483]\n",
      " [ 0.00512954]\n",
      " [ 0.01402396]\n",
      " [ 0.03091415]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49505895]\n",
      " [0.50128238]\n",
      " [0.50350593]\n",
      " [0.50772792]]\n",
      "Error [[-0.49505895]\n",
      " [ 0.49871762]\n",
      " [ 0.49649407]\n",
      " [-0.50772792]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24432287 0.91318697]\n",
      " [0.87394636 1.3362813 ]\n",
      " [1.02307235 1.07794347]\n",
      " [1.65269584 1.5010378 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56077868 0.71365187]\n",
      " [0.70556619 0.79187774]\n",
      " [0.73557062 0.74610461]\n",
      " [0.83925507 0.81772921]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01981329]\n",
      " [ 0.00513122]\n",
      " [ 0.01403733]\n",
      " [ 0.03095961]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49504684]\n",
      " [0.5012828 ]\n",
      " [0.50350927]\n",
      " [0.50773929]]\n",
      "Error [[-0.49504684]\n",
      " [ 0.4987172 ]\n",
      " [ 0.49649073]\n",
      " [-0.50773929]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2443729  0.91318784]\n",
      " [0.87417626 1.33627232]\n",
      " [1.02326622 1.07791662]\n",
      " [1.65306958 1.50100111]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.560791   0.71365205]\n",
      " [0.70561395 0.79187626]\n",
      " [0.73560833 0.74609952]\n",
      " [0.83930548 0.81772374]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01986179]\n",
      " [ 0.00513291]\n",
      " [ 0.01405072]\n",
      " [ 0.03100512]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49503472]\n",
      " [0.50128322]\n",
      " [0.50351262]\n",
      " [0.50775066]]\n",
      "Error [[-0.49503472]\n",
      " [ 0.49871678]\n",
      " [ 0.49648738]\n",
      " [-0.50775066]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24442301 0.91318871]\n",
      " [0.87440658 1.33626334]\n",
      " [1.02346043 1.07788974]\n",
      " [1.653444   1.50096438]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56080334 0.71365223]\n",
      " [0.70566179 0.79187478]\n",
      " [0.7356461  0.74609443]\n",
      " [0.83935597 0.81771827]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01991031]\n",
      " [ 0.00513461]\n",
      " [ 0.01406412]\n",
      " [ 0.03105066]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49502259]\n",
      " [0.50128365]\n",
      " [0.50351597]\n",
      " [0.50776204]]\n",
      "Error [[-0.49502259]\n",
      " [ 0.49871635]\n",
      " [ 0.49648403]\n",
      " [-0.50776204]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24447321 0.91318957]\n",
      " [0.87463731 1.33625435]\n",
      " [1.023655   1.07786284]\n",
      " [1.65381911 1.50092761]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5608157  0.7136524 ]\n",
      " [0.70570971 0.7918733 ]\n",
      " [0.73568394 0.74608933]\n",
      " [0.83940655 0.81771279]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.01995888]\n",
      " [ 0.00513634]\n",
      " [ 0.01407754]\n",
      " [ 0.03109623]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49501045]\n",
      " [0.50128408]\n",
      " [0.50351933]\n",
      " [0.50777343]]\n",
      "Error [[-0.49501045]\n",
      " [ 0.49871592]\n",
      " [ 0.49648067]\n",
      " [-0.50777343]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24452348 0.91319044]\n",
      " [0.87486845 1.33624535]\n",
      " [1.02384992 1.0778359 ]\n",
      " [1.65419489 1.50089081]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56082809 0.71365258]\n",
      " [0.70575771 0.79187181]\n",
      " [0.73572184 0.74608423]\n",
      " [0.8394572  0.8177073 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02000747]\n",
      " [ 0.00513808]\n",
      " [ 0.01409098]\n",
      " [ 0.03114184]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4949983 ]\n",
      " [0.50128452]\n",
      " [0.50352269]\n",
      " [0.50778483]]\n",
      "Error [[-0.4949983 ]\n",
      " [ 0.49871548]\n",
      " [ 0.49647731]\n",
      " [-0.50778483]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24457385 0.91319131]\n",
      " [0.8751     1.33623634]\n",
      " [1.0240452  1.07780894]\n",
      " [1.65457135 1.50085397]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56084049 0.71365276]\n",
      " [0.70580579 0.79187033]\n",
      " [0.73575981 0.74607912]\n",
      " [0.83950792 0.81770181]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0200561 ]\n",
      " [ 0.00513984]\n",
      " [ 0.01410443]\n",
      " [ 0.03118749]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49498614]\n",
      " [0.50128496]\n",
      " [0.50352605]\n",
      " [0.50779624]]\n",
      "Error [[-0.49498614]\n",
      " [ 0.49871504]\n",
      " [ 0.49647395]\n",
      " [-0.50779624]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24462429 0.91319219]\n",
      " [0.87533196 1.33622733]\n",
      " [1.02424083 1.07778195]\n",
      " [1.65494849 1.50081709]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56085292 0.71365294]\n",
      " [0.70585396 0.79186884]\n",
      " [0.73579784 0.74607401]\n",
      " [0.83955873 0.81769631]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02010477]\n",
      " [ 0.00514161]\n",
      " [ 0.0141179 ]\n",
      " [ 0.03123317]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49497398]\n",
      " [0.5012854 ]\n",
      " [0.50352942]\n",
      " [0.50780766]]\n",
      "Error [[-0.49497398]\n",
      " [ 0.4987146 ]\n",
      " [ 0.49647058]\n",
      " [-0.50780766]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24467482 0.91319306]\n",
      " [0.87556433 1.33621831]\n",
      " [1.02443681 1.07775492]\n",
      " [1.65532632 1.50078018]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56086536 0.71365312]\n",
      " [0.7059022  0.79186736]\n",
      " [0.73583594 0.74606889]\n",
      " [0.83960962 0.81769081]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02015346]\n",
      " [ 0.0051434 ]\n",
      " [ 0.01413138]\n",
      " [ 0.03127889]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4949618 ]\n",
      " [0.50128585]\n",
      " [0.50353279]\n",
      " [0.50781908]]\n",
      "Error [[-0.4949618 ]\n",
      " [ 0.49871415]\n",
      " [ 0.49646721]\n",
      " [-0.50781908]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24472544 0.91319393]\n",
      " [0.87579712 1.33620929]\n",
      " [1.02463315 1.07772787]\n",
      " [1.65570483 1.50074322]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56087783 0.7136533 ]\n",
      " [0.70595052 0.79186587]\n",
      " [0.7358741  0.74606376]\n",
      " [0.83966058 0.8176853 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0202022 ]\n",
      " [ 0.00514521]\n",
      " [ 0.01414488]\n",
      " [ 0.03132464]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49494962]\n",
      " [0.5012863 ]\n",
      " [0.50353616]\n",
      " [0.50783052]]\n",
      "Error [[-0.49494962]\n",
      " [ 0.4987137 ]\n",
      " [ 0.49646384]\n",
      " [-0.50783052]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24477613 0.91319481]\n",
      " [0.87603031 1.33620025]\n",
      " [1.02482984 1.07770079]\n",
      " [1.65608402 1.50070623]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56089031 0.71365347]\n",
      " [0.70599893 0.79186438]\n",
      " [0.73591233 0.74605863]\n",
      " [0.83971163 0.81767978]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02025096]\n",
      " [ 0.00514703]\n",
      " [ 0.0141584 ]\n",
      " [ 0.03137043]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49493743]\n",
      " [0.50128676]\n",
      " [0.50353954]\n",
      " [0.50784197]]\n",
      "Error [[-0.49493743]\n",
      " [ 0.49871324]\n",
      " [ 0.49646046]\n",
      " [-0.50784197]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24482692 0.91319568]\n",
      " [0.87626392 1.33619121]\n",
      " [1.02502689 1.07767367]\n",
      " [1.65646389 1.50066921]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56090282 0.71365365]\n",
      " [0.70604742 0.79186289]\n",
      " [0.73595062 0.7460535 ]\n",
      " [0.83976275 0.81767426]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02029976]\n",
      " [ 0.00514888]\n",
      " [ 0.01417193]\n",
      " [ 0.03141626]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49492523]\n",
      " [0.50128722]\n",
      " [0.50354292]\n",
      " [0.50785342]]\n",
      "Error [[-0.49492523]\n",
      " [ 0.49871278]\n",
      " [ 0.49645708]\n",
      " [-0.50785342]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24487778 0.91319656]\n",
      " [0.87649794 1.33618217]\n",
      " [1.02522429 1.07764653]\n",
      " [1.65684445 1.50063214]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56091535 0.71365383]\n",
      " [0.70609598 0.7918614 ]\n",
      " [0.73598898 0.74604835]\n",
      " [0.83981395 0.81766874]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0203486 ]\n",
      " [ 0.00515073]\n",
      " [ 0.01418548]\n",
      " [ 0.03146213]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49491303]\n",
      " [0.50128768]\n",
      " [0.50354631]\n",
      " [0.50786488]]\n",
      "Error [[-0.49491303]\n",
      " [ 0.49871232]\n",
      " [ 0.49645369]\n",
      " [-0.50786488]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24492873 0.91319743]\n",
      " [0.87673237 1.33617311]\n",
      " [1.02542205 1.07761936]\n",
      " [1.65722569 1.50059504]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5609279  0.71365401]\n",
      " [0.70614463 0.79185991]\n",
      " [0.7360274  0.74604321]\n",
      " [0.83986523 0.81766321]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02039747]\n",
      " [ 0.00515261]\n",
      " [ 0.01419905]\n",
      " [ 0.03150803]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49490081]\n",
      " [0.50128815]\n",
      " [0.5035497 ]\n",
      " [0.50787635]]\n",
      "Error [[-0.49490081]\n",
      " [ 0.49871185]\n",
      " [ 0.4964503 ]\n",
      " [-0.50787635]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24497976 0.91319831]\n",
      " [0.87696722 1.33616405]\n",
      " [1.02562017 1.07759216]\n",
      " [1.65760762 1.5005579 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56094047 0.71365419]\n",
      " [0.70619336 0.79185841]\n",
      " [0.73606589 0.74603805]\n",
      " [0.83991659 0.81765767]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02044637]\n",
      " [ 0.0051545 ]\n",
      " [ 0.01421263]\n",
      " [ 0.03155396]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49488859]\n",
      " [0.50128862]\n",
      " [0.5035531 ]\n",
      " [0.50788784]]\n",
      "Error [[-0.49488859]\n",
      " [ 0.49871138]\n",
      " [ 0.4964469 ]\n",
      " [-0.50788784]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24503088 0.91319919]\n",
      " [0.87720248 1.33615499]\n",
      " [1.02581864 1.07756493]\n",
      " [1.65799024 1.50052072]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56095306 0.71365437]\n",
      " [0.70624217 0.79185692]\n",
      " [0.73610445 0.74603289]\n",
      " [0.83996803 0.81765213]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02049531]\n",
      " [ 0.00515641]\n",
      " [ 0.01422623]\n",
      " [ 0.03159994]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49487635]\n",
      " [0.5012891 ]\n",
      " [0.5035565 ]\n",
      " [0.50789933]]\n",
      "Error [[-0.49487635]\n",
      " [ 0.4987109 ]\n",
      " [ 0.4964435 ]\n",
      " [-0.50789933]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24508208 0.91320007]\n",
      " [0.87743815 1.33614591]\n",
      " [1.02601747 1.07753767]\n",
      " [1.65837354 1.50048351]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56096567 0.71365455]\n",
      " [0.70629106 0.79185542]\n",
      " [0.73614307 0.74602773]\n",
      " [0.84001955 0.81764658]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02054428]\n",
      " [ 0.00515834]\n",
      " [ 0.01423985]\n",
      " [ 0.03164595]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49486411]\n",
      " [0.50128958]\n",
      " [0.5035599 ]\n",
      " [0.50791083]]\n",
      "Error [[-0.49486411]\n",
      " [ 0.49871042]\n",
      " [ 0.4964401 ]\n",
      " [-0.50791083]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24513337 0.91320095]\n",
      " [0.87767424 1.33613683]\n",
      " [1.02621665 1.07751037]\n",
      " [1.65875752 1.50044626]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5609783  0.71365473]\n",
      " [0.70634003 0.79185393]\n",
      " [0.73618176 0.74602256]\n",
      " [0.84007115 0.81764102]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02059329]\n",
      " [ 0.00516028]\n",
      " [ 0.01425348]\n",
      " [ 0.03169199]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49485186]\n",
      " [0.50129007]\n",
      " [0.50356331]\n",
      " [0.50792234]]\n",
      "Error [[-0.49485186]\n",
      " [ 0.49870993]\n",
      " [ 0.49643669]\n",
      " [-0.50792234]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24518474 0.91320183]\n",
      " [0.87791074 1.33612775]\n",
      " [1.02641619 1.07748305]\n",
      " [1.6591422  1.50040897]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56099095 0.71365491]\n",
      " [0.70638909 0.79185243]\n",
      " [0.73622051 0.74601738]\n",
      " [0.84012282 0.81763546]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02064233]\n",
      " [ 0.00516224]\n",
      " [ 0.01426713]\n",
      " [ 0.03173808]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4948396 ]\n",
      " [0.50129056]\n",
      " [0.50356672]\n",
      " [0.50793385]]\n",
      "Error [[-0.4948396 ]\n",
      " [ 0.49870944]\n",
      " [ 0.49643328]\n",
      " [-0.50793385]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24523619 0.91320272]\n",
      " [0.87814766 1.33611865]\n",
      " [1.02661609 1.0774557 ]\n",
      " [1.65952756 1.50037164]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56100362 0.71365509]\n",
      " [0.70643822 0.79185093]\n",
      " [0.73625933 0.7460122 ]\n",
      " [0.84017457 0.8176299 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02069141]\n",
      " [ 0.00516422]\n",
      " [ 0.01428079]\n",
      " [ 0.0317842 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49482733]\n",
      " [0.50129105]\n",
      " [0.50357014]\n",
      " [0.50794538]]\n",
      "Error [[-0.49482733]\n",
      " [ 0.49870895]\n",
      " [ 0.49642986]\n",
      " [-0.50794538]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24528773 0.9132036 ]\n",
      " [0.87838499 1.33610955]\n",
      " [1.02681635 1.07742832]\n",
      " [1.65991361 1.50033427]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56101631 0.71365527]\n",
      " [0.70648744 0.79184943]\n",
      " [0.73629821 0.74600701]\n",
      " [0.84022641 0.81762433]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02074052]\n",
      " [ 0.00516622]\n",
      " [ 0.01429447]\n",
      " [ 0.03183036]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49481506]\n",
      " [0.50129155]\n",
      " [0.50357356]\n",
      " [0.50795692]]\n",
      "Error [[-0.49481506]\n",
      " [ 0.49870845]\n",
      " [ 0.49642644]\n",
      " [-0.50795692]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24533935 0.91320448]\n",
      " [0.87862274 1.33610045]\n",
      " [1.02701696 1.07740091]\n",
      " [1.66030035 1.50029687]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56102902 0.71365545]\n",
      " [0.70653674 0.79184793]\n",
      " [0.73633716 0.74600181]\n",
      " [0.84027832 0.81761875]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02078967]\n",
      " [ 0.00516823]\n",
      " [ 0.01430817]\n",
      " [ 0.03187655]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49480277]\n",
      " [0.50129205]\n",
      " [0.50357698]\n",
      " [0.50796846]]\n",
      "Error [[-0.49480277]\n",
      " [ 0.49870795]\n",
      " [ 0.49642302]\n",
      " [-0.50796846]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24539105 0.91320537]\n",
      " [0.8788609  1.33609133]\n",
      " [1.02721794 1.07737347]\n",
      " [1.66068779 1.50025943]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56104176 0.71365563]\n",
      " [0.70658612 0.79184643]\n",
      " [0.73637618 0.74599661]\n",
      " [0.84033031 0.81761317]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02083885]\n",
      " [ 0.00517026]\n",
      " [ 0.01432188]\n",
      " [ 0.03192278]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49479048]\n",
      " [0.50129256]\n",
      " [0.50358041]\n",
      " [0.50798002]]\n",
      "Error [[-0.49479048]\n",
      " [ 0.49870744]\n",
      " [ 0.49641959]\n",
      " [-0.50798002]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24544284 0.91320626]\n",
      " [0.87909948 1.33608221]\n",
      " [1.02741927 1.077346  ]\n",
      " [1.66107591 1.50022195]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56105451 0.71365581]\n",
      " [0.70663558 0.79184492]\n",
      " [0.73641526 0.74599141]\n",
      " [0.84038238 0.81760758]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02088807]\n",
      " [ 0.00517231]\n",
      " [ 0.01433561]\n",
      " [ 0.03196905]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49477817]\n",
      " [0.50129307]\n",
      " [0.50358384]\n",
      " [0.50799158]]\n",
      "Error [[-0.49477817]\n",
      " [ 0.49870693]\n",
      " [ 0.49641616]\n",
      " [-0.50799158]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24549471 0.91320714]\n",
      " [0.87933847 1.33607309]\n",
      " [1.02762096 1.0773185 ]\n",
      " [1.66146472 1.50018444]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56106729 0.71365599]\n",
      " [0.70668512 0.79184342]\n",
      " [0.73645441 0.7459862 ]\n",
      " [0.84043453 0.81760198]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02093732]\n",
      " [ 0.00517437]\n",
      " [ 0.01434936]\n",
      " [ 0.03201536]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49476586]\n",
      " [0.50129359]\n",
      " [0.50358728]\n",
      " [0.50800316]]\n",
      "Error [[-0.49476586]\n",
      " [ 0.49870641]\n",
      " [ 0.49641272]\n",
      " [-0.50800316]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24554667 0.91320803]\n",
      " [0.87957788 1.33606395]\n",
      " [1.02782301 1.07729097]\n",
      " [1.66185422 1.50014689]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56108008 0.71365618]\n",
      " [0.70673474 0.79184191]\n",
      " [0.73649362 0.74598098]\n",
      " [0.84048675 0.81759638]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02098661]\n",
      " [ 0.00517645]\n",
      " [ 0.01436313]\n",
      " [ 0.0320617 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49475354]\n",
      " [0.50129411]\n",
      " [0.50359072]\n",
      " [0.50801474]]\n",
      "Error [[-0.49475354]\n",
      " [ 0.49870589]\n",
      " [ 0.49640928]\n",
      " [-0.50801474]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24559871 0.91320892]\n",
      " [0.87981771 1.33605481]\n",
      " [1.02802542 1.0772634 ]\n",
      " [1.66224442 1.5001093 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5610929  0.71365636]\n",
      " [0.70678445 0.79184041]\n",
      " [0.7365329  0.74597576]\n",
      " [0.84053906 0.81759078]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02103593]\n",
      " [ 0.00517855]\n",
      " [ 0.01437691]\n",
      " [ 0.03210808]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49474121]\n",
      " [0.50129464]\n",
      " [0.50359416]\n",
      " [0.50802633]]\n",
      "Error [[-0.49474121]\n",
      " [ 0.49870536]\n",
      " [ 0.49640584]\n",
      " [-0.50802633]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24565084 0.91320981]\n",
      " [0.88005796 1.33604566]\n",
      " [1.02822819 1.07723581]\n",
      " [1.66263531 1.50007167]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56110574 0.71365654]\n",
      " [0.70683423 0.7918389 ]\n",
      " [0.73657225 0.74597053]\n",
      " [0.84059144 0.81758516]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02108529]\n",
      " [ 0.00518067]\n",
      " [ 0.01439071]\n",
      " [ 0.0321545 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49472887]\n",
      " [0.50129516]\n",
      " [0.50359761]\n",
      " [0.50803793]]\n",
      "Error [[-0.49472887]\n",
      " [ 0.49870484]\n",
      " [ 0.49640239]\n",
      " [-0.50803793]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24570305 0.9132107 ]\n",
      " [0.88029862 1.33603651]\n",
      " [1.02843132 1.07720819]\n",
      " [1.66302689 1.500034  ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56111859 0.71365672]\n",
      " [0.7068841  0.79183739]\n",
      " [0.73661166 0.7459653 ]\n",
      " [0.84064391 0.81757955]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02113469]\n",
      " [ 0.00518281]\n",
      " [ 0.01440452]\n",
      " [ 0.03220095]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49471652]\n",
      " [0.5012957 ]\n",
      " [0.50360107]\n",
      " [0.50804954]]\n",
      "Error [[-0.49471652]\n",
      " [ 0.4987043 ]\n",
      " [ 0.49639893]\n",
      " [-0.50804954]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggrigation in hidden layer\n",
      "[[0.24575534 0.91321159]\n",
      " [0.8805397  1.33602735]\n",
      " [1.02863481 1.07718054]\n",
      " [1.66341917 1.4999963 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56113147 0.7136569 ]\n",
      " [0.70693405 0.79183588]\n",
      " [0.73665114 0.74596006]\n",
      " [0.84069645 0.81757392]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02118412]\n",
      " [ 0.00518496]\n",
      " [ 0.01441835]\n",
      " [ 0.03224745]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49470417]\n",
      " [0.50129624]\n",
      " [0.50360453]\n",
      " [0.50806116]]\n",
      "Error [[-0.49470417]\n",
      " [ 0.49870376]\n",
      " [ 0.49639547]\n",
      " [-0.50806116]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24580772 0.91321249]\n",
      " [0.8807812  1.33601818]\n",
      " [1.02883866 1.07715286]\n",
      " [1.66381214 1.49995855]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56114437 0.71365709]\n",
      " [0.70698408 0.79183437]\n",
      " [0.73669068 0.74595481]\n",
      " [0.84074907 0.81756829]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02123359]\n",
      " [ 0.00518713]\n",
      " [ 0.0144322 ]\n",
      " [ 0.03229398]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4946918 ]\n",
      " [0.50129678]\n",
      " [0.50360799]\n",
      " [0.50807279]]\n",
      "Error [[-0.4946918 ]\n",
      " [ 0.49870322]\n",
      " [ 0.49639201]\n",
      " [-0.50807279]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24586018 0.91321338]\n",
      " [0.88102311 1.33600901]\n",
      " [1.02904287 1.07712515]\n",
      " [1.6642058  1.49992077]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56115729 0.71365727]\n",
      " [0.70703419 0.79183286]\n",
      " [0.73673029 0.74594956]\n",
      " [0.84080177 0.81756266]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02128309]\n",
      " [ 0.00518931]\n",
      " [ 0.01444607]\n",
      " [ 0.03234055]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49467943]\n",
      " [0.50129733]\n",
      " [0.50361145]\n",
      " [0.50808443]]\n",
      "Error [[-0.49467943]\n",
      " [ 0.49870267]\n",
      " [ 0.49638855]\n",
      " [-0.50808443]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24591273 0.91321428]\n",
      " [0.88126545 1.33599983]\n",
      " [1.02924745 1.0770974 ]\n",
      " [1.66460017 1.49988296]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56117023 0.71365745]\n",
      " [0.70708438 0.79183134]\n",
      " [0.73676997 0.7459443 ]\n",
      " [0.84085455 0.81755702]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02133263]\n",
      " [ 0.00519152]\n",
      " [ 0.01445995]\n",
      " [ 0.03238715]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49466704]\n",
      " [0.50129788]\n",
      " [0.50361492]\n",
      " [0.50809608]]\n",
      "Error [[-0.49466704]\n",
      " [ 0.49870212]\n",
      " [ 0.49638508]\n",
      " [-0.50809608]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24596536 0.91321517]\n",
      " [0.8815082  1.33599064]\n",
      " [1.02945238 1.07706963]\n",
      " [1.66499522 1.4998451 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56118319 0.71365764]\n",
      " [0.70713466 0.79182983]\n",
      " [0.73680971 0.74593904]\n",
      " [0.84090741 0.81755137]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02138221]\n",
      " [ 0.00519374]\n",
      " [ 0.01447385]\n",
      " [ 0.0324338 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49465465]\n",
      " [0.50129843]\n",
      " [0.5036184 ]\n",
      " [0.50810774]]\n",
      "Error [[-0.49465465]\n",
      " [ 0.49870157]\n",
      " [ 0.4963816 ]\n",
      " [-0.50810774]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24601808 0.91321607]\n",
      " [0.88175138 1.33598145]\n",
      " [1.02965768 1.07704183]\n",
      " [1.66539098 1.49980721]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56119617 0.71365782]\n",
      " [0.70718502 0.79182832]\n",
      " [0.73684952 0.74593377]\n",
      " [0.84096035 0.81754572]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02143182]\n",
      " [ 0.00519598]\n",
      " [ 0.01448776]\n",
      " [ 0.03248048]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49464225]\n",
      " [0.50129899]\n",
      " [0.50362188]\n",
      " [0.50811941]]\n",
      "Error [[-0.49464225]\n",
      " [ 0.49870101]\n",
      " [ 0.49637812]\n",
      " [-0.50811941]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24607088 0.91321697]\n",
      " [0.88199497 1.33597225]\n",
      " [1.02986334 1.077014  ]\n",
      " [1.66578743 1.49976927]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56120917 0.713658  ]\n",
      " [0.70723546 0.7918268 ]\n",
      " [0.7368894  0.74592849]\n",
      " [0.84101337 0.81754006]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02148147]\n",
      " [ 0.00519824]\n",
      " [ 0.0145017 ]\n",
      " [ 0.0325272 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49462984]\n",
      " [0.50129956]\n",
      " [0.50362536]\n",
      " [0.50813108]]\n",
      "Error [[-0.49462984]\n",
      " [ 0.49870044]\n",
      " [ 0.49637464]\n",
      " [-0.50813108]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24612376 0.91321787]\n",
      " [0.88223898 1.33596304]\n",
      " [1.03006936 1.07698613]\n",
      " [1.66618458 1.49973131]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5612222  0.71365819]\n",
      " [0.70728598 0.79182528]\n",
      " [0.73692934 0.74592321]\n",
      " [0.84106646 0.8175344 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02153116]\n",
      " [ 0.00520051]\n",
      " [ 0.01451565]\n",
      " [ 0.03257396]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49461742]\n",
      " [0.50130013]\n",
      " [0.50362885]\n",
      " [0.50814277]]\n",
      "Error [[-0.49461742]\n",
      " [ 0.49869987]\n",
      " [ 0.49637115]\n",
      " [-0.50814277]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24617673 0.91321877]\n",
      " [0.88248342 1.33595383]\n",
      " [1.03027574 1.07695824]\n",
      " [1.66658243 1.4996933 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56123524 0.71365837]\n",
      " [0.70733658 0.79182376]\n",
      " [0.73696935 0.74591793]\n",
      " [0.84111964 0.81752873]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02158088]\n",
      " [ 0.00520281]\n",
      " [ 0.01452962]\n",
      " [ 0.03262076]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49460499]\n",
      " [0.5013007 ]\n",
      " [0.50363234]\n",
      " [0.50815447]]\n",
      "Error [[-0.49460499]\n",
      " [ 0.4986993 ]\n",
      " [ 0.49636766]\n",
      " [-0.50815447]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24622978 0.91321967]\n",
      " [0.88272827 1.33594461]\n",
      " [1.03048249 1.07693032]\n",
      " [1.66698098 1.49965525]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56124831 0.71365855]\n",
      " [0.70738727 0.79182224]\n",
      " [0.73700943 0.74591263]\n",
      " [0.84117289 0.81752305]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02163064]\n",
      " [ 0.00520512]\n",
      " [ 0.0145436 ]\n",
      " [ 0.03266759]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49459255]\n",
      " [0.50130128]\n",
      " [0.50363584]\n",
      " [0.50816617]]\n",
      "Error [[-0.49459255]\n",
      " [ 0.49869872]\n",
      " [ 0.49636416]\n",
      " [-0.50816617]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24628292 0.91322057]\n",
      " [0.88297355 1.33593538]\n",
      " [1.0306896  1.07690236]\n",
      " [1.66738023 1.49961717]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56126139 0.71365874]\n",
      " [0.70743803 0.79182072]\n",
      " [0.73704957 0.74590734]\n",
      " [0.84122623 0.81751737]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02168043]\n",
      " [ 0.00520745]\n",
      " [ 0.0145576 ]\n",
      " [ 0.03271447]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4945801 ]\n",
      " [0.50130186]\n",
      " [0.50363934]\n",
      " [0.50817789]]\n",
      "Error [[-0.4945801 ]\n",
      " [ 0.49869814]\n",
      " [ 0.49636066]\n",
      " [-0.50817789]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24633614 0.91322147]\n",
      " [0.88321924 1.33592614]\n",
      " [1.03089708 1.07687438]\n",
      " [1.66778018 1.49957905]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5612745  0.71365892]\n",
      " [0.70748888 0.7918192 ]\n",
      " [0.73708978 0.74590203]\n",
      " [0.84127964 0.81751168]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02173027]\n",
      " [ 0.00520979]\n",
      " [ 0.01457162]\n",
      " [ 0.03276138]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49456765]\n",
      " [0.50130245]\n",
      " [0.50364284]\n",
      " [0.50818961]]\n",
      "Error [[-0.49456765]\n",
      " [ 0.49869755]\n",
      " [ 0.49635716]\n",
      " [-0.50818961]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24638945 0.91322238]\n",
      " [0.88346536 1.3359169 ]\n",
      " [1.03110492 1.07684636]\n",
      " [1.66818083 1.49954089]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56128762 0.71365911]\n",
      " [0.70753981 0.79181768]\n",
      " [0.73713005 0.74589672]\n",
      " [0.84133313 0.81750599]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02178014]\n",
      " [ 0.00521216]\n",
      " [ 0.01458566]\n",
      " [ 0.03280833]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49455518]\n",
      " [0.50130304]\n",
      " [0.50364635]\n",
      " [0.50820135]]\n",
      "Error [[-0.49455518]\n",
      " [ 0.49869696]\n",
      " [ 0.49635365]\n",
      " [-0.50820135]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24644284 0.91322328]\n",
      " [0.8837119  1.33590766]\n",
      " [1.03131312 1.07681831]\n",
      " [1.66858219 1.49950269]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56130077 0.71365929]\n",
      " [0.70759083 0.79181615]\n",
      " [0.73717039 0.74589141]\n",
      " [0.8413867  0.81750029]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02183004]\n",
      " [ 0.00521454]\n",
      " [ 0.01459971]\n",
      " [ 0.03285532]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49454271]\n",
      " [0.50130363]\n",
      " [0.50364986]\n",
      " [0.50821309]]\n",
      "Error [[-0.49454271]\n",
      " [ 0.49869637]\n",
      " [ 0.49635014]\n",
      " [-0.50821309]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24649631 0.91322419]\n",
      " [0.88395886 1.3358984 ]\n",
      " [1.03152169 1.07679024]\n",
      " [1.66898424 1.49946445]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56131394 0.71365948]\n",
      " [0.70764192 0.79181463]\n",
      " [0.7372108  0.74588609]\n",
      " [0.84144035 0.81749459]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02187999]\n",
      " [ 0.00521694]\n",
      " [ 0.01461379]\n",
      " [ 0.03290234]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49453022]\n",
      " [0.50130423]\n",
      " [0.50365338]\n",
      " [0.50822484]]\n",
      "Error [[-0.49453022]\n",
      " [ 0.49869577]\n",
      " [ 0.49634662]\n",
      " [-0.50822484]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24654987 0.9132251 ]\n",
      " [0.88420624 1.33588914]\n",
      " [1.03173062 1.07676213]\n",
      " [1.669387   1.49942618]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56132712 0.71365966]\n",
      " [0.7076931  0.7918131 ]\n",
      " [0.73725128 0.74588076]\n",
      " [0.84149408 0.81748888]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02192997]\n",
      " [ 0.00521936]\n",
      " [ 0.01462787]\n",
      " [ 0.03294941]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49451773]\n",
      " [0.50130484]\n",
      " [0.5036569 ]\n",
      " [0.50823661]]\n",
      "Error [[-0.49451773]\n",
      " [ 0.49869516]\n",
      " [ 0.4963431 ]\n",
      " [-0.50823661]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24660351 0.913226  ]\n",
      " [0.88445405 1.33587988]\n",
      " [1.03193992 1.07673399]\n",
      " [1.66979046 1.49938787]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56134033 0.71365985]\n",
      " [0.70774436 0.79181157]\n",
      " [0.73729182 0.74587542]\n",
      " [0.84154788 0.81748316]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02197998]\n",
      " [ 0.0052218 ]\n",
      " [ 0.01464198]\n",
      " [ 0.03299651]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49450523]\n",
      " [0.50130545]\n",
      " [0.50366043]\n",
      " [0.50824838]]\n",
      "Error [[-0.49450523]\n",
      " [ 0.49869455]\n",
      " [ 0.49633957]\n",
      " [-0.50824838]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24665724 0.91322691]\n",
      " [0.88470228 1.3358706 ]\n",
      " [1.03214959 1.07670583]\n",
      " [1.67019463 1.49934952]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56135356 0.71366003]\n",
      " [0.7077957  0.79181004]\n",
      " [0.73733243 0.74587009]\n",
      " [0.84160177 0.81747744]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02203004]\n",
      " [ 0.00522425]\n",
      " [ 0.0146561 ]\n",
      " [ 0.03304366]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49449271]\n",
      " [0.50130606]\n",
      " [0.50366396]\n",
      " [0.50826016]]\n",
      "Error [[-0.49449271]\n",
      " [ 0.49869394]\n",
      " [ 0.49633604]\n",
      " [-0.50826016]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24671105 0.91322782]\n",
      " [0.88495093 1.33586132]\n",
      " [1.03235962 1.07667763]\n",
      " [1.6705995  1.49931113]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56136681 0.71366022]\n",
      " [0.70784712 0.79180851]\n",
      " [0.7373731  0.74586474]\n",
      " [0.84165573 0.81747171]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02208013]\n",
      " [ 0.00522673]\n",
      " [ 0.01467024]\n",
      " [ 0.03309084]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49448019]\n",
      " [0.50130668]\n",
      " [0.5036675 ]\n",
      " [0.50827195]]\n",
      "Error [[-0.49448019]\n",
      " [ 0.49869332]\n",
      " [ 0.4963325 ]\n",
      " [-0.50827195]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24676495 0.91322873]\n",
      " [0.88520001 1.33585204]\n",
      " [1.03257001 1.0766494 ]\n",
      " [1.67100508 1.4992727 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56138008 0.71366041]\n",
      " [0.70789863 0.79180698]\n",
      " [0.73741384 0.74585939]\n",
      " [0.84170978 0.81746598]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02213026]\n",
      " [ 0.00522922]\n",
      " [ 0.0146844 ]\n",
      " [ 0.03313806]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49446766]\n",
      " [0.5013073 ]\n",
      " [0.50367103]\n",
      " [0.50828376]]\n",
      "Error [[-0.49446766]\n",
      " [ 0.4986927 ]\n",
      " [ 0.49632897]\n",
      " [-0.50828376]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24681893 0.91322965]\n",
      " [0.88544951 1.33584274]\n",
      " [1.03278078 1.07662114]\n",
      " [1.67141136 1.49923423]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56139338 0.71366059]\n",
      " [0.70795022 0.79180545]\n",
      " [0.73745465 0.74585403]\n",
      " [0.8417639  0.81746024]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02218043]\n",
      " [ 0.00523173]\n",
      " [ 0.01469858]\n",
      " [ 0.03318532]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49445512]\n",
      " [0.50130793]\n",
      " [0.50367458]\n",
      " [0.50829557]]\n",
      "Error [[-0.49445512]\n",
      " [ 0.49869207]\n",
      " [ 0.49632542]\n",
      " [-0.50829557]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24687299 0.91323056]\n",
      " [0.88569944 1.33583344]\n",
      " [1.03299191 1.07659285]\n",
      " [1.67181835 1.49919573]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56140669 0.71366078]\n",
      " [0.70800189 0.79180392]\n",
      " [0.73749553 0.74584867]\n",
      " [0.8418181  0.81745449]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02223064]\n",
      " [ 0.00523425]\n",
      " [ 0.01471277]\n",
      " [ 0.03323262]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49444257]\n",
      " [0.50130856]\n",
      " [0.50367813]\n",
      " [0.50830739]]\n",
      "Error [[-0.49444257]\n",
      " [ 0.49869144]\n",
      " [ 0.49632187]\n",
      " [-0.50830739]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24692715 0.91323147]\n",
      " [0.88594978 1.33582414]\n",
      " [1.03320341 1.07656453]\n",
      " [1.67222604 1.49915719]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56142002 0.71366097]\n",
      " [0.70805364 0.79180238]\n",
      " [0.73753647 0.7458433 ]\n",
      " [0.84187239 0.81744874]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02228088]\n",
      " [ 0.0052368 ]\n",
      " [ 0.01472699]\n",
      " [ 0.03327996]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49443001]\n",
      " [0.5013092 ]\n",
      " [0.50368168]\n",
      " [0.50831922]]\n",
      "Error [[-0.49443001]\n",
      " [ 0.4986908 ]\n",
      " [ 0.49631832]\n",
      " [-0.50831922]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24698138 0.91323239]\n",
      " [0.88620056 1.33581482]\n",
      " [1.03341527 1.07653617]\n",
      " [1.67263445 1.49911861]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56143338 0.71366115]\n",
      " [0.70810548 0.79180085]\n",
      " [0.73757748 0.74583793]\n",
      " [0.84192675 0.81744298]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02233116]\n",
      " [ 0.00523936]\n",
      " [ 0.01474121]\n",
      " [ 0.03332734]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49441744]\n",
      " [0.50130984]\n",
      " [0.50368524]\n",
      " [0.50833106]]\n",
      "Error [[-0.49441744]\n",
      " [ 0.49869016]\n",
      " [ 0.49631476]\n",
      " [-0.50833106]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2470357  0.91323331]\n",
      " [0.88645176 1.3358055 ]\n",
      " [1.0336275  1.07650779]\n",
      " [1.67304356 1.49907999]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56144675 0.71366134]\n",
      " [0.7081574  0.79179931]\n",
      " [0.73761856 0.74583255]\n",
      " [0.84198119 0.81743722]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02238148]\n",
      " [ 0.00524195]\n",
      " [ 0.01475546]\n",
      " [ 0.03337475]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49440486]\n",
      " [0.50131048]\n",
      " [0.5036888 ]\n",
      " [0.50834291]]\n",
      "Error [[-0.49440486]\n",
      " [ 0.49868952]\n",
      " [ 0.4963112 ]\n",
      " [-0.50834291]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2470901  0.91323422]\n",
      " [0.88670338 1.33579618]\n",
      " [1.0338401  1.07647938]\n",
      " [1.67345339 1.49904133]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56146015 0.71366153]\n",
      " [0.7082094  0.79179777]\n",
      " [0.7376597  0.74582716]\n",
      " [0.8420357  0.81743145]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02243184]\n",
      " [ 0.00524455]\n",
      " [ 0.01476973]\n",
      " [ 0.03342221]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49439227]\n",
      " [0.50131113]\n",
      " [0.50369236]\n",
      " [0.50835477]]\n",
      "Error [[-0.49439227]\n",
      " [ 0.49868887]\n",
      " [ 0.49630764]\n",
      " [-0.50835477]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24714459 0.91323514]\n",
      " [0.88695544 1.33578685]\n",
      " [1.03405307 1.07645093]\n",
      " [1.67386392 1.49900264]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56147356 0.71366172]\n",
      " [0.70826148 0.79179624]\n",
      " [0.73770091 0.74582177]\n",
      " [0.8420903  0.81742568]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02248224]\n",
      " [ 0.00524717]\n",
      " [ 0.01478401]\n",
      " [ 0.0334697 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49437968]\n",
      " [0.50131179]\n",
      " [0.50369593]\n",
      " [0.50836665]]\n",
      "Error [[-0.49437968]\n",
      " [ 0.49868821]\n",
      " [ 0.49630407]\n",
      " [-0.50836665]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24719916 0.91323606]\n",
      " [0.88720791 1.33577751]\n",
      " [1.03426641 1.07642246]\n",
      " [1.67427516 1.4989639 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.561487   0.7136619 ]\n",
      " [0.70831365 0.7917947 ]\n",
      " [0.73774219 0.74581637]\n",
      " [0.84214498 0.8174199 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02253267]\n",
      " [ 0.0052498 ]\n",
      " [ 0.01479831]\n",
      " [ 0.03351724]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49436707]\n",
      " [0.50131245]\n",
      " [0.50369951]\n",
      " [0.50837853]]\n",
      "Error [[-0.49436707]\n",
      " [ 0.49868755]\n",
      " [ 0.49630049]\n",
      " [-0.50837853]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24725382 0.91323698]\n",
      " [0.88746082 1.33576816]\n",
      " [1.03448012 1.07639395]\n",
      " [1.67468712 1.49892513]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56150046 0.71366209]\n",
      " [0.7083659  0.79179316]\n",
      " [0.73778354 0.74581097]\n",
      " [0.84219974 0.81741411]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02258315]\n",
      " [ 0.00525246]\n",
      " [ 0.01481263]\n",
      " [ 0.03356481]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49435445]\n",
      " [0.50131311]\n",
      " [0.50370309]\n",
      " [0.50839042]]\n",
      "Error [[-0.49435445]\n",
      " [ 0.49868689]\n",
      " [ 0.49629691]\n",
      " [-0.50839042]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24730856 0.9132379 ]\n",
      " [0.88771415 1.33575881]\n",
      " [1.0346942  1.07636541]\n",
      " [1.67509978 1.49888632]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56151394 0.71366228]\n",
      " [0.70841823 0.79179161]\n",
      " [0.73782495 0.74580556]\n",
      " [0.84225457 0.81740832]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02263366]\n",
      " [ 0.00525514]\n",
      " [ 0.01482696]\n",
      " [ 0.03361243]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49434183]\n",
      " [0.50131378]\n",
      " [0.50370667]\n",
      " [0.50840232]]\n",
      "Error [[-0.49434183]\n",
      " [ 0.49868622]\n",
      " [ 0.49629333]\n",
      " [-0.50840232]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24736339 0.91323882]\n",
      " [0.88796791 1.33574945]\n",
      " [1.03490864 1.07633684]\n",
      " [1.67551316 1.49884747]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56152744 0.71366247]\n",
      " [0.70847064 0.79179007]\n",
      " [0.73786643 0.74580014]\n",
      " [0.84230948 0.81740252]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02268421]\n",
      " [ 0.00525783]\n",
      " [ 0.01484132]\n",
      " [ 0.03366008]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49432919]\n",
      " [0.50131445]\n",
      " [0.50371026]\n",
      " [0.50841423]]\n",
      "Error [[-0.49432919]\n",
      " [ 0.49868555]\n",
      " [ 0.49628974]\n",
      " [-0.50841423]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2474183  0.91323975]\n",
      " [0.88822209 1.33574009]\n",
      " [1.03512346 1.07630824]\n",
      " [1.67592725 1.49880858]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56154096 0.71366266]\n",
      " [0.70852314 0.79178853]\n",
      " [0.73790798 0.74579472]\n",
      " [0.84236448 0.81739671]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0227348 ]\n",
      " [ 0.00526054]\n",
      " [ 0.01485569]\n",
      " [ 0.03370778]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49431655]\n",
      " [0.50131513]\n",
      " [0.50371385]\n",
      " [0.50842615]]\n",
      "Error [[-0.49431655]\n",
      " [ 0.49868487]\n",
      " [ 0.49628615]\n",
      " [-0.50842615]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2474733  0.91324067]\n",
      " [0.88847671 1.33573071]\n",
      " [1.03533865 1.07627961]\n",
      " [1.67634205 1.49876965]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5615545  0.71366285]\n",
      " [0.70857572 0.79178698]\n",
      " [0.73794959 0.74578929]\n",
      " [0.84241955 0.8173909 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02278543]\n",
      " [ 0.00526327]\n",
      " [ 0.01487008]\n",
      " [ 0.03375551]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49430389]\n",
      " [0.50131581]\n",
      " [0.50371745]\n",
      " [0.50843808]]\n",
      "Error [[-0.49430389]\n",
      " [ 0.49868419]\n",
      " [ 0.49628255]\n",
      " [-0.50843808]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24752838 0.9132416 ]\n",
      " [0.88873175 1.33572134]\n",
      " [1.0355542  1.07625095]\n",
      " [1.67675757 1.49873069]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56156806 0.71366304]\n",
      " [0.70862838 0.79178544]\n",
      " [0.73799128 0.74578386]\n",
      " [0.8424747  0.81738509]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02283609]\n",
      " [ 0.00526602]\n",
      " [ 0.01488449]\n",
      " [ 0.03380329]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49429122]\n",
      " [0.5013165 ]\n",
      " [0.50372105]\n",
      " [0.50845002]]\n",
      "Error [[-0.49429122]\n",
      " [ 0.4986835 ]\n",
      " [ 0.49627895]\n",
      " [-0.50845002]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24758355 0.91324253]\n",
      " [0.88898722 1.33571195]\n",
      " [1.03577013 1.07622226]\n",
      " [1.67717381 1.49869169]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56158164 0.71366323]\n",
      " [0.70868113 0.79178389]\n",
      " [0.73803303 0.74577842]\n",
      " [0.84252993 0.81737926]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0228868 ]\n",
      " [ 0.00526879]\n",
      " [ 0.01489891]\n",
      " [ 0.0338511 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49427855]\n",
      " [0.50131719]\n",
      " [0.50372466]\n",
      " [0.50846197]]\n",
      "Error [[-0.49427855]\n",
      " [ 0.49868281]\n",
      " [ 0.49627534]\n",
      " [-0.50846197]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2476388  0.91324345]\n",
      " [0.88924312 1.33570256]\n",
      " [1.03598643 1.07619354]\n",
      " [1.67759076 1.49865264]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56159524 0.71366341]\n",
      " [0.70873395 0.79178234]\n",
      " [0.73807484 0.74577297]\n",
      " [0.84258524 0.81737344]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02293754]\n",
      " [ 0.00527158]\n",
      " [ 0.01491336]\n",
      " [ 0.03389895]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49426587]\n",
      " [0.50131789]\n",
      " [0.50372827]\n",
      " [0.50847393]]\n",
      "Error [[-0.49426587]\n",
      " [ 0.49868211]\n",
      " [ 0.49627173]\n",
      " [-0.50847393]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24769413 0.91324438]\n",
      " [0.88949945 1.33569316]\n",
      " [1.03620311 1.07616478]\n",
      " [1.67800842 1.49861356]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56160887 0.7136636 ]\n",
      " [0.70878687 0.79178079]\n",
      " [0.73811673 0.74576752]\n",
      " [0.84264063 0.8173676 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02298833]\n",
      " [ 0.00527438]\n",
      " [ 0.01492782]\n",
      " [ 0.03394685]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49425317]\n",
      " [0.50131859]\n",
      " [0.50373189]\n",
      " [0.5084859 ]]\n",
      "Error [[-0.49425317]\n",
      " [ 0.49868141]\n",
      " [ 0.49626811]\n",
      " [-0.5084859 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24774955 0.91324531]\n",
      " [0.8897562  1.33568376]\n",
      " [1.03642015 1.076136  ]\n",
      " [1.6784268  1.49857444]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56162251 0.71366379]\n",
      " [0.70883986 0.79177924]\n",
      " [0.73815868 0.74576206]\n",
      " [0.8426961  0.81736176]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02303915]\n",
      " [ 0.00527721]\n",
      " [ 0.0149423 ]\n",
      " [ 0.03399478]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49424047]\n",
      " [0.5013193 ]\n",
      " [0.50373551]\n",
      " [0.50849788]]\n",
      "Error [[-0.49424047]\n",
      " [ 0.4986807 ]\n",
      " [ 0.49626449]\n",
      " [-0.50849788]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24780505 0.91324624]\n",
      " [0.89001339 1.33567435]\n",
      " [1.03663757 1.07610718]\n",
      " [1.6788459  1.49853528]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56163618 0.71366398]\n",
      " [0.70889294 0.79177769]\n",
      " [0.7382007  0.7457566 ]\n",
      " [0.84275165 0.81735592]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02309001]\n",
      " [ 0.00528005]\n",
      " [ 0.0149568 ]\n",
      " [ 0.03404276]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49422775]\n",
      " [0.50132001]\n",
      " [0.50373913]\n",
      " [0.50850987]]\n",
      "Error [[-0.49422775]\n",
      " [ 0.49867999]\n",
      " [ 0.49626087]\n",
      " [-0.50850987]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24786064 0.91324717]\n",
      " [0.89027101 1.33566493]\n",
      " [1.03685535 1.07607833]\n",
      " [1.67926572 1.49849609]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56164986 0.71366418]\n",
      " [0.7089461  0.79177614]\n",
      " [0.73824279 0.74575113]\n",
      " [0.84280728 0.81735007]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02314092]\n",
      " [ 0.00528291]\n",
      " [ 0.01497132]\n",
      " [ 0.03409077]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49421503]\n",
      " [0.50132072]\n",
      " [0.50374276]\n",
      " [0.50852187]]\n",
      "Error [[-0.49421503]\n",
      " [ 0.49867928]\n",
      " [ 0.49625724]\n",
      " [-0.50852187]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24791632 0.91324811]\n",
      " [0.89052906 1.33565551]\n",
      " [1.03707352 1.07604945]\n",
      " [1.67968626 1.49845685]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56166357 0.71366437]\n",
      " [0.70899934 0.79177458]\n",
      " [0.73828494 0.74574565]\n",
      " [0.84286298 0.81734421]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02319186]\n",
      " [ 0.00528579]\n",
      " [ 0.01498585]\n",
      " [ 0.03413883]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4942023 ]\n",
      " [0.50132145]\n",
      " [0.50374639]\n",
      " [0.50853388]]\n",
      "Error [[-0.4942023 ]\n",
      " [ 0.49867855]\n",
      " [ 0.49625361]\n",
      " [-0.50853388]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24797208 0.91324904]\n",
      " [0.89078754 1.33564608]\n",
      " [1.03729205 1.07602054]\n",
      " [1.68010751 1.49841758]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5616773  0.71366456]\n",
      " [0.70905267 0.79177303]\n",
      " [0.73832717 0.74574017]\n",
      " [0.84291877 0.81733834]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02324284]\n",
      " [ 0.00528869]\n",
      " [ 0.0150004 ]\n",
      " [ 0.03418693]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49418955]\n",
      " [0.50132217]\n",
      " [0.50375003]\n",
      " [0.5085459 ]]\n",
      "Error [[-0.49418955]\n",
      " [ 0.49867783]\n",
      " [ 0.49624997]\n",
      " [-0.5085459 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24802792 0.91324998]\n",
      " [0.89104645 1.33563664]\n",
      " [1.03751096 1.0759916 ]\n",
      " [1.68052949 1.49837826]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56169105 0.71366475]\n",
      " [0.70910608 0.79177147]\n",
      " [0.73836946 0.74573468]\n",
      " [0.84297463 0.81733248]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02329386]\n",
      " [ 0.00529161]\n",
      " [ 0.01501498]\n",
      " [ 0.03423506]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4941768 ]\n",
      " [0.5013229 ]\n",
      " [0.50375367]\n",
      " [0.50855793]]\n",
      "Error [[-0.4941768 ]\n",
      " [ 0.4986771 ]\n",
      " [ 0.49624633]\n",
      " [-0.50855793]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24808385 0.91325091]\n",
      " [0.89130579 1.3356272 ]\n",
      " [1.03773024 1.07596263]\n",
      " [1.68095218 1.49833891]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56170481 0.71366494]\n",
      " [0.70915957 0.79176992]\n",
      " [0.73841182 0.74572919]\n",
      " [0.84303057 0.8173266 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02334492]\n",
      " [ 0.00529455]\n",
      " [ 0.01502957]\n",
      " [ 0.03428324]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49416403]\n",
      " [0.50132363]\n",
      " [0.50375732]\n",
      " [0.50856997]]\n",
      "Error [[-0.49416403]\n",
      " [ 0.49867637]\n",
      " [ 0.49624268]\n",
      " [-0.50856997]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24813986 0.91325185]\n",
      " [0.89156556 1.33561775]\n",
      " [1.0379499  1.07593362]\n",
      " [1.6813756  1.49829952]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5617186  0.71366513]\n",
      " [0.70921314 0.79176836]\n",
      " [0.73845424 0.74572369]\n",
      " [0.8430866  0.81732072]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02339602]\n",
      " [ 0.00529751]\n",
      " [ 0.01504418]\n",
      " [ 0.03433146]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49415126]\n",
      " [0.50132437]\n",
      " [0.50376097]\n",
      " [0.50858202]]\n",
      "Error [[-0.49415126]\n",
      " [ 0.49867563]\n",
      " [ 0.49623903]\n",
      " [-0.50858202]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24819596 0.91325279]\n",
      " [0.89182577 1.33560829]\n",
      " [1.03816993 1.07590459]\n",
      " [1.68179974 1.49826009]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56173242 0.71366532]\n",
      " [0.7092668  0.7917668 ]\n",
      " [0.73849674 0.74571818]\n",
      " [0.8431427  0.81731483]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02344717]\n",
      " [ 0.00530048]\n",
      " [ 0.0150588 ]\n",
      " [ 0.03437972]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49413848]\n",
      " [0.50132512]\n",
      " [0.50376463]\n",
      " [0.50859408]]\n",
      "Error [[-0.49413848]\n",
      " [ 0.49867488]\n",
      " [ 0.49623537]\n",
      " [-0.50859408]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24825214 0.91325373]\n",
      " [0.89208641 1.33559883]\n",
      " [1.03839034 1.07587552]\n",
      " [1.6822246  1.49822062]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56174625 0.71366551]\n",
      " [0.70932055 0.79176524]\n",
      " [0.7385393  0.74571267]\n",
      " [0.84319888 0.81730894]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02349835]\n",
      " [ 0.00530348]\n",
      " [ 0.01507345]\n",
      " [ 0.03442802]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49412568]\n",
      " [0.50132587]\n",
      " [0.50376829]\n",
      " [0.50860615]]\n",
      "Error [[-0.49412568]\n",
      " [ 0.49867413]\n",
      " [ 0.49623171]\n",
      " [-0.50860615]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24830841 0.91325467]\n",
      " [0.89234748 1.33558936]\n",
      " [1.03861112 1.07584642]\n",
      " [1.68265019 1.49818111]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5617601  0.71366571]\n",
      " [0.70937437 0.79176368]\n",
      " [0.73858193 0.74570715]\n",
      " [0.84325514 0.81730304]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02354957]\n",
      " [ 0.00530649]\n",
      " [ 0.01508812]\n",
      " [ 0.03447636]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49411288]\n",
      " [0.50132662]\n",
      " [0.50377196]\n",
      " [0.50861824]]\n",
      "Error [[-0.49411288]\n",
      " [ 0.49867338]\n",
      " [ 0.49622804]\n",
      " [-0.50861824]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24836476 0.91325561]\n",
      " [0.89260898 1.33557989]\n",
      " [1.03883227 1.07581729]\n",
      " [1.68307649 1.49814157]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56177397 0.7136659 ]\n",
      " [0.70942828 0.79176212]\n",
      " [0.73862463 0.74570163]\n",
      " [0.84331148 0.81729713]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02360083]\n",
      " [ 0.00530953]\n",
      " [ 0.0151028 ]\n",
      " [ 0.03452474]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49410007]\n",
      " [0.50132738]\n",
      " [0.50377563]\n",
      " [0.50863033]]\n",
      "Error [[-0.49410007]\n",
      " [ 0.49867262]\n",
      " [ 0.49622437]\n",
      " [-0.50863033]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2484212  0.91325656]\n",
      " [0.89287092 1.33557041]\n",
      " [1.03905381 1.07578813]\n",
      " [1.68350353 1.49810198]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56178787 0.71366609]\n",
      " [0.70948227 0.79176055]\n",
      " [0.7386674  0.7456961 ]\n",
      " [0.8433679  0.81729122]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02365213]\n",
      " [ 0.00531258]\n",
      " [ 0.0151175 ]\n",
      " [ 0.03457316]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49408724]\n",
      " [0.50132814]\n",
      " [0.5037793 ]\n",
      " [0.50864243]]\n",
      "Error [[-0.49408724]\n",
      " [ 0.49867186]\n",
      " [ 0.4962207 ]\n",
      " [-0.50864243]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24847772 0.9132575 ]\n",
      " [0.89313329 1.33556092]\n",
      " [1.03927572 1.07575894]\n",
      " [1.68393129 1.49806236]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56180178 0.71366629]\n",
      " [0.70953635 0.79175899]\n",
      " [0.73871023 0.74569056]\n",
      " [0.8434244  0.81728531]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02370348]\n",
      " [ 0.00531565]\n",
      " [ 0.01513222]\n",
      " [ 0.03462163]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49407441]\n",
      " [0.50132891]\n",
      " [0.50378298]\n",
      " [0.50865454]]\n",
      "Error [[-0.49407441]\n",
      " [ 0.49867109]\n",
      " [ 0.49621702]\n",
      " [-0.50865454]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24853433 0.91325844]\n",
      " [0.89339609 1.33555142]\n",
      " [1.039498   1.07572971]\n",
      " [1.68435977 1.49802269]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56181572 0.71366648]\n",
      " [0.70959051 0.79175742]\n",
      " [0.73875313 0.74568502]\n",
      " [0.84348097 0.81727938]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02375486]\n",
      " [ 0.00531874]\n",
      " [ 0.01514696]\n",
      " [ 0.03467014]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49406156]\n",
      " [0.50132968]\n",
      " [0.50378667]\n",
      " [0.50866667]]\n",
      "Error [[-0.49406156]\n",
      " [ 0.49867032]\n",
      " [ 0.49621333]\n",
      " [-0.50866667]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24859102 0.91325939]\n",
      " [0.89365933 1.33554192]\n",
      " [1.03972067 1.07570046]\n",
      " [1.68478898 1.49798299]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56182967 0.71366667]\n",
      " [0.70964475 0.79175586]\n",
      " [0.7387961  0.74567947]\n",
      " [0.84353763 0.81727345]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02380628]\n",
      " [ 0.00532186]\n",
      " [ 0.01516172]\n",
      " [ 0.03471868]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49404871]\n",
      " [0.50133046]\n",
      " [0.50379036]\n",
      " [0.5086788 ]]\n",
      "Error [[-0.49404871]\n",
      " [ 0.49866954]\n",
      " [ 0.49620964]\n",
      " [-0.5086788 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2486478  0.91326034]\n",
      " [0.89392301 1.33553242]\n",
      " [1.0399437  1.07567117]\n",
      " [1.68521892 1.49794325]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56184365 0.71366687]\n",
      " [0.70969908 0.79175429]\n",
      " [0.73883914 0.74567392]\n",
      " [0.84359437 0.81726752]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02385775]\n",
      " [ 0.00532499]\n",
      " [ 0.0151765 ]\n",
      " [ 0.03476727]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49403585]\n",
      " [0.50133124]\n",
      " [0.50379405]\n",
      " [0.50869094]]\n",
      "Error [[-0.49403585]\n",
      " [ 0.49866876]\n",
      " [ 0.49620595]\n",
      " [-0.50869094]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24870466 0.91326129]\n",
      " [0.89418712 1.3355229 ]\n",
      " [1.04016712 1.07564185]\n",
      " [1.68564958 1.49790347]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56185765 0.71366706]\n",
      " [0.70975349 0.79175272]\n",
      " [0.73888225 0.74566836]\n",
      " [0.84365118 0.81726158]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02390926]\n",
      " [ 0.00532814]\n",
      " [ 0.01519129]\n",
      " [ 0.0348159 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49402297]\n",
      " [0.50133203]\n",
      " [0.50379775]\n",
      " [0.5087031 ]]\n",
      "Error [[-0.49402297]\n",
      " [ 0.49866797]\n",
      " [ 0.49620225]\n",
      " [-0.5087031 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2487616  0.91326224]\n",
      " [0.89445166 1.33551338]\n",
      " [1.04039092 1.0756125 ]\n",
      " [1.68608098 1.49786365]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56187167 0.71366725]\n",
      " [0.70980798 0.79175115]\n",
      " [0.73892543 0.74566279]\n",
      " [0.84370807 0.81725563]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0239608 ]\n",
      " [ 0.00533131]\n",
      " [ 0.01520611]\n",
      " [ 0.03486457]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49401009]\n",
      " [0.50133282]\n",
      " [0.50380145]\n",
      " [0.50871526]]\n",
      "Error [[-0.49401009]\n",
      " [ 0.49866718]\n",
      " [ 0.49619855]\n",
      " [-0.50871526]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24881864 0.91326319]\n",
      " [0.89471664 1.33550386]\n",
      " [1.04061509 1.07558312]\n",
      " [1.6865131  1.49782379]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56188571 0.71366745]\n",
      " [0.70986256 0.79174958]\n",
      " [0.73896867 0.74565722]\n",
      " [0.84376505 0.81724968]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02401239]\n",
      " [ 0.0053345 ]\n",
      " [ 0.01522094]\n",
      " [ 0.03491329]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49399719]\n",
      " [0.50133362]\n",
      " [0.50380516]\n",
      " [0.50872744]]\n",
      "Error [[-0.49399719]\n",
      " [ 0.49866638]\n",
      " [ 0.49619484]\n",
      " [-0.50872744]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24887575 0.91326414]\n",
      " [0.89498206 1.33549432]\n",
      " [1.04083964 1.0755537 ]\n",
      " [1.68694595 1.49778389]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56189977 0.71366764]\n",
      " [0.70991722 0.79174801]\n",
      " [0.73901198 0.74565164]\n",
      " [0.8438221  0.81724372]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02406402]\n",
      " [ 0.0053377 ]\n",
      " [ 0.01523579]\n",
      " [ 0.03496204]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49398428]\n",
      " [0.50133442]\n",
      " [0.50380887]\n",
      " [0.50873962]]\n",
      "Error [[-0.49398428]\n",
      " [ 0.49866558]\n",
      " [ 0.49619113]\n",
      " [-0.50873962]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24893295 0.91326509]\n",
      " [0.89524791 1.33548479]\n",
      " [1.04106457 1.07552426]\n",
      " [1.68737953 1.49774395]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56191385 0.71366784]\n",
      " [0.70997197 0.79174644]\n",
      " [0.73905536 0.74564606]\n",
      " [0.84387923 0.81723775]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02411569]\n",
      " [ 0.00534093]\n",
      " [ 0.01525066]\n",
      " [ 0.03501084]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49397137]\n",
      " [0.50133523]\n",
      " [0.50381259]\n",
      " [0.50875182]]\n",
      "Error [[-0.49397137]\n",
      " [ 0.49866477]\n",
      " [ 0.49618741]\n",
      " [-0.50875182]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24899024 0.91326605]\n",
      " [0.8955142  1.33547524]\n",
      " [1.04128988 1.07549478]\n",
      " [1.68781385 1.49770398]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56192795 0.71366803]\n",
      " [0.7100268  0.79174486]\n",
      " [0.73909881 0.74564047]\n",
      " [0.84393644 0.81723178]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02416741]\n",
      " [ 0.00534418]\n",
      " [ 0.01526556]\n",
      " [ 0.03505968]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49395844]\n",
      " [0.50133604]\n",
      " [0.50381631]\n",
      " [0.50876402]]\n",
      "Error [[-0.49395844]\n",
      " [ 0.49866396]\n",
      " [ 0.49618369]\n",
      " [-0.50876402]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24904761 0.913267  ]\n",
      " [0.89578093 1.33546569]\n",
      " [1.04151557 1.07546527]\n",
      " [1.68824889 1.49766396]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56194207 0.71366823]\n",
      " [0.71008171 0.79174329]\n",
      " [0.73914233 0.74563487]\n",
      " [0.84399373 0.81722581]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02421916]\n",
      " [ 0.00534745]\n",
      " [ 0.01528047]\n",
      " [ 0.03510856]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49394551]\n",
      " [0.50133686]\n",
      " [0.50382004]\n",
      " [0.50877624]]\n",
      "Error [[-0.49394551]\n",
      " [ 0.49866314]\n",
      " [ 0.49617996]\n",
      " [-0.50877624]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24910507 0.91326796]\n",
      " [0.8960481  1.33545613]\n",
      " [1.04174164 1.07543573]\n",
      " [1.68868467 1.49762391]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56195622 0.71366842]\n",
      " [0.71013671 0.79174171]\n",
      " [0.73918592 0.74562927]\n",
      " [0.8440511  0.81721982]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02427095]\n",
      " [ 0.00535074]\n",
      " [ 0.01529539]\n",
      " [ 0.03515748]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49393256]\n",
      " [0.50133768]\n",
      " [0.50382377]\n",
      " [0.50878847]]\n",
      "Error [[-0.49393256]\n",
      " [ 0.49866232]\n",
      " [ 0.49617623]\n",
      " [-0.50878847]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24916261 0.91326892]\n",
      " [0.8963157  1.33544657]\n",
      " [1.04196809 1.07540616]\n",
      " [1.68912118 1.49758381]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56197038 0.71366862]\n",
      " [0.71019179 0.79174013]\n",
      " [0.73922957 0.74562366]\n",
      " [0.84410855 0.81721383]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02432279]\n",
      " [ 0.00535404]\n",
      " [ 0.01531034]\n",
      " [ 0.03520645]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4939196 ]\n",
      " [0.50133851]\n",
      " [0.50382751]\n",
      " [0.5088007 ]]\n",
      "Error [[-0.4939196 ]\n",
      " [ 0.49866149]\n",
      " [ 0.49617249]\n",
      " [-0.5088007 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24922023 0.91326988]\n",
      " [0.89658374 1.335437  ]\n",
      " [1.04219492 1.07537655]\n",
      " [1.68955842 1.49754368]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56198456 0.71366881]\n",
      " [0.71024695 0.79173856]\n",
      " [0.7392733  0.74561804]\n",
      " [0.84416608 0.81720784]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02437467]\n",
      " [ 0.00535737]\n",
      " [ 0.01532531]\n",
      " [ 0.03525546]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49390663]\n",
      " [0.50133934]\n",
      " [0.50383125]\n",
      " [0.50881295]]\n",
      "Error [[-0.49390663]\n",
      " [ 0.49866066]\n",
      " [ 0.49616875]\n",
      " [-0.50881295]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24927794 0.91327084]\n",
      " [0.89685222 1.33542742]\n",
      " [1.04242213 1.07534692]\n",
      " [1.6899964  1.4975035 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56199877 0.71366901]\n",
      " [0.7103022  0.79173698]\n",
      " [0.73931709 0.74561242]\n",
      " [0.84422369 0.81720184]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02442659]\n",
      " [ 0.00536072]\n",
      " [ 0.0153403 ]\n",
      " [ 0.03530451]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49389366]\n",
      " [0.50134018]\n",
      " [0.503835  ]\n",
      " [0.50882521]]\n",
      "Error [[-0.49389366]\n",
      " [ 0.49865982]\n",
      " [ 0.496165  ]\n",
      " [-0.50882521]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24933574 0.9132718 ]\n",
      " [0.89712113 1.33541784]\n",
      " [1.04264972 1.07531725]\n",
      " [1.69043512 1.49746329]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.562013   0.71366921]\n",
      " [0.71035754 0.7917354 ]\n",
      " [0.73936095 0.74560679]\n",
      " [0.84428137 0.81719583]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02447855]\n",
      " [ 0.00536408]\n",
      " [ 0.0153553 ]\n",
      " [ 0.0353536 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49388067]\n",
      " [0.50134102]\n",
      " [0.50383875]\n",
      " [0.50883748]]\n",
      "Error [[-0.49388067]\n",
      " [ 0.49865898]\n",
      " [ 0.49616125]\n",
      " [-0.50883748]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24939362 0.91327276]\n",
      " [0.89739049 1.33540825]\n",
      " [1.0428777  1.07528755]\n",
      " [1.69087457 1.49742304]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56202724 0.7136694 ]\n",
      " [0.71041295 0.79173382]\n",
      " [0.73940488 0.74560116]\n",
      " [0.84433914 0.81718982]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02453056]\n",
      " [ 0.00536747]\n",
      " [ 0.01537033]\n",
      " [ 0.03540273]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49386767]\n",
      " [0.50134186]\n",
      " [0.50384251]\n",
      " [0.50884976]]\n",
      "Error [[-0.49386767]\n",
      " [ 0.49865814]\n",
      " [ 0.49615749]\n",
      " [-0.50884976]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24945159 0.91327372]\n",
      " [0.89766029 1.33539865]\n",
      " [1.04310605 1.07525782]\n",
      " [1.69131475 1.49738275]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56204151 0.7136696 ]\n",
      " [0.71046845 0.79173223]\n",
      " [0.73944888 0.74559552]\n",
      " [0.84439698 0.8171838 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02458261]\n",
      " [ 0.00537088]\n",
      " [ 0.01538537]\n",
      " [ 0.03545191]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49385466]\n",
      " [0.50134272]\n",
      " [0.50384627]\n",
      " [0.50886205]]\n",
      "Error [[-0.49385466]\n",
      " [ 0.49865728]\n",
      " [ 0.49615373]\n",
      " [-0.50886205]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24950964 0.91327469]\n",
      " [0.89793052 1.33538905]\n",
      " [1.04333479 1.07522805]\n",
      " [1.69175567 1.49734242]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5620558  0.7136698 ]\n",
      " [0.71052404 0.79173065]\n",
      " [0.73949294 0.74558988]\n",
      " [0.84445491 0.81717777]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0246347 ]\n",
      " [ 0.0053743 ]\n",
      " [ 0.01540044]\n",
      " [ 0.03550113]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49384164]\n",
      " [0.50134357]\n",
      " [0.50385003]\n",
      " [0.50887435]]\n",
      "Error [[-0.49384164]\n",
      " [ 0.49865643]\n",
      " [ 0.49614997]\n",
      " [-0.50887435]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24956778 0.91327565]\n",
      " [0.8982012  1.33537945]\n",
      " [1.04356391 1.07519826]\n",
      " [1.69219733 1.49730205]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56207011 0.71366999]\n",
      " [0.71057971 0.79172907]\n",
      " [0.73953708 0.74558422]\n",
      " [0.84451291 0.81717174]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02468683]\n",
      " [ 0.00537775]\n",
      " [ 0.01541552]\n",
      " [ 0.03555039]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49382861]\n",
      " [0.50134443]\n",
      " [0.5038538 ]\n",
      " [0.50888666]]\n",
      "Error [[-0.49382861]\n",
      " [ 0.49865557]\n",
      " [ 0.4961462 ]\n",
      " [-0.50888666]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.249626   0.91327662]\n",
      " [0.89847232 1.33536983]\n",
      " [1.04379341 1.07516843]\n",
      " [1.69263973 1.49726164]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56208444 0.71367019]\n",
      " [0.71063546 0.79172748]\n",
      " [0.73958128 0.74557857]\n",
      " [0.84457099 0.8171657 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.024739  ]\n",
      " [ 0.00538122]\n",
      " [ 0.01543062]\n",
      " [ 0.03559969]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49381556]\n",
      " [0.5013453 ]\n",
      " [0.50385758]\n",
      " [0.50889898]]\n",
      "Error [[-0.49381556]\n",
      " [ 0.4986547 ]\n",
      " [ 0.49614242]\n",
      " [-0.50889898]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2496843  0.91327759]\n",
      " [0.89874387 1.33536021]\n",
      " [1.0440233  1.07513857]\n",
      " [1.69308287 1.49722119]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5620988  0.71367039]\n",
      " [0.7106913  0.79172589]\n",
      " [0.73962556 0.7455729 ]\n",
      " [0.84462916 0.81715966]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02479122]\n",
      " [ 0.0053847 ]\n",
      " [ 0.01544575]\n",
      " [ 0.03564904]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49380251]\n",
      " [0.50134617]\n",
      " [0.50386136]\n",
      " [0.50891132]]\n",
      "Error [[-0.49380251]\n",
      " [ 0.49865383]\n",
      " [ 0.49613864]\n",
      " [-0.50891132]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24974269 0.91327856]\n",
      " [0.89901587 1.33535058]\n",
      " [1.04425357 1.07510868]\n",
      " [1.69352675 1.4971807 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56211317 0.71367059]\n",
      " [0.71074722 0.79172431]\n",
      " [0.7396699  0.74556723]\n",
      " [0.8446874  0.81715361]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02484348]\n",
      " [ 0.00538821]\n",
      " [ 0.01546089]\n",
      " [ 0.03569843]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49378945]\n",
      " [0.50134705]\n",
      " [0.50386514]\n",
      " [0.50892366]]\n",
      "Error [[-0.49378945]\n",
      " [ 0.49865295]\n",
      " [ 0.49613486]\n",
      " [-0.50892366]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24980117 0.91327953]\n",
      " [0.89928831 1.33534095]\n",
      " [1.04448422 1.07507875]\n",
      " [1.69397136 1.49714018]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56212756 0.71367079]\n",
      " [0.71080323 0.79172272]\n",
      " [0.73971431 0.74556155]\n",
      " [0.84474572 0.81714756]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02489578]\n",
      " [ 0.00539174]\n",
      " [ 0.01547605]\n",
      " [ 0.03574787]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49377638]\n",
      " [0.50134793]\n",
      " [0.50386894]\n",
      " [0.50893602]]\n",
      "Error [[-0.49377638]\n",
      " [ 0.49865207]\n",
      " [ 0.49613106]\n",
      " [-0.50893602]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24985973 0.9132805 ]\n",
      " [0.8995612  1.33533131]\n",
      " [1.04471526 1.0750488 ]\n",
      " [1.69441672 1.49709961]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56214198 0.71367099]\n",
      " [0.71085932 0.79172113]\n",
      " [0.73975879 0.74555587]\n",
      " [0.84480412 0.81714149]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02494813]\n",
      " [ 0.00539529]\n",
      " [ 0.01549123]\n",
      " [ 0.03579734]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49376329]\n",
      " [0.50134882]\n",
      " [0.50387273]\n",
      " [0.50894838]]\n",
      "Error [[-0.49376329]\n",
      " [ 0.49865118]\n",
      " [ 0.49612727]\n",
      " [-0.50894838]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24991838 0.91328147]\n",
      " [0.89983452 1.33532167]\n",
      " [1.04494668 1.07501881]\n",
      " [1.69486282 1.497059  ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56215641 0.71367118]\n",
      " [0.7109155  0.79171954]\n",
      " [0.73980334 0.74555018]\n",
      " [0.8448626  0.81713543]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02500052]\n",
      " [ 0.00539885]\n",
      " [ 0.01550643]\n",
      " [ 0.03584686]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4937502 ]\n",
      " [0.50134971]\n",
      " [0.50387653]\n",
      " [0.50896076]]\n",
      "Error [[-0.4937502 ]\n",
      " [ 0.49865029]\n",
      " [ 0.49612347]\n",
      " [-0.50896076]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.24997711 0.91328245]\n",
      " [0.90010829 1.33531202]\n",
      " [1.04517849 1.07498879]\n",
      " [1.69530966 1.49701836]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56217087 0.71367138]\n",
      " [0.71097176 0.79171795]\n",
      " [0.73984796 0.74554449]\n",
      " [0.84492116 0.81712935]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02505295]\n",
      " [ 0.00540244]\n",
      " [ 0.01552165]\n",
      " [ 0.03589643]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49373709]\n",
      " [0.50135061]\n",
      " [0.50388034]\n",
      " [0.50897314]]\n",
      "Error [[-0.49373709]\n",
      " [ 0.49864939]\n",
      " [ 0.49611966]\n",
      " [-0.50897314]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25003593 0.91328342]\n",
      " [0.9003825  1.33530236]\n",
      " [1.04541068 1.07495873]\n",
      " [1.69575725 1.49697767]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56218534 0.71367158]\n",
      " [0.7110281  0.79171635]\n",
      " [0.73989265 0.74553879]\n",
      " [0.84497979 0.81712327]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02510543]\n",
      " [ 0.00540605]\n",
      " [ 0.01553689]\n",
      " [ 0.03594603]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49372397]\n",
      " [0.50135151]\n",
      " [0.50388415]\n",
      " [0.50898554]]\n",
      "Error [[-0.49372397]\n",
      " [ 0.49864849]\n",
      " [ 0.49611585]\n",
      " [-0.50898554]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25009483 0.9132844 ]\n",
      " [0.90065715 1.33529269]\n",
      " [1.04564326 1.07492865]\n",
      " [1.69620558 1.49693694]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56219984 0.71367178]\n",
      " [0.71108453 0.79171476]\n",
      " [0.73993741 0.74553308]\n",
      " [0.84503851 0.81711719]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02515794]\n",
      " [ 0.00540968]\n",
      " [ 0.01555215]\n",
      " [ 0.03599568]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49371085]\n",
      " [0.50135242]\n",
      " [0.50388796]\n",
      " [0.50899795]]\n",
      "Error [[-0.49371085]\n",
      " [ 0.49864758]\n",
      " [ 0.49611204]\n",
      " [-0.50899795]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25015381 0.91328538]\n",
      " [0.90093225 1.33528302]\n",
      " [1.04587622 1.07489853]\n",
      " [1.69665465 1.49689618]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56221436 0.71367198]\n",
      " [0.71114104 0.79171317]\n",
      " [0.73998223 0.74552736]\n",
      " [0.84509731 0.8171111 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02521051]\n",
      " [ 0.00541333]\n",
      " [ 0.01556743]\n",
      " [ 0.03604537]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49369771]\n",
      " [0.50135333]\n",
      " [0.50389178]\n",
      " [0.50901037]]\n",
      "Error [[-0.49369771]\n",
      " [ 0.49864667]\n",
      " [ 0.49610822]\n",
      " [-0.50901037]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25021289 0.91328636]\n",
      " [0.90120779 1.33527335]\n",
      " [1.04610957 1.07486838]\n",
      " [1.69710447 1.49685537]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5622289  0.71367218]\n",
      " [0.71119764 0.79171157]\n",
      " [0.74002713 0.74552164]\n",
      " [0.84515618 0.817105  ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02526311]\n",
      " [ 0.005417  ]\n",
      " [ 0.01558274]\n",
      " [ 0.03609511]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49368456]\n",
      " [0.50135425]\n",
      " [0.5038956 ]\n",
      " [0.5090228 ]]\n",
      "Error [[-0.49368456]\n",
      " [ 0.49864575]\n",
      " [ 0.4961044 ]\n",
      " [-0.5090228 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25027204 0.91328734]\n",
      " [0.90148377 1.33526367]\n",
      " [1.04634331 1.0748382 ]\n",
      " [1.69755504 1.49681453]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56224346 0.71367238]\n",
      " [0.71125432 0.79170997]\n",
      " [0.7400721  0.74551592]\n",
      " [0.84521514 0.81709889]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02531576]\n",
      " [ 0.00542069]\n",
      " [ 0.01559806]\n",
      " [ 0.03614489]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4936714 ]\n",
      " [0.50135517]\n",
      " [0.50389943]\n",
      " [0.50903524]]\n",
      "Error [[-0.4936714 ]\n",
      " [ 0.49864483]\n",
      " [ 0.49610057]\n",
      " [-0.50903524]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25033129 0.91328832]\n",
      " [0.9017602  1.33525398]\n",
      " [1.04657743 1.07480798]\n",
      " [1.69800635 1.49677364]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56225804 0.71367258]\n",
      " [0.71131109 0.79170838]\n",
      " [0.74011713 0.74551019]\n",
      " [0.84527417 0.81709278]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02536845]\n",
      " [ 0.0054244 ]\n",
      " [ 0.0156134 ]\n",
      " [ 0.03619471]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49365823]\n",
      " [0.5013561 ]\n",
      " [0.50390327]\n",
      " [0.50904769]]\n",
      "Error [[-0.49365823]\n",
      " [ 0.4986439 ]\n",
      " [ 0.49609673]\n",
      " [-0.50904769]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25039061 0.9132893 ]\n",
      " [0.90203708 1.33524428]\n",
      " [1.04681194 1.07477774]\n",
      " [1.69845841 1.49673272]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56227264 0.71367278]\n",
      " [0.71136794 0.79170678]\n",
      " [0.74016223 0.74550445]\n",
      " [0.84533329 0.81708667]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02542119]\n",
      " [ 0.00542813]\n",
      " [ 0.01562876]\n",
      " [ 0.03624458]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49364505]\n",
      " [0.50135703]\n",
      " [0.50390711]\n",
      " [0.50906015]]\n",
      "Error [[-0.49364505]\n",
      " [ 0.49864297]\n",
      " [ 0.49609289]\n",
      " [-0.50906015]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25045003 0.91329028]\n",
      " [0.9023144  1.33523458]\n",
      " [1.04704684 1.07474746]\n",
      " [1.69891121 1.49669176]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56228726 0.71367298]\n",
      " [0.71142488 0.79170518]\n",
      " [0.74020741 0.7454987 ]\n",
      " [0.84539248 0.81708054]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02547397]\n",
      " [ 0.00543188]\n",
      " [ 0.01564414]\n",
      " [ 0.03629449]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49363185]\n",
      " [0.50135797]\n",
      " [0.50391095]\n",
      " [0.50907263]]\n",
      "Error [[-0.49363185]\n",
      " [ 0.49864203]\n",
      " [ 0.49608905]\n",
      " [-0.50907263]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25050952 0.91329127]\n",
      " [0.90259216 1.33522488]\n",
      " [1.04728213 1.07471715]\n",
      " [1.69936477 1.49665075]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56230191 0.71367319]\n",
      " [0.7114819  0.79170358]\n",
      " [0.74025265 0.74549295]\n",
      " [0.84545175 0.81707442]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02552679]\n",
      " [ 0.00543566]\n",
      " [ 0.01565954]\n",
      " [ 0.03634445]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49361865]\n",
      " [0.50135891]\n",
      " [0.5039148 ]\n",
      " [0.50908511]]\n",
      "Error [[-0.49361865]\n",
      " [ 0.49864109]\n",
      " [ 0.4960852 ]\n",
      " [-0.50908511]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2505691  0.91329225]\n",
      " [0.90287037 1.33521516]\n",
      " [1.0475178  1.0746868 ]\n",
      " [1.69981907 1.49660971]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56231657 0.71367339]\n",
      " [0.71153901 0.79170198]\n",
      " [0.74029796 0.74548719]\n",
      " [0.8455111  0.81706828]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02557966]\n",
      " [ 0.00543945]\n",
      " [ 0.01567496]\n",
      " [ 0.03639445]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49360543]\n",
      " [0.50135986]\n",
      " [0.50391866]\n",
      " [0.50909761]]\n",
      "Error [[-0.49360543]\n",
      " [ 0.49864014]\n",
      " [ 0.49608134]\n",
      " [-0.50909761]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25062877 0.91329324]\n",
      " [0.90314903 1.33520544]\n",
      " [1.04775386 1.07465642]\n",
      " [1.70027412 1.49656863]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56233126 0.71367359]\n",
      " [0.7115962  0.79170037]\n",
      " [0.74034335 0.74548143]\n",
      " [0.84557053 0.81706214]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02563257]\n",
      " [ 0.00544326]\n",
      " [ 0.0156904 ]\n",
      " [ 0.03644449]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49359221]\n",
      " [0.50136081]\n",
      " [0.50392252]\n",
      " [0.50911011]]\n",
      "Error [[-0.49359221]\n",
      " [ 0.49863919]\n",
      " [ 0.49607748]\n",
      " [-0.50911011]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25068853 0.91329423]\n",
      " [0.90342814 1.33519572]\n",
      " [1.04799032 1.07462602]\n",
      " [1.70072993 1.4965275 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56234596 0.71367379]\n",
      " [0.71165348 0.79169877]\n",
      " [0.7403888  0.74547566]\n",
      " [0.84563004 0.81705599]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02568553]\n",
      " [ 0.0054471 ]\n",
      " [ 0.01570586]\n",
      " [ 0.03649458]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49357897]\n",
      " [0.50136177]\n",
      " [0.50392638]\n",
      " [0.50912263]]\n",
      "Error [[-0.49357897]\n",
      " [ 0.49863823]\n",
      " [ 0.49607362]\n",
      " [-0.50912263]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25074836 0.91329522]\n",
      " [0.90370769 1.33518599]\n",
      " [1.04822716 1.07459557]\n",
      " [1.70118648 1.49648634]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56236069 0.71367399]\n",
      " [0.71171084 0.79169716]\n",
      " [0.74043432 0.74546988]\n",
      " [0.84568963 0.81704984]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02573853]\n",
      " [ 0.00545096]\n",
      " [ 0.01572134]\n",
      " [ 0.03654471]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49356572]\n",
      " [0.50136274]\n",
      " [0.50393025]\n",
      " [0.50913516]]\n",
      "Error [[-0.49356572]\n",
      " [ 0.49863726]\n",
      " [ 0.49606975]\n",
      " [-0.50913516]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25080829 0.91329621]\n",
      " [0.90398769 1.33517625]\n",
      " [1.04846439 1.0745651 ]\n",
      " [1.70164379 1.49644514]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56237544 0.7136742 ]\n",
      " [0.71176828 0.79169556]\n",
      " [0.74047991 0.7454641 ]\n",
      " [0.8457493  0.81704368]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02579158]\n",
      " [ 0.00545483]\n",
      " [ 0.01573684]\n",
      " [ 0.03659488]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49355246]\n",
      " [0.5013637 ]\n",
      " [0.50393413]\n",
      " [0.5091477 ]]\n",
      "Error [[-0.49355246]\n",
      " [ 0.4986363 ]\n",
      " [ 0.49606587]\n",
      " [-0.5091477 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25086829 0.9132972 ]\n",
      " [0.90426813 1.33516651]\n",
      " [1.04870201 1.07453459]\n",
      " [1.70210185 1.49640389]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56239021 0.7136744 ]\n",
      " [0.71182582 0.79169395]\n",
      " [0.74052557 0.74545831]\n",
      " [0.84580905 0.81703752]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02584467]\n",
      " [ 0.00545873]\n",
      " [ 0.01575237]\n",
      " [ 0.0366451 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49353919]\n",
      " [0.50136468]\n",
      " [0.50393801]\n",
      " [0.50916025]]\n",
      "Error [[-0.49353919]\n",
      " [ 0.49863532]\n",
      " [ 0.49606199]\n",
      " [-0.50916025]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25092839 0.9132982 ]\n",
      " [0.90454903 1.33515676]\n",
      " [1.04894002 1.07450405]\n",
      " [1.70256067 1.49636261]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.562405   0.7136746 ]\n",
      " [0.71188343 0.79169234]\n",
      " [0.7405713  0.74545252]\n",
      " [0.84586888 0.81703135]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02589781]\n",
      " [ 0.00546265]\n",
      " [ 0.01576791]\n",
      " [ 0.03669537]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49352591]\n",
      " [0.50136566]\n",
      " [0.5039419 ]\n",
      " [0.50917281]]\n",
      "Error [[-0.49352591]\n",
      " [ 0.49863434]\n",
      " [ 0.4960581 ]\n",
      " [-0.50917281]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25098857 0.91329919]\n",
      " [0.90483037 1.335147  ]\n",
      " [1.04917843 1.07447348]\n",
      " [1.70302023 1.49632129]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56241981 0.7136748 ]\n",
      " [0.71194113 0.79169073]\n",
      " [0.7406171  0.74544672]\n",
      " [0.84592878 0.81702517]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02595099]\n",
      " [ 0.00546659]\n",
      " [ 0.01578347]\n",
      " [ 0.03674568]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49351262]\n",
      " [0.50136664]\n",
      " [0.50394579]\n",
      " [0.50918539]]\n",
      "Error [[-0.49351262]\n",
      " [ 0.49863336]\n",
      " [ 0.49605421]\n",
      " [-0.50918539]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25104883 0.91330019]\n",
      " [0.90511217 1.33513724]\n",
      " [1.04941722 1.07444287]\n",
      " [1.70348056 1.49627992]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56243464 0.71367501]\n",
      " [0.71199892 0.79168912]\n",
      " [0.74066297 0.74544091]\n",
      " [0.84598877 0.81701898]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02600421]\n",
      " [ 0.00547055]\n",
      " [ 0.01579906]\n",
      " [ 0.03679603]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49349931]\n",
      " [0.50136763]\n",
      " [0.50394968]\n",
      " [0.50919797]]\n",
      "Error [[-0.49349931]\n",
      " [ 0.49863237]\n",
      " [ 0.49605032]\n",
      " [-0.50919797]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25110918 0.91330119]\n",
      " [0.90539441 1.33512747]\n",
      " [1.0496564  1.07441224]\n",
      " [1.70394163 1.49623852]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56244949 0.71367521]\n",
      " [0.71205679 0.79168751]\n",
      " [0.74070891 0.7454351 ]\n",
      " [0.84604883 0.81701279]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02605748]\n",
      " [ 0.00547453]\n",
      " [ 0.01581466]\n",
      " [ 0.03684643]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.493486  ]\n",
      " [0.50136863]\n",
      " [0.50395358]\n",
      " [0.50921057]]\n",
      "Error [[-0.493486  ]\n",
      " [ 0.49863137]\n",
      " [ 0.49604642]\n",
      " [-0.50921057]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25116961 0.91330218]\n",
      " [0.9056771  1.3351177 ]\n",
      " [1.04989598 1.07438157]\n",
      " [1.70440347 1.49619708]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56246436 0.71367542]\n",
      " [0.71211475 0.7916859 ]\n",
      " [0.74075492 0.74542928]\n",
      " [0.84610898 0.8170066 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0261108 ]\n",
      " [ 0.00547854]\n",
      " [ 0.01583028]\n",
      " [ 0.03689687]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49347267]\n",
      " [0.50136963]\n",
      " [0.50395749]\n",
      " [0.50922317]]\n",
      "Error [[-0.49347267]\n",
      " [ 0.49863037]\n",
      " [ 0.49604251]\n",
      " [-0.50922317]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25123013 0.91330318]\n",
      " [0.90596024 1.33510792]\n",
      " [1.05013595 1.07435086]\n",
      " [1.70486606 1.4961556 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56247925 0.71367562]\n",
      " [0.71217279 0.79168429]\n",
      " [0.740801   0.74542345]\n",
      " [0.8461692  0.8170004 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02616416]\n",
      " [ 0.00548256]\n",
      " [ 0.01584593]\n",
      " [ 0.03694736]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49345933]\n",
      " [0.50137064]\n",
      " [0.5039614 ]\n",
      " [0.50923579]]\n",
      "Error [[-0.49345933]\n",
      " [ 0.49862936]\n",
      " [ 0.4960386 ]\n",
      " [-0.50923579]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25129073 0.91330419]\n",
      " [0.90624383 1.33509813]\n",
      " [1.05037631 1.07432013]\n",
      " [1.70532941 1.49611407]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56249417 0.71367583]\n",
      " [0.71223092 0.79168268]\n",
      " [0.74084715 0.74541762]\n",
      " [0.84622951 0.81699419]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02621757]\n",
      " [ 0.00548661]\n",
      " [ 0.0158616 ]\n",
      " [ 0.03699789]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49344598]\n",
      " [0.50137165]\n",
      " [0.50396532]\n",
      " [0.50924842]]\n",
      "Error [[-0.49344598]\n",
      " [ 0.49862835]\n",
      " [ 0.49603468]\n",
      " [-0.50924842]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25135142 0.91330519]\n",
      " [0.90652787 1.33508834]\n",
      " [1.05061707 1.07428936]\n",
      " [1.70579351 1.49607251]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5625091  0.71367603]\n",
      " [0.71228913 0.79168106]\n",
      " [0.74089338 0.74541178]\n",
      " [0.84628989 0.81698797]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02627102]\n",
      " [ 0.00549067]\n",
      " [ 0.01587728]\n",
      " [ 0.03704847]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49343262]\n",
      " [0.50137267]\n",
      " [0.50396924]\n",
      " [0.50926106]]\n",
      "Error [[-0.49343262]\n",
      " [ 0.49862733]\n",
      " [ 0.49603076]\n",
      " [-0.50926106]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2514122  0.91330619]\n",
      " [0.90681236 1.33507854]\n",
      " [1.05085821 1.07425856]\n",
      " [1.70625838 1.49603091]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56252406 0.71367624]\n",
      " [0.71234743 0.79167944]\n",
      " [0.74093967 0.74540593]\n",
      " [0.84635035 0.81698175]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02632451]\n",
      " [ 0.00549476]\n",
      " [ 0.01589299]\n",
      " [ 0.03709909]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49341925]\n",
      " [0.50137369]\n",
      " [0.50397316]\n",
      " [0.50927371]]\n",
      "Error [[-0.49341925]\n",
      " [ 0.49862631]\n",
      " [ 0.49602684]\n",
      " [-0.50927371]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25147306 0.9133072 ]\n",
      " [0.90709731 1.33506874]\n",
      " [1.05109975 1.07422772]\n",
      " [1.70672401 1.49598926]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56253904 0.71367644]\n",
      " [0.71240582 0.79167783]\n",
      " [0.74098603 0.74540008]\n",
      " [0.84641089 0.81697553]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02637806]\n",
      " [ 0.00549887]\n",
      " [ 0.01590872]\n",
      " [ 0.03714976]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49340587]\n",
      " [0.50137471]\n",
      " [0.5039771 ]\n",
      " [0.50928637]]\n",
      "Error [[-0.49340587]\n",
      " [ 0.49862529]\n",
      " [ 0.4960229 ]\n",
      " [-0.50928637]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.251534   0.9133082 ]\n",
      " [0.9073827  1.33505893]\n",
      " [1.05134169 1.07419685]\n",
      " [1.70719039 1.49594758]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56255403 0.71367665]\n",
      " [0.71246428 0.79167621]\n",
      " [0.74103246 0.74539422]\n",
      " [0.84647151 0.81696929]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02643165]\n",
      " [ 0.005503  ]\n",
      " [ 0.01592447]\n",
      " [ 0.03720047]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49339247]\n",
      " [0.50137575]\n",
      " [0.50398103]\n",
      " [0.50929905]]\n",
      "Error [[-0.49339247]\n",
      " [ 0.49862425]\n",
      " [ 0.49601897]\n",
      " [-0.50929905]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25159503 0.91330921]\n",
      " [0.90766855 1.33504911]\n",
      " [1.05158402 1.07416595]\n",
      " [1.70765754 1.49590585]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56256905 0.71367685]\n",
      " [0.71252284 0.79167459]\n",
      " [0.74107896 0.74538836]\n",
      " [0.84653221 0.81696305]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02648528]\n",
      " [ 0.00550716]\n",
      " [ 0.01594024]\n",
      " [ 0.03725123]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49337907]\n",
      " [0.50137679]\n",
      " [0.50398498]\n",
      " [0.50931173]]\n",
      "Error [[-0.49337907]\n",
      " [ 0.49862321]\n",
      " [ 0.49601502]\n",
      " [-0.50931173]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25165615 0.91331022]\n",
      " [0.90795485 1.33503929]\n",
      " [1.05182674 1.07413502]\n",
      " [1.70812545 1.49586409]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56258409 0.71367706]\n",
      " [0.71258148 0.79167297]\n",
      " [0.74112553 0.74538249]\n",
      " [0.84659299 0.81695681]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02653896]\n",
      " [ 0.00551133]\n",
      " [ 0.01595603]\n",
      " [ 0.03730203]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49336565]\n",
      " [0.50137783]\n",
      " [0.50398892]\n",
      " [0.50932443]]\n",
      "Error [[-0.49336565]\n",
      " [ 0.49862217]\n",
      " [ 0.49601108]\n",
      " [-0.50932443]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25171735 0.91331123]\n",
      " [0.9082416  1.33502946]\n",
      " [1.05206986 1.07410405]\n",
      " [1.70859412 1.49582229]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56259915 0.71367726]\n",
      " [0.71264021 0.79167135]\n",
      " [0.74117217 0.74537661]\n",
      " [0.84665385 0.81695056]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02659269]\n",
      " [ 0.00551553]\n",
      " [ 0.01597184]\n",
      " [ 0.03735288]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49335222]\n",
      " [0.50137888]\n",
      " [0.50399288]\n",
      " [0.50933714]]\n",
      "Error [[-0.49335222]\n",
      " [ 0.49862112]\n",
      " [ 0.49600712]\n",
      " [-0.50933714]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25177863 0.91331224]\n",
      " [0.90852881 1.33501963]\n",
      " [1.05231338 1.07407305]\n",
      " [1.70906355 1.49578044]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56261423 0.71367747]\n",
      " [0.71269902 0.79166973]\n",
      " [0.74121888 0.74537073]\n",
      " [0.84671478 0.8169443 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02664646]\n",
      " [ 0.00551974]\n",
      " [ 0.01598768]\n",
      " [ 0.03740378]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49333878]\n",
      " [0.50137993]\n",
      " [0.50399683]\n",
      " [0.50934985]]\n",
      "Error [[-0.49333878]\n",
      " [ 0.49862007]\n",
      " [ 0.49600317]\n",
      " [-0.50934985]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25184    0.91331325]\n",
      " [0.90881647 1.33500979]\n",
      " [1.05255729 1.07404202]\n",
      " [1.70953375 1.49573856]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56262934 0.71367768]\n",
      " [0.71275791 0.79166811]\n",
      " [0.74126567 0.74536484]\n",
      " [0.8467758  0.81693804]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02670028]\n",
      " [ 0.00552398]\n",
      " [ 0.01600353]\n",
      " [ 0.03745472]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49332533]\n",
      " [0.50138099]\n",
      " [0.5040008 ]\n",
      " [0.50936258]]\n",
      "Error [[-0.49332533]\n",
      " [ 0.49861901]\n",
      " [ 0.4959992 ]\n",
      " [-0.50936258]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25190146 0.91331427]\n",
      " [0.90910458 1.33499995]\n",
      " [1.05280159 1.07401095]\n",
      " [1.71000472 1.49569663]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56264446 0.71367789]\n",
      " [0.7128169  0.79166648]\n",
      " [0.74131252 0.74535894]\n",
      " [0.8468369  0.81693177]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02675415]\n",
      " [ 0.00552824]\n",
      " [ 0.01601941]\n",
      " [ 0.0375057 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49331186]\n",
      " [0.50138206]\n",
      " [0.50400477]\n",
      " [0.50937533]]\n",
      "Error [[-0.49331186]\n",
      " [ 0.49861794]\n",
      " [ 0.49599523]\n",
      " [-0.50937533]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.251963   0.91331528]\n",
      " [0.90939315 1.33499009]\n",
      " [1.05304629 1.07397985]\n",
      " [1.71047644 1.49565466]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5626596  0.71367809]\n",
      " [0.71287597 0.79166486]\n",
      " [0.74135944 0.74535304]\n",
      " [0.84689807 0.81692549]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02680806]\n",
      " [ 0.00553253]\n",
      " [ 0.0160353 ]\n",
      " [ 0.03755674]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49329839]\n",
      " [0.50138313]\n",
      " [0.50400874]\n",
      " [0.50938808]]\n",
      "Error [[-0.49329839]\n",
      " [ 0.49861687]\n",
      " [ 0.49599126]\n",
      " [-0.50938808]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25202462 0.9133163 ]\n",
      " [0.90968217 1.33498024]\n",
      " [1.05329139 1.07394872]\n",
      " [1.71094894 1.49561266]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56267477 0.7136783 ]\n",
      " [0.71293512 0.79166323]\n",
      " [0.74140644 0.74534713]\n",
      " [0.84695933 0.81691921]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02686202]\n",
      " [ 0.00553683]\n",
      " [ 0.01605122]\n",
      " [ 0.03760781]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4932849 ]\n",
      " [0.5013842 ]\n",
      " [0.50401272]\n",
      " [0.50940085]]\n",
      "Error [[-0.4932849 ]\n",
      " [ 0.4986158 ]\n",
      " [ 0.49598728]\n",
      " [-0.50940085]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25208633 0.91331732]\n",
      " [0.90997165 1.33497037]\n",
      " [1.05353689 1.07391756]\n",
      " [1.7114222  1.49557061]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56268995 0.71367851]\n",
      " [0.71299436 0.7916616 ]\n",
      " [0.7414535  0.74534121]\n",
      " [0.84702066 0.81691292]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02691602]\n",
      " [ 0.00554116]\n",
      " [ 0.01606716]\n",
      " [ 0.03765894]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4932714 ]\n",
      " [0.50138529]\n",
      " [0.5040167 ]\n",
      " [0.50941362]]\n",
      "Error [[-0.4932714 ]\n",
      " [ 0.49861471]\n",
      " [ 0.4959833 ]\n",
      " [-0.50941362]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25214813 0.91331834]\n",
      " [0.91026158 1.3349605 ]\n",
      " [1.05378278 1.07388636]\n",
      " [1.71189623 1.49552853]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56270516 0.71367872]\n",
      " [0.71305369 0.79165998]\n",
      " [0.74150064 0.74533529]\n",
      " [0.84708207 0.81690662]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02697008]\n",
      " [ 0.0055455 ]\n",
      " [ 0.01608312]\n",
      " [ 0.03771011]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49325789]\n",
      " [0.50138637]\n",
      " [0.50402069]\n",
      " [0.50942641]]\n",
      "Error [[-0.49325789]\n",
      " [ 0.49861363]\n",
      " [ 0.49597931]\n",
      " [-0.50942641]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25221001 0.91331936]\n",
      " [0.91055197 1.33495063]\n",
      " [1.05402907 1.07385513]\n",
      " [1.71237103 1.4954864 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56272039 0.71367893]\n",
      " [0.7131131  0.79165835]\n",
      " [0.74154784 0.74532936]\n",
      " [0.84714356 0.81690032]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02702418]\n",
      " [ 0.00554987]\n",
      " [ 0.0160991 ]\n",
      " [ 0.03776132]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49324437]\n",
      " [0.50138746]\n",
      " [0.50402469]\n",
      " [0.50943921]]\n",
      "Error [[-0.49324437]\n",
      " [ 0.49861254]\n",
      " [ 0.49597531]\n",
      " [-0.50943921]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25227198 0.91332038]\n",
      " [0.91084281 1.33494075]\n",
      " [1.05427576 1.07382386]\n",
      " [1.71284659 1.49544423]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56273563 0.71367913]\n",
      " [0.7131726  0.79165672]\n",
      " [0.74159512 0.74532343]\n",
      " [0.84720514 0.81689402]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02707832]\n",
      " [ 0.00555426]\n",
      " [ 0.01611511]\n",
      " [ 0.03781258]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49323083]\n",
      " [0.50138856]\n",
      " [0.50402869]\n",
      " [0.50945202]]\n",
      "Error [[-0.49323083]\n",
      " [ 0.49861144]\n",
      " [ 0.49597131]\n",
      " [-0.50945202]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25233403 0.9133214 ]\n",
      " [0.91113411 1.33493086]\n",
      " [1.05452285 1.07379256]\n",
      " [1.71332293 1.49540202]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5627509  0.71367934]\n",
      " [0.71323218 0.79165509]\n",
      " [0.74164246 0.74531749]\n",
      " [0.84726679 0.8168877 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02713252]\n",
      " [ 0.00555868]\n",
      " [ 0.01613113]\n",
      " [ 0.03786389]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49321729]\n",
      " [0.50138967]\n",
      " [0.5040327 ]\n",
      " [0.50946484]]\n",
      "Error [[-0.49321729]\n",
      " [ 0.49861033]\n",
      " [ 0.4959673 ]\n",
      " [-0.50946484]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25239617 0.91332243]\n",
      " [0.91142586 1.33492097]\n",
      " [1.05477034 1.07376123]\n",
      " [1.71380004 1.49535977]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56276619 0.71367955]\n",
      " [0.71329185 0.79165346]\n",
      " [0.74168988 0.74531154]\n",
      " [0.84732852 0.81688138]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02718676]\n",
      " [ 0.00556311]\n",
      " [ 0.01614718]\n",
      " [ 0.03791524]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49320373]\n",
      " [0.50139077]\n",
      " [0.50403671]\n",
      " [0.50947768]]\n",
      "Error [[-0.49320373]\n",
      " [ 0.49860923]\n",
      " [ 0.49596329]\n",
      " [-0.50947768]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25245839 0.91332345]\n",
      " [0.91171808 1.33491107]\n",
      " [1.05501822 1.07372987]\n",
      " [1.71427791 1.49531748]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5627815  0.71367976]\n",
      " [0.71335161 0.79165182]\n",
      " [0.74173737 0.74530559]\n",
      " [0.84739033 0.81687506]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02724105]\n",
      " [ 0.00556757]\n",
      " [ 0.01616325]\n",
      " [ 0.03796665]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49319016]\n",
      " [0.50139189]\n",
      " [0.50404072]\n",
      " [0.50949052]]\n",
      "Error [[-0.49319016]\n",
      " [ 0.49860811]\n",
      " [ 0.49595928]\n",
      " [-0.50949052]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25252069 0.91332448]\n",
      " [0.91201075 1.33490117]\n",
      " [1.05526651 1.07369847]\n",
      " [1.71475656 1.49527515]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56279683 0.71367997]\n",
      " [0.71341145 0.79165019]\n",
      " [0.74178493 0.74529963]\n",
      " [0.84745221 0.81686872]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02729538]\n",
      " [ 0.00557205]\n",
      " [ 0.01617934]\n",
      " [ 0.03801809]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49317658]\n",
      " [0.50139301]\n",
      " [0.50404475]\n",
      " [0.50950338]]\n",
      "Error [[-0.49317658]\n",
      " [ 0.49860699]\n",
      " [ 0.49595525]\n",
      " [-0.50950338]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25258309 0.91332551]\n",
      " [0.91230388 1.33489126]\n",
      " [1.05551519 1.07366704]\n",
      " [1.71523598 1.49523278]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56281218 0.71368018]\n",
      " [0.71347138 0.79164856]\n",
      " [0.74183256 0.74529366]\n",
      " [0.84751418 0.81686239]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02734977]\n",
      " [ 0.00557655]\n",
      " [ 0.01619545]\n",
      " [ 0.03806959]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49316298]\n",
      " [0.50139413]\n",
      " [0.50404877]\n",
      " [0.50951625]]\n",
      "Error [[-0.49316298]\n",
      " [ 0.49860587]\n",
      " [ 0.49595123]\n",
      " [-0.50951625]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25264556 0.91332654]\n",
      " [0.91259746 1.33488134]\n",
      " [1.05576428 1.07363557]\n",
      " [1.71571618 1.49519037]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56282756 0.71368039]\n",
      " [0.71353139 0.79164692]\n",
      " [0.74188026 0.74528769]\n",
      " [0.84757623 0.81685604]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0274042 ]\n",
      " [ 0.00558108]\n",
      " [ 0.01621158]\n",
      " [ 0.03812113]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49314938]\n",
      " [0.50139527]\n",
      " [0.50405281]\n",
      " [0.50952913]]\n",
      "Error [[-0.49314938]\n",
      " [ 0.49860473]\n",
      " [ 0.49594719]\n",
      " [-0.50952913]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25270812 0.91332757]\n",
      " [0.91289151 1.33487142]\n",
      " [1.05601377 1.07360407]\n",
      " [1.71619715 1.49514792]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56284295 0.7136806 ]\n",
      " [0.71359149 0.79164528]\n",
      " [0.74192803 0.74528171]\n",
      " [0.84763836 0.81684969]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02745868]\n",
      " [ 0.00558562]\n",
      " [ 0.01622774]\n",
      " [ 0.03817271]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49313576]\n",
      " [0.5013964 ]\n",
      " [0.50405684]\n",
      " [0.50954202]]\n",
      "Error [[-0.49313576]\n",
      " [ 0.4986036 ]\n",
      " [ 0.49594316]\n",
      " [-0.50954202]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25277077 0.9133286 ]\n",
      " [0.91318601 1.33486149]\n",
      " [1.05626365 1.07357254]\n",
      " [1.71667889 1.49510543]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56285836 0.71368082]\n",
      " [0.71365168 0.79164365]\n",
      " [0.74197588 0.74527572]\n",
      " [0.84770056 0.81684333]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0275132 ]\n",
      " [ 0.00559019]\n",
      " [ 0.01624391]\n",
      " [ 0.03822435]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49312213]\n",
      " [0.50139754]\n",
      " [0.50406089]\n",
      " [0.50955492]]\n",
      "Error [[-0.49312213]\n",
      " [ 0.49860246]\n",
      " [ 0.49593911]\n",
      " [-0.50955492]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2528335  0.91332964]\n",
      " [0.91348097 1.33485156]\n",
      " [1.05651394 1.07354097]\n",
      " [1.71716141 1.49506289]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5628738  0.71368103]\n",
      " [0.71371195 0.79164201]\n",
      " [0.74202379 0.74526973]\n",
      " [0.84776285 0.81683697]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02756778]\n",
      " [ 0.00559478]\n",
      " [ 0.01626011]\n",
      " [ 0.03827603]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49310849]\n",
      " [0.50139869]\n",
      " [0.50406494]\n",
      " [0.50956784]]\n",
      "Error [[-0.49310849]\n",
      " [ 0.49860131]\n",
      " [ 0.49593506]\n",
      " [-0.50956784]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25289632 0.91333067]\n",
      " [0.9137764  1.33484162]\n",
      " [1.05676463 1.07350937]\n",
      " [1.71764471 1.49502032]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56288926 0.71368124]\n",
      " [0.71377231 0.79164037]\n",
      " [0.74207178 0.74526373]\n",
      " [0.84782521 0.8168306 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0276224 ]\n",
      " [ 0.0055994 ]\n",
      " [ 0.01627633]\n",
      " [ 0.03832776]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49309484]\n",
      " [0.50139985]\n",
      " [0.50406899]\n",
      " [0.50958077]]\n",
      "Error [[-0.49309484]\n",
      " [ 0.49860015]\n",
      " [ 0.49593101]\n",
      " [-0.50958077]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25295922 0.91333171]\n",
      " [0.91407228 1.33483168]\n",
      " [1.05701573 1.07347774]\n",
      " [1.71812878 1.49497771]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56290473 0.71368145]\n",
      " [0.71383275 0.79163873]\n",
      " [0.74211983 0.74525772]\n",
      " [0.84788765 0.81682422]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02767707]\n",
      " [ 0.00560403]\n",
      " [ 0.01629257]\n",
      " [ 0.03837953]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49308117]\n",
      " [0.501401  ]\n",
      " [0.50407305]\n",
      " [0.50959371]]\n",
      "Error [[-0.49308117]\n",
      " [ 0.498599  ]\n",
      " [ 0.49592695]\n",
      " [-0.50959371]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25302221 0.91333275]\n",
      " [0.91436862 1.33482173]\n",
      " [1.05726722 1.07344607]\n",
      " [1.71861363 1.49493505]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56292023 0.71368166]\n",
      " [0.71389329 0.79163709]\n",
      " [0.74216796 0.74525171]\n",
      " [0.84795018 0.81681784]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02773179]\n",
      " [ 0.00560869]\n",
      " [ 0.01630884]\n",
      " [ 0.03843135]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4930675 ]\n",
      " [0.50140217]\n",
      " [0.50407712]\n",
      " [0.50960666]]\n",
      "Error [[-0.4930675 ]\n",
      " [ 0.49859783]\n",
      " [ 0.49592288]\n",
      " [-0.50960666]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25308528 0.91333379]\n",
      " [0.91466542 1.33481177]\n",
      " [1.05751912 1.07341437]\n",
      " [1.71909926 1.49489236]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56293575 0.71368187]\n",
      " [0.7139539  0.79163544]\n",
      " [0.74221616 0.74524569]\n",
      " [0.84801278 0.81681145]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02778656]\n",
      " [ 0.00561337]\n",
      " [ 0.01632512]\n",
      " [ 0.03848322]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49305381]\n",
      " [0.50140334]\n",
      " [0.50408119]\n",
      " [0.50961962]]\n",
      "Error [[-0.49305381]\n",
      " [ 0.49859666]\n",
      " [ 0.49591881]\n",
      " [-0.50961962]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25314844 0.91333483]\n",
      " [0.91496269 1.33480181]\n",
      " [1.05777142 1.07338264]\n",
      " [1.71958567 1.49484962]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56295129 0.71368209]\n",
      " [0.71401461 0.7916338 ]\n",
      " [0.74226443 0.74523967]\n",
      " [0.84807546 0.81680506]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02784138]\n",
      " [ 0.00561808]\n",
      " [ 0.01634143]\n",
      " [ 0.03853514]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49304011]\n",
      " [0.50140452]\n",
      " [0.50408527]\n",
      " [0.50963259]]\n",
      "Error [[-0.49304011]\n",
      " [ 0.49859548]\n",
      " [ 0.49591473]\n",
      " [-0.50963259]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25321168 0.91333587]\n",
      " [0.91526041 1.33479184]\n",
      " [1.05802413 1.07335087]\n",
      " [1.72007285 1.49480684]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56296685 0.7136823 ]\n",
      " [0.7140754  0.79163216]\n",
      " [0.74231277 0.74523364]\n",
      " [0.84813822 0.81679866]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02789624]\n",
      " [ 0.0056228 ]\n",
      " [ 0.01635776]\n",
      " [ 0.0385871 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49302639]\n",
      " [0.5014057 ]\n",
      " [0.50408935]\n",
      " [0.50964558]]\n",
      "Error [[-0.49302639]\n",
      " [ 0.4985943 ]\n",
      " [ 0.49591065]\n",
      " [-0.50964558]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25327501 0.91333692]\n",
      " [0.9155586  1.33478187]\n",
      " [1.05827723 1.07331907]\n",
      " [1.72056082 1.49476402]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56298243 0.71368251]\n",
      " [0.71413628 0.79163051]\n",
      " [0.74236119 0.7452276 ]\n",
      " [0.84820106 0.81679225]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02795116]\n",
      " [ 0.00562755]\n",
      " [ 0.01637411]\n",
      " [ 0.03863911]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49301267]\n",
      " [0.50140688]\n",
      " [0.50409344]\n",
      " [0.50965858]]\n",
      "Error [[-0.49301267]\n",
      " [ 0.49859312]\n",
      " [ 0.49590656]\n",
      " [-0.50965858]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25333843 0.91333796]\n",
      " [0.91585725 1.33477189]\n",
      " [1.05853075 1.07328724]\n",
      " [1.72104957 1.49472116]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56299803 0.71368273]\n",
      " [0.71419724 0.79162887]\n",
      " [0.74240967 0.74522155]\n",
      " [0.84826398 0.81678584]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02800612]\n",
      " [ 0.00563232]\n",
      " [ 0.01639049]\n",
      " [ 0.03869117]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49299893]\n",
      " [0.50140808]\n",
      " [0.50409753]\n",
      " [0.50967159]]\n",
      "Error [[-0.49299893]\n",
      " [ 0.49859192]\n",
      " [ 0.49590247]\n",
      " [-0.50967159]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25340192 0.91333901]\n",
      " [0.91615636 1.3347619 ]\n",
      " [1.05878467 1.07325537]\n",
      " [1.7215391  1.49467826]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56301365 0.71368294]\n",
      " [0.71425829 0.79162722]\n",
      " [0.74245822 0.7452155 ]\n",
      " [0.84832698 0.81677942]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02806113]\n",
      " [ 0.00563712]\n",
      " [ 0.01640688]\n",
      " [ 0.03874328]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49298518]\n",
      " [0.50140928]\n",
      " [0.50410163]\n",
      " [0.50968461]]\n",
      "Error [[-0.49298518]\n",
      " [ 0.49859072]\n",
      " [ 0.49589837]\n",
      " [-0.50968461]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25346551 0.91334006]\n",
      " [0.91645594 1.33475191]\n",
      " [1.05903899 1.07322347]\n",
      " [1.72202942 1.49463532]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5630293  0.71368316]\n",
      " [0.71431943 0.79162557]\n",
      " [0.74250685 0.74520945]\n",
      " [0.84839005 0.81677299]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02811619]\n",
      " [ 0.00564193]\n",
      " [ 0.0164233 ]\n",
      " [ 0.03879543]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49297141]\n",
      " [0.50141048]\n",
      " [0.50410573]\n",
      " [0.50969764]]\n",
      "Error [[-0.49297141]\n",
      " [ 0.49858952]\n",
      " [ 0.49589427]\n",
      " [-0.50969764]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25352917 0.91334111]\n",
      " [0.91675597 1.33474192]\n",
      " [1.05929372 1.07319153]\n",
      " [1.72252052 1.49459234]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56304496 0.71368337]\n",
      " [0.71438065 0.79162392]\n",
      " [0.74255555 0.74520338]\n",
      " [0.84845321 0.81676656]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0281713 ]\n",
      " [ 0.00564677]\n",
      " [ 0.01643975]\n",
      " [ 0.03884763]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49295764]\n",
      " [0.50141169]\n",
      " [0.50410984]\n",
      " [0.50971069]]\n",
      "Error [[-0.49295764]\n",
      " [ 0.49858831]\n",
      " [ 0.49589016]\n",
      " [-0.50971069]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25359293 0.91334216]\n",
      " [0.91705648 1.33473192]\n",
      " [1.05954885 1.07315956]\n",
      " [1.7230124  1.49454932]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56306064 0.71368358]\n",
      " [0.71444196 0.79162227]\n",
      " [0.74260432 0.74519731]\n",
      " [0.84851645 0.81676012]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02822646]\n",
      " [ 0.00565163]\n",
      " [ 0.01645621]\n",
      " [ 0.03889988]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49294385]\n",
      " [0.5014129 ]\n",
      " [0.50411396]\n",
      " [0.50972375]]\n",
      "Error [[-0.49294385]\n",
      " [ 0.4985871 ]\n",
      " [ 0.49588604]\n",
      " [-0.50972375]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25365677 0.91334321]\n",
      " [0.91735744 1.33472191]\n",
      " [1.05980439 1.07312755]\n",
      " [1.72350507 1.49450625]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56307635 0.7136838 ]\n",
      " [0.71450336 0.79162062]\n",
      " [0.74265316 0.74519124]\n",
      " [0.84857976 0.81675367]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02828167]\n",
      " [ 0.00565652]\n",
      " [ 0.0164727 ]\n",
      " [ 0.03895218]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49293005]\n",
      " [0.50141413]\n",
      " [0.50411808]\n",
      " [0.50973681]]\n",
      "Error [[-0.49293005]\n",
      " [ 0.49858587]\n",
      " [ 0.49588192]\n",
      " [-0.50973681]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25372069 0.91334426]\n",
      " [0.91765887 1.3347119 ]\n",
      " [1.06006034 1.07309552]\n",
      " [1.72399852 1.49446315]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56309208 0.71368401]\n",
      " [0.71456484 0.79161897]\n",
      " [0.74270208 0.74518515]\n",
      " [0.84864315 0.81674722]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02833693]\n",
      " [ 0.00566143]\n",
      " [ 0.0164892 ]\n",
      " [ 0.03900453]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49291624]\n",
      " [0.50141535]\n",
      " [0.50412221]\n",
      " [0.5097499 ]]\n",
      "Error [[-0.49291624]\n",
      " [ 0.49858465]\n",
      " [ 0.49587779]\n",
      " [-0.5097499 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.2537847  0.91334532]\n",
      " [0.91796077 1.33470188]\n",
      " [1.06031669 1.07306344]\n",
      " [1.72449276 1.49442   ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56310782 0.71368423]\n",
      " [0.71462642 0.79161732]\n",
      " [0.74275106 0.74517906]\n",
      " [0.84870663 0.81674076]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02839224]\n",
      " [ 0.00566636]\n",
      " [ 0.01650574]\n",
      " [ 0.03905692]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49290242]\n",
      " [0.50141659]\n",
      " [0.50412634]\n",
      " [0.50976299]]\n",
      "Error [[-0.49290242]\n",
      " [ 0.49858341]\n",
      " [ 0.49587366]\n",
      " [-0.50976299]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25384879 0.91334637]\n",
      " [0.91826313 1.33469185]\n",
      " [1.06057345 1.07303134]\n",
      " [1.72498779 1.49437682]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56312359 0.71368445]\n",
      " [0.71468807 0.79161566]\n",
      " [0.74280012 0.74517296]\n",
      " [0.84877018 0.8167343 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0284476 ]\n",
      " [ 0.00567132]\n",
      " [ 0.01652229]\n",
      " [ 0.03910936]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49288858]\n",
      " [0.50141783]\n",
      " [0.50413048]\n",
      " [0.50977609]]\n",
      "Error [[-0.49288858]\n",
      " [ 0.49858217]\n",
      " [ 0.49586952]\n",
      " [-0.50977609]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25391297 0.91334743]\n",
      " [0.91856595 1.33468182]\n",
      " [1.06083062 1.0729992 ]\n",
      " [1.7254836  1.49433359]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56313938 0.71368466]\n",
      " [0.71474982 0.79161401]\n",
      " [0.74284925 0.74516686]\n",
      " [0.84883381 0.81672783]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02850301]\n",
      " [ 0.00567629]\n",
      " [ 0.01653887]\n",
      " [ 0.03916185]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49287473]\n",
      " [0.50141907]\n",
      " [0.50413462]\n",
      " [0.50978921]]\n",
      "Error [[-0.49287473]\n",
      " [ 0.49858093]\n",
      " [ 0.49586538]\n",
      " [-0.50978921]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25397723 0.91334849]\n",
      " [0.91886924 1.33467179]\n",
      " [1.0610882  1.07296702]\n",
      " [1.72598021 1.49429032]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56315519 0.71368488]\n",
      " [0.71481165 0.79161235]\n",
      " [0.74289845 0.74516075]\n",
      " [0.84889752 0.81672135]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02855847]\n",
      " [ 0.00568129]\n",
      " [ 0.01655547]\n",
      " [ 0.03921439]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49286087]\n",
      " [0.50142032]\n",
      " [0.50413877]\n",
      " [0.50980234]]\n",
      "Error [[-0.49286087]\n",
      " [ 0.49857968]\n",
      " [ 0.49586123]\n",
      " [-0.50980234]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25404158 0.91334955]\n",
      " [0.919173   1.33466175]\n",
      " [1.06134618 1.07293482]\n",
      " [1.7264776  1.49424701]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56317102 0.7136851 ]\n",
      " [0.71487357 0.7916107 ]\n",
      " [0.74294772 0.74515464]\n",
      " [0.84896131 0.81671487]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02861398]\n",
      " [ 0.00568632]\n",
      " [ 0.01657209]\n",
      " [ 0.03926698]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49284699]\n",
      " [0.50142158]\n",
      " [0.50414293]\n",
      " [0.50981548]]\n",
      "Error [[-0.49284699]\n",
      " [ 0.49857842]\n",
      " [ 0.49585707]\n",
      " [-0.50981548]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25410601 0.91335061]\n",
      " [0.91947722 1.3346517 ]\n",
      " [1.06160457 1.07290257]\n",
      " [1.72697579 1.49420366]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56318687 0.71368531]\n",
      " [0.71493557 0.79160904]\n",
      " [0.74299706 0.74514851]\n",
      " [0.84902518 0.81670838]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02866953]\n",
      " [ 0.00569137]\n",
      " [ 0.01658873]\n",
      " [ 0.03931962]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49283311]\n",
      " [0.50142284]\n",
      " [0.50414709]\n",
      " [0.50982864]]\n",
      "Error [[-0.49283311]\n",
      " [ 0.49857716]\n",
      " [ 0.49585291]\n",
      " [-0.50982864]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25417053 0.91335168]\n",
      " [0.91978191 1.33464165]\n",
      " [1.06186338 1.0728703 ]\n",
      " [1.72747476 1.49416027]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56320274 0.71368553]\n",
      " [0.71499767 0.79160738]\n",
      " [0.74304648 0.74514238]\n",
      " [0.84908913 0.81670189]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02872514]\n",
      " [ 0.00569644]\n",
      " [ 0.0166054 ]\n",
      " [ 0.0393723 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49281921]\n",
      " [0.50142411]\n",
      " [0.50415125]\n",
      " [0.5098418 ]]\n",
      "Error [[-0.49281921]\n",
      " [ 0.49857589]\n",
      " [ 0.49584875]\n",
      " [-0.5098418 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25423513 0.91335274]\n",
      " [0.92008707 1.33463159]\n",
      " [1.06212259 1.07283799]\n",
      " [1.72797453 1.49411683]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56321864 0.71368575]\n",
      " [0.71505985 0.79160572]\n",
      " [0.74309597 0.74513625]\n",
      " [0.84915316 0.81669538]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0287808 ]\n",
      " [ 0.00570153]\n",
      " [ 0.01662209]\n",
      " [ 0.03942503]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4928053 ]\n",
      " [0.50142538]\n",
      " [0.50415543]\n",
      " [0.50985498]]\n",
      "Error [[-0.4928053 ]\n",
      " [ 0.49857462]\n",
      " [ 0.49584457]\n",
      " [-0.50985498]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25429982 0.91335381]\n",
      " [0.9203927  1.33462153]\n",
      " [1.06238221 1.07280564]\n",
      " [1.72847509 1.49407336]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56323455 0.71368597]\n",
      " [0.71512211 0.79160406]\n",
      " [0.74314553 0.7451301 ]\n",
      " [0.84921726 0.81668887]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02883651]\n",
      " [ 0.00570665]\n",
      " [ 0.0166388 ]\n",
      " [ 0.03947781]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49279137]\n",
      " [0.50142666]\n",
      " [0.50415961]\n",
      " [0.50986817]]\n",
      "Error [[-0.49279137]\n",
      " [ 0.49857334]\n",
      " [ 0.49584039]\n",
      " [-0.50986817]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25436459 0.91335488]\n",
      " [0.92069879 1.33461146]\n",
      " [1.06264224 1.07277326]\n",
      " [1.72897644 1.49402984]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56325048 0.71368618]\n",
      " [0.71518447 0.7916024 ]\n",
      " [0.74319516 0.74512396]\n",
      " [0.84928145 0.81668236]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02889227]\n",
      " [ 0.00571179]\n",
      " [ 0.01665554]\n",
      " [ 0.03953065]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49277743]\n",
      " [0.50142794]\n",
      " [0.50416379]\n",
      " [0.50988137]]\n",
      "Error [[-0.49277743]\n",
      " [ 0.49857206]\n",
      " [ 0.49583621]\n",
      " [-0.50988137]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25442945 0.91335595]\n",
      " [0.92100535 1.33460139]\n",
      " [1.06290269 1.07274085]\n",
      " [1.72947859 1.49398629]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56326644 0.7136864 ]\n",
      " [0.71524691 0.79160074]\n",
      " [0.74324486 0.7451178 ]\n",
      " [0.84934571 0.81667584]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02894808]\n",
      " [ 0.00571695]\n",
      " [ 0.0166723 ]\n",
      " [ 0.03958352]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49276348]\n",
      " [0.50142923]\n",
      " [0.50416798]\n",
      " [0.50989459]]\n",
      "Error [[-0.49276348]\n",
      " [ 0.49857077]\n",
      " [ 0.49583202]\n",
      " [-0.50989459]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25449439 0.91335702]\n",
      " [0.92131238 1.33459131]\n",
      " [1.06316354 1.0727084 ]\n",
      " [1.72998153 1.49394269]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56328241 0.71368662]\n",
      " [0.71530944 0.79159908]\n",
      " [0.74329464 0.74511164]\n",
      " [0.84941006 0.81666931]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02900395]\n",
      " [ 0.00572214]\n",
      " [ 0.01668908]\n",
      " [ 0.03963645]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49274952]\n",
      " [0.50143053]\n",
      " [0.50417217]\n",
      " [0.50990782]]\n",
      "Error [[-0.49274952]\n",
      " [ 0.49856947]\n",
      " [ 0.49582783]\n",
      " [-0.50990782]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25455942 0.91335809]\n",
      " [0.92161988 1.33458122]\n",
      " [1.0634248  1.07267592]\n",
      " [1.73048527 1.49389905]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56329841 0.71368684]\n",
      " [0.71537205 0.79159741]\n",
      " [0.74334449 0.74510547]\n",
      " [0.84947448 0.81666278]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02905986]\n",
      " [ 0.00572735]\n",
      " [ 0.01670589]\n",
      " [ 0.03968943]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49273555]\n",
      " [0.50143183]\n",
      " [0.50417638]\n",
      " [0.50992106]]\n",
      "Error [[-0.49273555]\n",
      " [ 0.49856817]\n",
      " [ 0.49582362]\n",
      " [-0.50992106]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25462453 0.91335917]\n",
      " [0.92192785 1.33457113]\n",
      " [1.06368648 1.0726434 ]\n",
      " [1.7309898  1.49385537]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56331443 0.71368706]\n",
      " [0.71543476 0.79159575]\n",
      " [0.74339441 0.74509929]\n",
      " [0.84953898 0.81665624]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02911583]\n",
      " [ 0.00573259]\n",
      " [ 0.01672272]\n",
      " [ 0.03974246]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49272156]\n",
      " [0.50143314]\n",
      " [0.50418058]\n",
      " [0.50993431]]\n",
      "Error [[-0.49272156]\n",
      " [ 0.49856686]\n",
      " [ 0.49581942]\n",
      " [-0.50993431]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25468973 0.91336024]\n",
      " [0.92223629 1.33456104]\n",
      " [1.06394857 1.07261085]\n",
      " [1.73149513 1.49381165]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56333046 0.71368728]\n",
      " [0.71549755 0.79159408]\n",
      " [0.7434444  0.74509311]\n",
      " [0.84960356 0.81664969]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02917184]\n",
      " [ 0.00573785]\n",
      " [ 0.01673957]\n",
      " [ 0.03979553]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49270756]\n",
      " [0.50143446]\n",
      " [0.50418479]\n",
      " [0.50994757]]\n",
      "Error [[-0.49270756]\n",
      " [ 0.49856554]\n",
      " [ 0.49581521]\n",
      " [-0.50994757]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25475501 0.91336132]\n",
      " [0.9225452  1.33455093]\n",
      " [1.06421107 1.07257827]\n",
      " [1.73200126 1.49376788]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56334652 0.7136875 ]\n",
      " [0.71556042 0.79159242]\n",
      " [0.74349446 0.74508692]\n",
      " [0.84966822 0.81664314]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02922791]\n",
      " [ 0.00574313]\n",
      " [ 0.01675645]\n",
      " [ 0.03984866]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49269354]\n",
      " [0.50143578]\n",
      " [0.50418901]\n",
      " [0.50996085]]\n",
      "Error [[-0.49269354]\n",
      " [ 0.49856422]\n",
      " [ 0.49581099]\n",
      " [-0.50996085]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25482038 0.9133624 ]\n",
      " [0.92285458 1.33454083]\n",
      " [1.06447398 1.07254565]\n",
      " [1.73250819 1.49372408]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5633626  0.71368772]\n",
      " [0.71562339 0.79159075]\n",
      " [0.7435446  0.74508073]\n",
      " [0.84973296 0.81663658]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02928403]\n",
      " [ 0.00574844]\n",
      " [ 0.01677335]\n",
      " [ 0.03990183]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49267952]\n",
      " [0.50143711]\n",
      " [0.50419324]\n",
      " [0.50997414]]\n",
      "Error [[-0.49267952]\n",
      " [ 0.49856289]\n",
      " [ 0.49580676]\n",
      " [-0.50997414]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25488583 0.91336348]\n",
      " [0.92316443 1.33453072]\n",
      " [1.06473731 1.07251299]\n",
      " [1.73301591 1.49368023]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5633787  0.71368794]\n",
      " [0.71568644 0.79158908]\n",
      " [0.74359481 0.74507452]\n",
      " [0.84979778 0.81663001]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0293402 ]\n",
      " [ 0.00575377]\n",
      " [ 0.01679027]\n",
      " [ 0.03995506]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49266548]\n",
      " [0.50143844]\n",
      " [0.50419747]\n",
      " [0.50998744]]\n",
      "Error [[-0.49266548]\n",
      " [ 0.49856156]\n",
      " [ 0.49580253]\n",
      " [-0.50998744]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25495137 0.91336456]\n",
      " [0.92347475 1.3345206 ]\n",
      " [1.06500105 1.0724803 ]\n",
      " [1.73352444 1.49363634]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56339482 0.71368816]\n",
      " [0.71574958 0.79158741]\n",
      " [0.74364509 0.74506831]\n",
      " [0.84986268 0.81662344]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02939642]\n",
      " [ 0.00575912]\n",
      " [ 0.01680721]\n",
      " [ 0.04000833]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49265142]\n",
      " [0.50143978]\n",
      " [0.5042017 ]\n",
      " [0.51000075]]\n",
      "Error [[-0.49265142]\n",
      " [ 0.49856022]\n",
      " [ 0.4957983 ]\n",
      " [-0.51000075]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25501699 0.91336564]\n",
      " [0.92378555 1.33451047]\n",
      " [1.06526521 1.07244758]\n",
      " [1.73403377 1.49359242]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56341096 0.71368838]\n",
      " [0.71581281 0.79158574]\n",
      " [0.74369545 0.7450621 ]\n",
      " [0.84992766 0.81661686]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02945269]\n",
      " [ 0.0057645 ]\n",
      " [ 0.01682418]\n",
      " [ 0.04006166]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49263736]\n",
      " [0.50144112]\n",
      " [0.50420595]\n",
      " [0.51001407]]\n",
      "Error [[-0.49263736]\n",
      " [ 0.49855888]\n",
      " [ 0.49579405]\n",
      " [-0.51001407]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25508269 0.91336672]\n",
      " [0.92409681 1.33450035]\n",
      " [1.06552978 1.07241482]\n",
      " [1.7345439  1.49354845]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56342713 0.7136886 ]\n",
      " [0.71587612 0.79158407]\n",
      " [0.74374587 0.74505588]\n",
      " [0.84999271 0.81661028]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02950902]\n",
      " [ 0.0057699 ]\n",
      " [ 0.01684118]\n",
      " [ 0.04011503]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49262328]\n",
      " [0.50144247]\n",
      " [0.50421019]\n",
      " [0.51002741]]\n",
      "Error [[-0.49262328]\n",
      " [ 0.49855753]\n",
      " [ 0.49578981]\n",
      " [-0.51002741]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25514848 0.91336781]\n",
      " [0.92440855 1.33449021]\n",
      " [1.06579476 1.07238203]\n",
      " [1.73505483 1.49350443]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56344331 0.71368883]\n",
      " [0.71593953 0.7915824 ]\n",
      " [0.74379637 0.74504965]\n",
      " [0.85005785 0.81660369]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0295654 ]\n",
      " [ 0.00577533]\n",
      " [ 0.01685819]\n",
      " [ 0.04016845]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49260919]\n",
      " [0.50144383]\n",
      " [0.50421445]\n",
      " [0.51004076]]\n",
      "Error [[-0.49260919]\n",
      " [ 0.49855617]\n",
      " [ 0.49578555]\n",
      " [-0.51004076]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25521436 0.9133689 ]\n",
      " [0.92472077 1.33448007]\n",
      " [1.06606016 1.0723492 ]\n",
      " [1.73556657 1.49346038]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56345951 0.71368905]\n",
      " [0.71600302 0.79158073]\n",
      " [0.74384695 0.74504341]\n",
      " [0.85012306 0.81659709]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02962183]\n",
      " [ 0.00578078]\n",
      " [ 0.01687523]\n",
      " [ 0.04022193]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49259508]\n",
      " [0.50144519]\n",
      " [0.50421871]\n",
      " [0.51005413]]\n",
      "Error [[-0.49259508]\n",
      " [ 0.49855481]\n",
      " [ 0.49578129]\n",
      " [-0.51005413]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25528032 0.91336999]\n",
      " [0.92503345 1.33446993]\n",
      " [1.06632597 1.07231634]\n",
      " [1.7360791  1.49341629]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56347574 0.71368927]\n",
      " [0.71606659 0.79157905]\n",
      " [0.74389759 0.74503717]\n",
      " [0.85018835 0.81659048]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02967831]\n",
      " [ 0.00578625]\n",
      " [ 0.0168923 ]\n",
      " [ 0.04027545]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49258097]\n",
      " [0.50144656]\n",
      " [0.50422297]\n",
      " [0.5100675 ]]\n",
      "Error [[-0.49258097]\n",
      " [ 0.49855344]\n",
      " [ 0.49577703]\n",
      " [-0.5100675 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25534636 0.91337108]\n",
      " [0.92534661 1.33445978]\n",
      " [1.0665922  1.07228345]\n",
      " [1.73659245 1.49337215]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56349198 0.71368949]\n",
      " [0.71613026 0.79157738]\n",
      " [0.74394831 0.74503092]\n",
      " [0.85025373 0.81658387]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02973484]\n",
      " [ 0.00579175]\n",
      " [ 0.01690938]\n",
      " [ 0.04032902]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49256684]\n",
      " [0.50144793]\n",
      " [0.50422724]\n",
      " [0.51008089]]\n",
      "Error [[-0.49256684]\n",
      " [ 0.49855207]\n",
      " [ 0.49577276]\n",
      " [-0.51008089]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25541249 0.91337217]\n",
      " [0.92566024 1.33444962]\n",
      " [1.06685885 1.07225052]\n",
      " [1.7371066  1.49332797]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56350825 0.71368972]\n",
      " [0.71619401 0.7915757 ]\n",
      " [0.7439991  0.74502467]\n",
      " [0.85031918 0.81657726]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02979143]\n",
      " [ 0.00579727]\n",
      " [ 0.01692649]\n",
      " [ 0.04038265]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49255269]\n",
      " [0.50144931]\n",
      " [0.50423152]\n",
      " [0.51009429]]\n",
      "Error [[-0.49255269]\n",
      " [ 0.49855069]\n",
      " [ 0.49576848]\n",
      " [-0.51009429]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25547871 0.91337326]\n",
      " [0.92597435 1.33443946]\n",
      " [1.06712591 1.07221755]\n",
      " [1.73762155 1.49328375]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56352454 0.71368994]\n",
      " [0.71625786 0.79157403]\n",
      " [0.74404996 0.7450184 ]\n",
      " [0.85038471 0.81657063]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02984807]\n",
      " [ 0.00580282]\n",
      " [ 0.01694363]\n",
      " [ 0.04043632]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49253854]\n",
      " [0.5014507 ]\n",
      " [0.50423581]\n",
      " [0.5101077 ]]\n",
      "Error [[-0.49253854]\n",
      " [ 0.4985493 ]\n",
      " [ 0.49576419]\n",
      " [-0.5101077 ]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25554501 0.91337436]\n",
      " [0.92628893 1.3344293 ]\n",
      " [1.06739339 1.07218455]\n",
      " [1.73813732 1.49323949]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56354084 0.71369016]\n",
      " [0.71632178 0.79157235]\n",
      " [0.7441009  0.74501213]\n",
      " [0.85045032 0.816564  ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02990476]\n",
      " [ 0.00580839]\n",
      " [ 0.01696079]\n",
      " [ 0.04049004]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49252437]\n",
      " [0.50145209]\n",
      " [0.5042401 ]\n",
      " [0.51012113]]\n",
      "Error [[-0.49252437]\n",
      " [ 0.49854791]\n",
      " [ 0.4957599 ]\n",
      " [-0.51012113]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25561139 0.91337546]\n",
      " [0.92660399 1.33441913]\n",
      " [1.06766129 1.07215152]\n",
      " [1.73865389 1.49319519]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56355717 0.71369039]\n",
      " [0.7163858  0.79157067]\n",
      " [0.7441519  0.74500586]\n",
      " [0.850516   0.81655737]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.02996151]\n",
      " [ 0.00581399]\n",
      " [ 0.01697797]\n",
      " [ 0.04054382]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49251018]\n",
      " [0.50145349]\n",
      " [0.50424439]\n",
      " [0.51013457]]\n",
      "Error [[-0.49251018]\n",
      " [ 0.49854651]\n",
      " [ 0.49575561]\n",
      " [-0.51013457]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25567786 0.91337655]\n",
      " [0.92691952 1.33440895]\n",
      " [1.0679296  1.07211845]\n",
      " [1.73917127 1.49315084]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56357352 0.71369061]\n",
      " [0.71644991 0.79156899]\n",
      " [0.74420298 0.74499958]\n",
      " [0.85058177 0.81655073]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03001831]\n",
      " [ 0.00581961]\n",
      " [ 0.01699518]\n",
      " [ 0.04059764]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49249599]\n",
      " [0.5014549 ]\n",
      " [0.50424869]\n",
      " [0.51014802]]\n",
      "Error [[-0.49249599]\n",
      " [ 0.4985451 ]\n",
      " [ 0.49575131]\n",
      " [-0.51014802]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25574441 0.91337765]\n",
      " [0.92723553 1.33439877]\n",
      " [1.06819834 1.07208534]\n",
      " [1.73968946 1.49310646]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56358989 0.71369084]\n",
      " [0.7165141  0.79156731]\n",
      " [0.74425414 0.74499329]\n",
      " [0.85064762 0.81654408]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03007516]\n",
      " [ 0.00582525]\n",
      " [ 0.01701241]\n",
      " [ 0.04065152]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49248178]\n",
      " [0.50145631]\n",
      " [0.504253  ]\n",
      " [0.51016148]]\n",
      "Error [[-0.49248178]\n",
      " [ 0.49854369]\n",
      " [ 0.495747  ]\n",
      " [-0.51016148]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25581105 0.91337876]\n",
      " [0.92755202 1.33438858]\n",
      " [1.06846749 1.0720522 ]\n",
      " [1.74020846 1.49306203]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56360628 0.71369106]\n",
      " [0.71657838 0.79156563]\n",
      " [0.74430537 0.74498699]\n",
      " [0.85071354 0.81653742]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03013206]\n",
      " [ 0.00583092]\n",
      " [ 0.01702966]\n",
      " [ 0.04070545]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49246755]\n",
      " [0.50145773]\n",
      " [0.50425731]\n",
      " [0.51017496]]\n",
      "Error [[-0.49246755]\n",
      " [ 0.49854227]\n",
      " [ 0.49574269]\n",
      " [-0.51017496]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25587777 0.91337986]\n",
      " [0.92786898 1.33437839]\n",
      " [1.06873706 1.07201903]\n",
      " [1.74072827 1.49301756]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56362269 0.71369129]\n",
      " [0.71664275 0.79156395]\n",
      " [0.74435667 0.74498069]\n",
      " [0.85077955 0.81653076]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03018902]\n",
      " [ 0.00583662]\n",
      " [ 0.01704694]\n",
      " [ 0.04075942]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49245332]\n",
      " [0.50145915]\n",
      " [0.50426163]\n",
      " [0.51018845]]\n",
      "Error [[-0.49245332]\n",
      " [ 0.49854085]\n",
      " [ 0.49573837]\n",
      " [-0.51018845]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25594458 0.91338096]\n",
      " [0.92818642 1.33436819]\n",
      " [1.06900705 1.07198582]\n",
      " [1.74124889 1.49297305]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56363912 0.71369151]\n",
      " [0.7167072  0.79156227]\n",
      " [0.74440804 0.74497438]\n",
      " [0.85084563 0.81652409]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03024603]\n",
      " [ 0.00584233]\n",
      " [ 0.01706425]\n",
      " [ 0.04081345]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49243907]\n",
      " [0.50146058]\n",
      " [0.50426596]\n",
      " [0.51020195]]\n",
      "Error [[-0.49243907]\n",
      " [ 0.49853942]\n",
      " [ 0.49573404]\n",
      " [-0.51020195]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25601147 0.91338207]\n",
      " [0.92850434 1.33435799]\n",
      " [1.06927746 1.07195257]\n",
      " [1.74177032 1.4929285 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56365557 0.71369174]\n",
      " [0.71677175 0.79156058]\n",
      " [0.74445948 0.74496806]\n",
      " [0.85091179 0.81651742]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0303031 ]\n",
      " [ 0.00584808]\n",
      " [ 0.01708157]\n",
      " [ 0.04086753]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4924248 ]\n",
      " [0.50146202]\n",
      " [0.50427029]\n",
      " [0.51021546]]\n",
      "Error [[-0.4924248 ]\n",
      " [ 0.49853798]\n",
      " [ 0.49572971]\n",
      " [-0.51021546]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25607845 0.91338318]\n",
      " [0.92882273 1.33434778]\n",
      " [1.06954829 1.07191929]\n",
      " [1.74229257 1.4928839 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56367204 0.71369197]\n",
      " [0.71683638 0.7915589 ]\n",
      " [0.744511   0.74496174]\n",
      " [0.85097803 0.81651074]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03036022]\n",
      " [ 0.00585385]\n",
      " [ 0.01709893]\n",
      " [ 0.04092166]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49241053]\n",
      " [0.50146346]\n",
      " [0.50427463]\n",
      " [0.51022899]]\n",
      "Error [[-0.49241053]\n",
      " [ 0.49853654]\n",
      " [ 0.49572537]\n",
      " [-0.51022899]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25614551 0.91338429]\n",
      " [0.9291416  1.33433757]\n",
      " [1.06981954 1.07188598]\n",
      " [1.74281563 1.49283927]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56368854 0.71369219]\n",
      " [0.7169011  0.79155721]\n",
      " [0.7445626  0.74495541]\n",
      " [0.85104435 0.81650405]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03041739]\n",
      " [ 0.00585964]\n",
      " [ 0.0171163 ]\n",
      " [ 0.04097584]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49239624]\n",
      " [0.50146491]\n",
      " [0.50427897]\n",
      " [0.51024253]]\n",
      "Error [[-0.49239624]\n",
      " [ 0.49853509]\n",
      " [ 0.49572103]\n",
      " [-0.51024253]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25621265 0.9133854 ]\n",
      " [0.92946095 1.33432735]\n",
      " [1.07009121 1.07185263]\n",
      " [1.74333951 1.49279459]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56370505 0.71369242]\n",
      " [0.71696591 0.79155553]\n",
      " [0.74461426 0.74494908]\n",
      " [0.85111075 0.81649735]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03047462]\n",
      " [ 0.00586546]\n",
      " [ 0.0171337 ]\n",
      " [ 0.04103007]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49238194]\n",
      " [0.50146636]\n",
      " [0.50428332]\n",
      " [0.51025608]]\n",
      "Error [[-0.49238194]\n",
      " [ 0.49853364]\n",
      " [ 0.49571668]\n",
      " [-0.51025608]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25627988 0.91338651]\n",
      " [0.92978078 1.33431713]\n",
      " [1.0703633  1.07181925]\n",
      " [1.7438642  1.49274987]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56372158 0.71369265]\n",
      " [0.71703081 0.79155384]\n",
      " [0.744666   0.74494273]\n",
      " [0.85117723 0.81649065]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0305319 ]\n",
      " [ 0.0058713 ]\n",
      " [ 0.01715113]\n",
      " [ 0.04108436]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49236762]\n",
      " [0.50146782]\n",
      " [0.50428768]\n",
      " [0.51026964]]\n",
      "Error [[-0.49236762]\n",
      " [ 0.49853218]\n",
      " [ 0.49571232]\n",
      " [-0.51026964]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25634719 0.91338762]\n",
      " [0.93010109 1.3343069 ]\n",
      " [1.07063581 1.07178583]\n",
      " [1.74438971 1.49270511]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56373814 0.71369287]\n",
      " [0.71709579 0.79155215]\n",
      " [0.74471781 0.74493638]\n",
      " [0.85124378 0.81648395]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03058923]\n",
      " [ 0.00587717]\n",
      " [ 0.01716858]\n",
      " [ 0.04113869]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49235329]\n",
      " [0.50146929]\n",
      " [0.50429204]\n",
      " [0.51028322]]\n",
      "Error [[-0.49235329]\n",
      " [ 0.49853071]\n",
      " [ 0.49570796]\n",
      " [-0.51028322]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25641459 0.91338874]\n",
      " [0.93042188 1.33429667]\n",
      " [1.07090875 1.07175237]\n",
      " [1.74491604 1.4926603 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56375472 0.7136931 ]\n",
      " [0.71716087 0.79155047]\n",
      " [0.7447697  0.74493003]\n",
      " [0.85131042 0.81647723]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03064662]\n",
      " [ 0.00588306]\n",
      " [ 0.01718605]\n",
      " [ 0.04119308]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49233894]\n",
      " [0.50147076]\n",
      " [0.50429641]\n",
      " [0.51029681]]\n",
      "Error [[-0.49233894]\n",
      " [ 0.49852924]\n",
      " [ 0.49570359]\n",
      " [-0.51029681]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25648207 0.91338986]\n",
      " [0.93074315 1.33428643]\n",
      " [1.07118211 1.07171888]\n",
      " [1.74544319 1.49261546]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56377131 0.71369333]\n",
      " [0.71722603 0.79154878]\n",
      " [0.74482165 0.74492366]\n",
      " [0.85137713 0.81647051]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03070406]\n",
      " [ 0.00588897]\n",
      " [ 0.01720355]\n",
      " [ 0.04124752]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49232459]\n",
      " [0.50147224]\n",
      " [0.50430078]\n",
      " [0.51031042]]\n",
      "Error [[-0.49232459]\n",
      " [ 0.49852776]\n",
      " [ 0.49569922]\n",
      " [-0.51031042]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25654964 0.91339097]\n",
      " [0.9310649  1.33427619]\n",
      " [1.07145589 1.07168536]\n",
      " [1.74597115 1.49257057]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56378793 0.71369356]\n",
      " [0.71729128 0.79154709]\n",
      " [0.74487369 0.74491729]\n",
      " [0.85144393 0.81646379]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03076156]\n",
      " [ 0.00589492]\n",
      " [ 0.01722108]\n",
      " [ 0.04130201]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49231022]\n",
      " [0.50147373]\n",
      " [0.50430516]\n",
      " [0.51032403]]\n",
      "Error [[-0.49231022]\n",
      " [ 0.49852627]\n",
      " [ 0.49569484]\n",
      " [-0.51032403]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25661729 0.9133921 ]\n",
      " [0.93138713 1.33426594]\n",
      " [1.07173009 1.0716518 ]\n",
      " [1.74649993 1.49252564]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56380457 0.71369379]\n",
      " [0.71735662 0.7915454 ]\n",
      " [0.74492579 0.74491091]\n",
      " [0.8515108  0.81645705]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03081911]\n",
      " [ 0.00590088]\n",
      " [ 0.01723863]\n",
      " [ 0.04135655]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49229583]\n",
      " [0.50147522]\n",
      " [0.50430955]\n",
      " [0.51033766]]\n",
      "Error [[-0.49229583]\n",
      " [ 0.49852478]\n",
      " [ 0.49569045]\n",
      " [-0.51033766]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25668503 0.91339322]\n",
      " [0.93170985 1.33425568]\n",
      " [1.07200472 1.0716182 ]\n",
      " [1.74702954 1.49248067]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56382122 0.71369402]\n",
      " [0.71742205 0.7915437 ]\n",
      " [0.74497797 0.74490453]\n",
      " [0.85157775 0.81645032]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03087672]\n",
      " [ 0.00590688]\n",
      " [ 0.0172562 ]\n",
      " [ 0.04141114]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49228143]\n",
      " [0.50147672]\n",
      " [0.50431394]\n",
      " [0.51035131]]\n",
      "Error [[-0.49228143]\n",
      " [ 0.49852328]\n",
      " [ 0.49568606]\n",
      " [-0.51035131]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25675285 0.91339434]\n",
      " [0.93203304 1.33424543]\n",
      " [1.07227977 1.07158457]\n",
      " [1.74755996 1.49243565]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5638379  0.71369425]\n",
      " [0.71748756 0.79154201]\n",
      " [0.74503022 0.74489814]\n",
      " [0.85164478 0.81644357]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03093438]\n",
      " [ 0.0059129 ]\n",
      " [ 0.0172738 ]\n",
      " [ 0.04146579]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49226702]\n",
      " [0.50147822]\n",
      " [0.50431834]\n",
      " [0.51036496]]\n",
      "Error [[-0.49226702]\n",
      " [ 0.49852178]\n",
      " [ 0.49568166]\n",
      " [-0.51036496]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25682075 0.91339547]\n",
      " [0.93235672 1.33423516]\n",
      " [1.07255524 1.0715509 ]\n",
      " [1.74809121 1.4923906 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5638546  0.71369448]\n",
      " [0.71755317 0.79154032]\n",
      " [0.74508255 0.74489174]\n",
      " [0.85171189 0.81643682]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0309921 ]\n",
      " [ 0.00591894]\n",
      " [ 0.01729142]\n",
      " [ 0.04152048]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4922526 ]\n",
      " [0.50147973]\n",
      " [0.50432275]\n",
      " [0.51037863]]\n",
      "Error [[-0.4922526 ]\n",
      " [ 0.49852027]\n",
      " [ 0.49567725]\n",
      " [-0.51037863]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25688874 0.91339659]\n",
      " [0.93268088 1.33422489]\n",
      " [1.07283114 1.0715172 ]\n",
      " [1.74862328 1.4923455 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56387132 0.71369471]\n",
      " [0.71761886 0.79153862]\n",
      " [0.74513495 0.74488534]\n",
      " [0.85177907 0.81643006]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03104987]\n",
      " [ 0.00592501]\n",
      " [ 0.01730907]\n",
      " [ 0.04157523]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49223816]\n",
      " [0.50148125]\n",
      " [0.50432716]\n",
      " [0.51039231]]\n",
      "Error [[-0.49223816]\n",
      " [ 0.49851875]\n",
      " [ 0.49567284]\n",
      " [-0.51039231]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25695681 0.91339772]\n",
      " [0.93300552 1.33421462]\n",
      " [1.07310747 1.07148347]\n",
      " [1.74915617 1.49230036]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56388806 0.71369494]\n",
      " [0.71768464 0.79153693]\n",
      " [0.74518742 0.74487893]\n",
      " [0.85184634 0.81642329]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.0311077 ]\n",
      " [ 0.0059311 ]\n",
      " [ 0.01732674]\n",
      " [ 0.04163003]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4922237 ]\n",
      " [0.50148277]\n",
      " [0.50433158]\n",
      " [0.51040601]]\n",
      "Error [[-0.4922237 ]\n",
      " [ 0.49851723]\n",
      " [ 0.49566842]\n",
      " [-0.51040601]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25702497 0.91339885]\n",
      " [0.93333064 1.33420434]\n",
      " [1.07338422 1.07144969]\n",
      " [1.74968989 1.49225518]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56390482 0.71369517]\n",
      " [0.71775051 0.79153523]\n",
      " [0.74523997 0.74487251]\n",
      " [0.85191368 0.81641652]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03116558]\n",
      " [ 0.00593722]\n",
      " [ 0.01734444]\n",
      " [ 0.04168489]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49220924]\n",
      " [0.5014843 ]\n",
      " [0.504336  ]\n",
      " [0.51041971]]\n",
      "Error [[-0.49220924]\n",
      " [ 0.4985157 ]\n",
      " [ 0.495664  ]\n",
      " [-0.51041971]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25709321 0.91339998]\n",
      " [0.93365625 1.33419406]\n",
      " [1.07366139 1.07141588]\n",
      " [1.75022443 1.49220996]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5639216  0.7136954 ]\n",
      " [0.71781647 0.79153353]\n",
      " [0.74529259 0.74486608]\n",
      " [0.85198111 0.81640974]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03122352]\n",
      " [ 0.00594337]\n",
      " [ 0.01736216]\n",
      " [ 0.04173979]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49219475]\n",
      " [0.50148584]\n",
      " [0.50434043]\n",
      " [0.51043343]]\n",
      "Error [[-0.49219475]\n",
      " [ 0.49851416]\n",
      " [ 0.49565957]\n",
      " [-0.51043343]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25716154 0.91340112]\n",
      " [0.93398234 1.33418377]\n",
      " [1.073939   1.07138204]\n",
      " [1.7507598  1.49216469]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56393841 0.71369563]\n",
      " [0.71788252 0.79153184]\n",
      " [0.74534528 0.74485965]\n",
      " [0.85204861 0.81640296]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03128151]\n",
      " [ 0.00594954]\n",
      " [ 0.01737991]\n",
      " [ 0.04179475]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49218026]\n",
      " [0.50148738]\n",
      " [0.50434487]\n",
      " [0.51044717]]\n",
      "Error [[-0.49218026]\n",
      " [ 0.49851262]\n",
      " [ 0.49565513]\n",
      " [-0.51044717]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25722995 0.91340225]\n",
      " [0.93430892 1.33417347]\n",
      " [1.07421703 1.07134816]\n",
      " [1.751296   1.49211938]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56395523 0.71369586]\n",
      " [0.71794865 0.79153014]\n",
      " [0.74539805 0.74485321]\n",
      " [0.85211619 0.81639617]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03133956]\n",
      " [ 0.00595573]\n",
      " [ 0.01739769]\n",
      " [ 0.04184976]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49216575]\n",
      " [0.50148893]\n",
      " [0.50434931]\n",
      " [0.51046091]]\n",
      "Error [[-0.49216575]\n",
      " [ 0.49851107]\n",
      " [ 0.49565069]\n",
      " [-0.51046091]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25729844 0.91340339]\n",
      " [0.93463598 1.33416318]\n",
      " [1.07449548 1.07131425]\n",
      " [1.75183302 1.49207403]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56397207 0.7136961 ]\n",
      " [0.71801488 0.79152844]\n",
      " [0.74545089 0.74484677]\n",
      " [0.85218385 0.81638937]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03139767]\n",
      " [ 0.00596195]\n",
      " [ 0.01741548]\n",
      " [ 0.04190482]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49215123]\n",
      " [0.50149048]\n",
      " [0.50435376]\n",
      " [0.51047467]]\n",
      "Error [[-0.49215123]\n",
      " [ 0.49850952]\n",
      " [ 0.49564624]\n",
      " [-0.51047467]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25736702 0.91340453]\n",
      " [0.93496353 1.33415287]\n",
      " [1.07477436 1.0712803 ]\n",
      " [1.75237087 1.49202864]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56398894 0.71369633]\n",
      " [0.71808119 0.79152674]\n",
      " [0.74550381 0.74484032]\n",
      " [0.85225159 0.81638257]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03145583]\n",
      " [ 0.0059682 ]\n",
      " [ 0.01743331]\n",
      " [ 0.04195994]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49213669]\n",
      " [0.50149205]\n",
      " [0.50435822]\n",
      " [0.51048845]]\n",
      "Error [[-0.49213669]\n",
      " [ 0.49850795]\n",
      " [ 0.49564178]\n",
      " [-0.51048845]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25743568 0.91340567]\n",
      " [0.93529156 1.33414256]\n",
      " [1.07505368 1.07124631]\n",
      " [1.75290956 1.49198321]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56400582 0.71369656]\n",
      " [0.71814759 0.79152504]\n",
      " [0.7455568  0.74483386]\n",
      " [0.85231941 0.81637575]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03151405]\n",
      " [ 0.00597448]\n",
      " [ 0.01745116]\n",
      " [ 0.04201511]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49212214]\n",
      " [0.50149361]\n",
      " [0.50436268]\n",
      " [0.51050223]]\n",
      "Error [[-0.49212214]\n",
      " [ 0.49850639]\n",
      " [ 0.49563732]\n",
      " [-0.51050223]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25750443 0.91340681]\n",
      " [0.93562008 1.33413225]\n",
      " [1.07533341 1.07121229]\n",
      " [1.75344907 1.49193773]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56402273 0.7136968 ]\n",
      " [0.71821409 0.79152334]\n",
      " [0.74560986 0.74482739]\n",
      " [0.8523873  0.81636894]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03157232]\n",
      " [ 0.00598077]\n",
      " [ 0.01746903]\n",
      " [ 0.04207033]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49210758]\n",
      " [0.50149519]\n",
      " [0.50436715]\n",
      " [0.51051603]]\n",
      "Error [[-0.49210758]\n",
      " [ 0.49850481]\n",
      " [ 0.49563285]\n",
      " [-0.51051603]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25757326 0.91340795]\n",
      " [0.93594908 1.33412193]\n",
      " [1.07561358 1.07117824]\n",
      " [1.75398941 1.49189221]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56403965 0.71369703]\n",
      " [0.71828067 0.79152163]\n",
      " [0.745663   0.74482092]\n",
      " [0.85245528 0.81636211]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03163065]\n",
      " [ 0.0059871 ]\n",
      " [ 0.01748694]\n",
      " [ 0.0421256 ]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.492093  ]\n",
      " [0.50149677]\n",
      " [0.50437162]\n",
      " [0.51052984]]\n",
      "Error [[-0.492093  ]\n",
      " [ 0.49850323]\n",
      " [ 0.49562838]\n",
      " [-0.51052984]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25764217 0.9134091 ]\n",
      " [0.93627857 1.33411161]\n",
      " [1.07589418 1.07114414]\n",
      " [1.75453058 1.49184665]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.5640566  0.71369726]\n",
      " [0.71834733 0.79151993]\n",
      " [0.74571621 0.74481444]\n",
      " [0.85252333 0.81635528]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03168903]\n",
      " [ 0.00599345]\n",
      " [ 0.01750486]\n",
      " [ 0.04218093]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4920784 ]\n",
      " [0.50149836]\n",
      " [0.5043761 ]\n",
      " [0.51054367]]\n",
      "Error [[-0.4920784 ]\n",
      " [ 0.49850164]\n",
      " [ 0.4956239 ]\n",
      " [-0.51054367]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25771117 0.91341025]\n",
      " [0.93660855 1.33410128]\n",
      " [1.07617521 1.07111001]\n",
      " [1.75507259 1.49180105]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56407356 0.7136975 ]\n",
      " [0.71841409 0.79151823]\n",
      " [0.74576949 0.74480795]\n",
      " [0.85259146 0.81634845]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03174748]\n",
      " [ 0.00599983]\n",
      " [ 0.01752281]\n",
      " [ 0.04223631]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.4920638 ]\n",
      " [0.50149995]\n",
      " [0.50438059]\n",
      " [0.51055751]]\n",
      "Error [[-0.4920638 ]\n",
      " [ 0.49850005]\n",
      " [ 0.49561941]\n",
      " [-0.51055751]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25778025 0.9134114 ]\n",
      " [0.93693902 1.33409095]\n",
      " [1.07645666 1.07107585]\n",
      " [1.75561543 1.4917554 ]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56409055 0.71369773]\n",
      " [0.71848094 0.79151652]\n",
      " [0.74582285 0.74480146]\n",
      " [0.85265967 0.8163416 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03180598]\n",
      " [ 0.00600623]\n",
      " [ 0.01754079]\n",
      " [ 0.04229175]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49204918]\n",
      " [0.50150155]\n",
      " [0.50438509]\n",
      " [0.51057136]]\n",
      "Error [[-0.49204918]\n",
      " [ 0.49849845]\n",
      " [ 0.49561491]\n",
      " [-0.51057136]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25784942 0.91341255]\n",
      " [0.93726997 1.33408061]\n",
      " [1.07673855 1.07104165]\n",
      " [1.7561591  1.49170972]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56410756 0.71369797]\n",
      " [0.71854788 0.79151481]\n",
      " [0.74587629 0.74479496]\n",
      " [0.85272796 0.81633475]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03186453]\n",
      " [ 0.00601266]\n",
      " [ 0.01755879]\n",
      " [ 0.04234723]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49203454]\n",
      " [0.50150316]\n",
      " [0.50438959]\n",
      " [0.51058523]]\n",
      "Error [[-0.49203454]\n",
      " [ 0.49849684]\n",
      " [ 0.49561041]\n",
      " [-0.51058523]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.25791867 0.9134137 ]\n",
      " [0.93760142 1.33407027]\n",
      " [1.07702086 1.07100742]\n",
      " [1.75670361 1.49166399]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56412459 0.7136982 ]\n",
      " [0.7186149  0.79151311]\n",
      " [0.7459298  0.74478845]\n",
      " [0.85279633 0.8163279 ]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03192314]\n",
      " [ 0.00601911]\n",
      " [ 0.01757682]\n",
      " [ 0.04240277]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49201989]\n",
      " [0.50150477]\n",
      " [0.50439409]\n",
      " [0.51059911]]\n",
      "Error [[-0.49201989]\n",
      " [ 0.49849523]\n",
      " [ 0.49560591]\n",
      " [-0.51059911]]\n",
      "Aggrigation in hidden layer\n",
      "[[0.257988   0.91341485]\n",
      " [0.93793335 1.33405992]\n",
      " [1.07730361 1.07097314]\n",
      " [1.75724896 1.49161821]]\n",
      " \n",
      "Applying Activation in Hidden layer\n",
      "[[0.56414163 0.71369844]\n",
      " [0.71868201 0.7915114 ]\n",
      " [0.74598338 0.74478194]\n",
      " [0.85286478 0.81632103]]\n",
      " \n",
      "Aggrigation in Output Layer\n",
      "[[-0.03198181]\n",
      " [ 0.0060256 ]\n",
      " [ 0.01759488]\n",
      " [ 0.04245837]]\n",
      " \n",
      "Applying Activation Function in Output layer\n",
      "Predicated Output\n",
      "[[0.49200523]\n",
      " [0.50150639]\n",
      " [0.50439861]\n",
      " [0.510613  ]]\n",
      "Error [[-0.49200523]\n",
      " [ 0.49849361]\n",
      " [ 0.49560139]\n",
      " [-0.510613  ]]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    #for hidden layer\n",
    "\n",
    "    print(\"Aggrigation in hidden layer\")\n",
    "    #doing aggrigation\n",
    "    HL_activation = np.dot(x,HW)\n",
    "    HL_activation += hidden_bias\n",
    "    print(HL_activation)\n",
    "    print(\" \")\n",
    "\n",
    "    print(\"Applying Activation in Hidden layer\")\n",
    "    #applying activation function\n",
    "    hidden_layer_output = sigmoid_fun(HL_activation)\n",
    "    print(hidden_layer_output)\n",
    "\n",
    "\n",
    "    print(\" \")\n",
    "\n",
    "\n",
    "    #for output layer\n",
    "    #doing aggrigation\n",
    "    print(\"Aggrigation in Output Layer\")\n",
    "    OL_activation=np.dot(hidden_layer_output,OW)\n",
    "    OL_activation += output_bias\n",
    "    print(OL_activation)\n",
    "\n",
    "\n",
    "    print(\" \")\n",
    "    #applying activation \n",
    "    print(\"Applying Activation Function in Output layer\")\n",
    "    print(\"Predicated Output\")\n",
    "    Predicted_Output = sigmoid_fun(OL_activation)\n",
    "    print(Predicted_Output)\n",
    "    \n",
    "    error = y - Predicted_Output\n",
    "    print(\"Error\",error)\n",
    "    \n",
    "    d_predicted_output = error * sigmoid_derivative(Predicted_Output)\n",
    "    error_hidden_layer = d_predicted_output.dot(OW.T)\n",
    "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "    #Updating Weights and Biases\n",
    "    OW += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
    "    output_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
    "    HW += x.T.dot(d_hidden_layer) * lr\n",
    "    hidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "031070fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer Weights\n",
      "[[0.81952937 0.15752283]\n",
      " [0.68020835 0.42063356]]\n",
      "Hidden layer bias\n",
      "[[0.25805742 0.91341601]]\n",
      "Output layer Weights\n",
      "[[ 0.28673778]\n",
      " [-0.08037803]]\n",
      "Output layer bias\n",
      "[[-0.13644046]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Hidden layer Weights\")\n",
    "print(HW)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Hidden layer bias\")\n",
    "print(hidden_bias)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Output layer Weights\")\n",
    "print(OW)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Output layer bias\")\n",
    "print(output_bias)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6737114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
